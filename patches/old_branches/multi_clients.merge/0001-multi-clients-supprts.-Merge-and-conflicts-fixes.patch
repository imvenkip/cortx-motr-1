From 3f5188797f6d1526de5a608b51dd3e60c0de824f Mon Sep 17 00:00:00 2001
From: Hua Huang <hua_huang@xyratex.com>
Date: Sat, 22 Mar 2014 23:22:56 +0800
Subject: [PATCH 1/3] multi-clients supprts. Merge and conflicts fixes.

---
 addb/addb_rec.c                                |   2 +-
 addb/linux_kernel/kctx.c                       |   1 +
 be/linux_kernel/stubs.c                        |   2 +
 be/ut/helper.c                                 |   4 +-
 file/file.c                                    |  30 +-
 file/file.h                                    |  15 +-
 fop/fom.c                                      |  52 +++-
 fop/fom.h                                      |   4 +-
 fop/fop.c                                      |   3 +
 ioservice/io_fops.c                            |  20 +-
 ioservice/ut/bulkio_client.c                   |  18 +-
 ioservice/ut/bulkio_common.c                   |   7 +-
 ioservice/ut/bulkio_common.h                   |   1 +
 layout/layout.c                                |   4 -
 layout/ut/layout.c                             |  22 --
 lib/bitmap.c                                   |  13 +
 lib/bitmap.h                                   |   8 +
 m0t1fs/linux_kernel/dir.c                      |  21 +-
 m0t1fs/linux_kernel/file.c                     |  27 +-
 m0t1fs/linux_kernel/inode.c                    |  17 +-
 m0t1fs/linux_kernel/m0t1fs.c                   | 367 ++--------------------
 m0t1fs/linux_kernel/m0t1fs.h                   |  94 +++---
 m0t1fs/linux_kernel/st/m0t1fs_client_inc.sh    | 107 ++++++-
 m0t1fs/linux_kernel/st/m0t1fs_common_inc.sh    |  15 +-
 m0t1fs/linux_kernel/st/m0t1fs_multi_clients.sh |  45 +++
 m0t1fs/linux_kernel/st/m0t1fs_test.sh          |   1 -
 m0t1fs/linux_kernel/st/st                      |  12 +-
 m0t1fs/linux_kernel/super.c                    | 414 +++++++++++++++++++++++--
 m0t1fs/linux_kernel/ut/file.c                  |  43 ++-
 mdservice/md_foms.c                            |   8 +-
 mdstore/mdstore.c                              |   3 +
 net/tm.c                                       |   9 +-
 reqh/reqh.c                                    |   2 +-
 rm/rm_service.c                                |   6 +-
 rm/rm_service.h                                |  14 +-
 rpc/it/st.sh                                   |   1 -
 scripts/m0                                     |   3 +
 stats/stats_srv.c                              |   2 -
 38 files changed, 862 insertions(+), 555 deletions(-)
 create mode 100755 m0t1fs/linux_kernel/st/m0t1fs_multi_clients.sh

diff --git a/addb/addb_rec.c b/addb/addb_rec.c
index 10fdbea..409893b 100644
--- a/addb/addb_rec.c
+++ b/addb/addb_rec.c
@@ -68,7 +68,6 @@ static void addb_rec_post(struct m0_addb_mc *mc,
 			  uint64_t *fields,
 			  size_t fields_nr)
 {
-	struct m0_addb_monitor *mon;
 	struct m0_addb_rec     *rec;
 	size_t                  len;
 	size_t                  ctxid_seq_data_size;
@@ -160,6 +159,7 @@ static void addb_rec_post(struct m0_addb_mc *mc,
 	 */
 	if (mc->am_reqh != NULL &&
 	    m0_addb_mon_ctx_invariant(&mc->am_reqh->rh_addb_monitoring_ctx)) {
+		struct m0_addb_monitor *mon;
 		/* Invoke all the monitor's filters */
 		m0_mutex_lock(&mc->am_reqh->rh_addb_monitoring_ctx.amc_mutex);
 		m0_tl_for(addb_mon,
diff --git a/addb/linux_kernel/kctx.c b/addb/linux_kernel/kctx.c
index f931bda..a8ed9f6 100644
--- a/addb/linux_kernel/kctx.c
+++ b/addb/linux_kernel/kctx.c
@@ -21,6 +21,7 @@
 /* This file is designed to be included by addb/addb.c */
 
 #include "m0t1fs/linux_kernel/m0t1fs.h"
+#include "m0t1fs/m0t1fs_addb.h"
 
 /**
    @ingroup addb_pvt
diff --git a/be/linux_kernel/stubs.c b/be/linux_kernel/stubs.c
index e243944..07e7917 100644
--- a/be/linux_kernel/stubs.c
+++ b/be/linux_kernel/stubs.c
@@ -111,6 +111,8 @@ M0_INTERNAL void m0_be_seg_init(struct m0_be_seg *seg,
 				struct m0_stob *stob,
 				struct m0_be_domain *dom)
 {
+	seg->bs_stob   = stob;
+	seg->bs_domain = dom;
 }
 
 M0_INTERNAL void m0_be_seg_fini(struct m0_be_seg *seg)
diff --git a/be/ut/helper.c b/be/ut/helper.c
index 6d46896..a7154f0 100644
--- a/be/ut/helper.c
+++ b/be/ut/helper.c
@@ -703,8 +703,8 @@ static bool fom_domain_is_idle(const struct m0_fom_domain *dom)
 	bool result = false;
 
 	for (i = 0; i < dom->fd_localities_nr; ++i) {
-		if ((i == 0 && dom->fd_localities[i].fl_foms == 1) ||
-				dom->fd_localities[i].fl_foms == 0)
+		if ((i == 0 && dom->fd_localities[i]->fl_foms == 1) ||
+				dom->fd_localities[i]->fl_foms == 0)
 			result = true;
 		else
 			return false;
diff --git a/file/file.c b/file/file.c
index 3b5620d..6c4f92c 100644
--- a/file/file.c
+++ b/file/file.c
@@ -183,10 +183,6 @@ static int file_lock_cr_decode(struct m0_rm_credit     *self,
 static void file_lock_cr_free(struct m0_rm_credit *self);
 static void file_lock_cr_initial_capital(struct m0_rm_credit *self);
 
-static struct m0_rm_resource_type flock_rt = {
-	.rt_name = "File Lock Resource Type"
-};
-
 const struct m0_rm_resource_type_ops file_lock_type_ops = {
 	.rto_eq     = file_lock_equal,
 	.rto_len    = file_lock_len,
@@ -540,36 +536,42 @@ M0_INTERNAL void m0_file_unlock(struct m0_rm_incoming *req)
 }
 M0_EXPORTED(m0_file_unlock);
 
-M0_INTERNAL int m0_file_lock_type_register(struct m0_rm_domain *dom)
+M0_INTERNAL int m0_file_lock_type_register(struct m0_rm_domain *dom,
+					   struct m0_rm_resource_type *flock_rt)
 {
 	M0_ENTRY();
 
-	flock_rt.rt_id = M0_RM_FLOCK_RT;
-	flock_rt.rt_ops = &file_lock_type_ops;
-	return M0_RC(m0_rm_type_register(dom, &flock_rt));
+	flock_rt->rt_id = M0_RM_FLOCK_RT;
+	flock_rt->rt_ops = &file_lock_type_ops;
+	return M0_RC(m0_rm_type_register(dom, flock_rt));
 }
 M0_EXPORTED(m0_file_lock_type_register);
 
-M0_INTERNAL void m0_file_lock_type_deregister(void)
+M0_INTERNAL
+void m0_file_lock_type_deregister(struct m0_rm_resource_type *flock_rt)
 {
 	M0_ENTRY();
-	m0_rm_type_deregister(&flock_rt);
+	m0_rm_type_deregister(flock_rt);
 	M0_LEAVE();
 }
 M0_EXPORTED(m0_file_lock_type_deregister);
 
-M0_INTERNAL bool m0_file_lock_resource_is_added(const struct m0_fid *fid)
+M0_INTERNAL
+bool m0_file_lock_resource_is_added(const struct m0_fid *fid,
+				    struct m0_rm_resource_type *flock_rt)
 {
 	struct m0_file file;
 
 	M0_PRE(fid != NULL);
 
 	file.fi_fid = fid;
-	return m0_rm_resource_find(&flock_rt, &file.fi_res) == NULL ?
+	return m0_rm_resource_find(flock_rt, &file.fi_res) == NULL ?
 		false : true;
 }
 
-M0_INTERNAL struct m0_file *m0_resource_to_file(const struct m0_fid *fid)
+M0_INTERNAL
+struct m0_file *m0_resource_to_file(const struct m0_fid *fid,
+				    struct m0_rm_resource_type *flock_rt)
 {
 	struct m0_file	      *file = NULL;
 	struct m0_file	       lfile;
@@ -581,7 +583,7 @@ M0_INTERNAL struct m0_file *m0_resource_to_file(const struct m0_fid *fid)
 	M0_LOG(M0_DEBUG, FID_F, FID_P(fid));
 
 	lfile.fi_fid = fid;
-	res = m0_rm_resource_find(&flock_rt, &lfile.fi_res);
+	res = m0_rm_resource_find(flock_rt, &lfile.fi_res);
 	if (res != NULL)
 		file = container_of(res, struct m0_file, fi_res);
 
diff --git a/file/file.h b/file/file.h
index 380f553..cbd1edf 100644
--- a/file/file.h
+++ b/file/file.h
@@ -137,23 +137,30 @@ M0_INTERNAL void m0_file_unlock(struct m0_rm_incoming *req);
 /**
  * Registers the resource of type 'distributed mutex' with a resource domain.
  */
-M0_INTERNAL int m0_file_lock_type_register(struct m0_rm_domain *dom);
+M0_INTERNAL
+int m0_file_lock_type_register(struct m0_rm_domain *dom,
+			       struct m0_rm_resource_type *flock_rt);
 
 /**
  * De-registers the resource of type 'distributed mutex' from a resource domain.
  */
-M0_INTERNAL void m0_file_lock_type_deregister(void);
+M0_INTERNAL
+void m0_file_lock_type_deregister(struct m0_rm_resource_type *flock_rt);
 
 /**
  * Check whether a file lock resource with description given in @fid is
  * registered with file lock domain.
  */
-M0_INTERNAL bool m0_file_lock_resource_is_added(const struct m0_fid *fid);
+M0_INTERNAL
+bool m0_file_lock_resource_is_added(const struct m0_fid *fid,
+				    struct m0_rm_resource_type *flock_rt);
 
 /**
  * Returns m0_file from the given resource @fid.
  */
-M0_INTERNAL struct m0_file *m0_resource_to_file(const struct m0_fid *fid);
+M0_INTERNAL
+struct m0_file *m0_resource_to_file(const struct m0_fid *fid,
+				    struct m0_rm_resource_type *flock_rt);
 
 /** @} end of FileLock */
 
diff --git a/fop/fom.c b/fop/fom.c
index 65ffc7e..3f3d0f4 100644
--- a/fop/fom.c
+++ b/fop/fom.c
@@ -156,6 +156,7 @@ struct m0_loc_thread {
 	uint64_t                lt_magix;
 };
 
+extern uint32_t  fop_rate_monitor_key;
 static m0_time_t fop_rate_interval = M0_MKTIME(1, 0);
 
 M0_TL_DESCR_DEFINE(thr, "fom thread", static, struct m0_loc_thread, lt_linkage,
@@ -179,8 +180,6 @@ static void __fom_domain_fini(struct m0_fom_domain *dom);
  * Fom domain operations.
  * @todo Support fom timeout functionality.
  */
-#undef FOM_RATE_KEY
-#define FOM_RATE_KEY(reqh)	(reqh->rh_fom_dom.fd_fop_rate_monitor_key)
 
 static struct m0_fom_domain_ops m0_fom_dom_ops = {
 	.fdo_time_is_out = fom_wait_time_is_out
@@ -199,7 +198,7 @@ fop_rate_monitor_sum_rec(const struct m0_addb_monitor *mon,
 	M0_PRE(reqh != NULL);
 
 	m0_rwlock_read_lock(&reqh->rh_rwlock);
-	sum_rec = m0_reqh_lockers_get(reqh, FOM_RATE_KEY(reqh));
+	sum_rec = m0_reqh_lockers_get(reqh, fop_rate_monitor_key);
 	m0_rwlock_read_unlock(&reqh->rh_rwlock);
 
 	M0_ASSERT(sum_rec != NULL);
@@ -251,7 +250,7 @@ const struct m0_addb_monitor_ops fop_rate_monitor_ops = {
 
 static int fop_rate_monitor_init(struct m0_reqh         *reqh,
 				 struct m0_addb_monitor *monitor,
-				 uint32_t               *fop_rate_monitor_key)
+				 uint32_t                fop_rate_monitor_key)
 {
 #undef FOP_RATE_STATS_NR
 #define FOP_RATE_STATS_NR (sizeof(fop_rate_stats_sum) / sizeof(uint64_t))
@@ -269,10 +268,8 @@ static int fop_rate_monitor_init(struct m0_reqh         *reqh,
 				     (uint64_t *)&fop_rate_stats_sum,
 				     FOP_RATE_STATS_NR);
 
-	*fop_rate_monitor_key = m0_reqh_lockers_allot();
-
 	m0_rwlock_write_lock(&reqh->rh_rwlock);
-	m0_reqh_lockers_set(reqh, *fop_rate_monitor_key, sum_rec);
+	m0_reqh_lockers_set(reqh, fop_rate_monitor_key, sum_rec);
 	m0_rwlock_write_unlock(&reqh->rh_rwlock);
 
 	m0_addb_monitor_add(reqh, monitor);
@@ -337,7 +334,9 @@ static bool thread_invariant(const struct m0_loc_thread *t)
 
 M0_INTERNAL bool m0_fom_domain_invariant(const struct m0_fom_domain *dom)
 {
+	size_t cpu_max = m0_processor_nr_max();
 	return dom != NULL && dom->fd_localities != NULL &&
+	       m0_forall(i, cpu_max, dom->fd_localities[i] != NULL) &&
 		dom->fd_ops != NULL;
 }
 
@@ -555,7 +554,7 @@ M0_INTERNAL void m0_fom_queue(struct m0_fom *fom, struct m0_reqh *reqh)
 	dom = &reqh->rh_fom_dom;
 	loc_idx = fom->fo_ops->fo_home_locality(fom) % dom->fd_localities_nr;
 	M0_ASSERT(loc_idx >= 0 && loc_idx < dom->fd_localities_nr);
-	fom->fo_loc = &reqh->rh_fom_dom.fd_localities[loc_idx];
+	fom->fo_loc = reqh->rh_fom_dom.fd_localities[loc_idx];
 	m0_fom_sm_init(fom);
 	fom->fo_cb.fc_ast.sa_cb = queueit;
 	m0_sm_ast_post(&fom->fo_loc->fl_group, &fom->fo_cb.fc_ast);
@@ -1015,8 +1014,8 @@ M0_INTERNAL int m0_fom_domain_init(struct m0_fom_domain *dom)
 	int                     result;
 	size_t                  cpu;
 	size_t                  cpu_max;
-	struct m0_fom_locality *localities;
 	struct m0_bitmap        onln_cpu_map;
+	int                     i;
 
 
 	M0_PRE(dom != NULL);
@@ -1028,20 +1027,34 @@ M0_INTERNAL int m0_fom_domain_init(struct m0_fom_domain *dom)
 		return result;
 
 	m0_processors_online(&onln_cpu_map);
+	M0_LOG(M0_DEBUG, "sizeof struct m0_fom_locality = %d cpu_max = %d",
+			 (int)(sizeof **dom->fd_localities), (int)cpu_max);
 	FOP_ALLOC_ARR(dom->fd_localities, cpu_max, FOM_DOMAIN_INIT,
 			&m0_fop_addb_ctx);
 	if (dom->fd_localities == NULL) {
 		m0_bitmap_fini(&onln_cpu_map);
 		return -ENOMEM;
 	}
+	for (i = 0; i < cpu_max; i++) {
+		FOP_ALLOC_PTR(dom->fd_localities[i], FOM_DOMAIN_INIT,
+			      &m0_fop_addb_ctx);
+		if (dom->fd_localities[i] == NULL) {
+			int j;
+			for (j = 0; j <= i; j++) {
+				m0_free(dom->fd_localities[j]);
+			}
+			m0_free(dom->fd_localities);
+			m0_bitmap_fini(&onln_cpu_map);
+			return -ENOMEM;
+		}
+	}
 
-	localities = dom->fd_localities;
 	for (cpu = 0; cpu < cpu_max; ++cpu) {
 		struct m0_fom_locality *loc;
 
 		if (!m0_bitmap_get(&onln_cpu_map, cpu))
 			continue;
-		loc = &localities[dom->fd_localities_nr];
+		loc = dom->fd_localities[dom->fd_localities_nr];
 		loc->fl_dom = dom;
 		result = loc_init(loc, cpu, cpu_max);
 		if (result != 0) {
@@ -1056,24 +1069,27 @@ M0_INTERNAL int m0_fom_domain_init(struct m0_fom_domain *dom)
 	}
 
 	m0_bitmap_fini(&onln_cpu_map);
-	dom->fd_fop_rate_monitor_key = 0;
 	return fop_rate_monitor_init(dom->fd_reqh,
 				     &dom->fd_fop_rate_monitor,
-				     &dom->fd_fop_rate_monitor_key);
+				     fop_rate_monitor_key);
 }
 
 static void __fom_domain_fini(struct m0_fom_domain *dom)
 {
 	int fd_loc_nr;
+	int i;
 
 	M0_ASSERT(m0_fom_domain_invariant(dom));
 
 	fd_loc_nr = dom->fd_localities_nr;
 	while (fd_loc_nr > 0) {
-		loc_fini(&dom->fd_localities[fd_loc_nr - 1]);
+		loc_fini(dom->fd_localities[fd_loc_nr - 1]);
 		--fd_loc_nr;
 	}
 
+	for (i = 0; i < m0_processor_nr_max(); i++) {
+		m0_free(dom->fd_localities[i]);
+	}
 	m0_free(dom->fd_localities);
 }
 
@@ -1082,13 +1098,13 @@ M0_INTERNAL void m0_fom_domain_fini(struct m0_fom_domain *dom)
 	__fom_domain_fini(dom);
 	fop_rate_monitor_fini(dom->fd_reqh,
 			      &dom->fd_fop_rate_monitor,
-			      dom->fd_fop_rate_monitor_key);
+			      fop_rate_monitor_key);
 }
 
 M0_INTERNAL bool m0_fom_domain_is_idle(const struct m0_fom_domain *dom)
 {
 	return m0_forall(i, dom->fd_localities_nr,
-			 dom->fd_localities[i].fl_foms == 0);
+			 dom->fd_localities[i]->fl_foms == 0);
 }
 
 static void fop_fini(struct m0_fop *fop, bool local)
@@ -1524,6 +1540,9 @@ M0_INTERNAL int m0_fom_fol_rec_add(struct m0_fom *fom)
 	struct m0_fol_rec_desc *desc;
 	struct m0_fol          *fol;
 	int                     rc;
+#ifdef __KERNEL__
+	return 0;
+#endif
 
 	fol  = m0_fom_reqh(fom)->rh_fol;
 	desc = &fom->fo_tx.tx_fol_rec.fr_desc;
@@ -1539,7 +1558,6 @@ M0_INTERNAL int m0_fom_fol_rec_add(struct m0_fom *fom)
 }
 
 /** @} endgroup fom */
-#undef FOM_RATE_KEY
 /*
  *  Local variables:
  *  c-indentation-style: "K&R"
diff --git a/fop/fom.h b/fop/fom.h
index a8f8e25..cde876e 100644
--- a/fop/fom.h
+++ b/fop/fom.h
@@ -331,7 +331,7 @@ M0_INTERNAL void m0_fom_locality_post_stats(struct m0_fom_locality *loc);
  */
 struct m0_fom_domain {
 	/** An array of localities. */
-	struct m0_fom_locality		*fd_localities;
+	struct m0_fom_locality	       **fd_localities;
 	/** Number of localities in the domain. */
 	size_t				 fd_localities_nr;
 	/** Domain operations. */
@@ -340,8 +340,6 @@ struct m0_fom_domain {
 	struct m0_reqh			*fd_reqh;
 	/** Addb context for fom */
 	struct m0_addb_ctx               fd_addb_ctx;
-	/** fop rate monitor key */
-	uint32_t			 fd_fop_rate_monitor_key;
 	/** fop rate monitor */
 	struct m0_addb_monitor           fd_fop_rate_monitor;
 };
diff --git a/fop/fop.c b/fop/fop.c
index 7db7811..24bb31f 100644
--- a/fop/fop.c
+++ b/fop/fop.c
@@ -36,6 +36,7 @@
 #include "fop/fop_xc.h"
 #include "fop/fom_long_lock.h" /* m0_fom_ll_global_init */
 #include "addb/addb_monitor.h" /* stats register */
+#include "reqh/reqh.h"
 
 /**
    @addtogroup fop
@@ -46,6 +47,7 @@
 struct m0_addb_ctx     m0_fop_addb_ctx;
 static struct m0_mutex fop_types_lock;
 static struct m0_tl    fop_types_list;
+uint32_t               fop_rate_monitor_key;
 
 M0_TL_DESCR_DEFINE(ft, "fop types", static, struct m0_fop_type,
 		   ft_linkage,	ft_magix,
@@ -289,6 +291,7 @@ M0_INTERNAL int m0_fops_init(void)
 	m0_fop_fol_rec_part_type.rpt_ops = NULL;
 	M0_FOL_REC_PART_TYPE_INIT(m0_fop_fol_rec_part,
 				  "fop generic record part");
+	fop_rate_monitor_key = m0_reqh_lockers_allot();
 	return m0_fol_rec_part_type_register(&m0_fop_fol_rec_part_type);
 }
 
diff --git a/ioservice/io_fops.c b/ioservice/io_fops.c
index 37f23b3..c486d0e 100644
--- a/ioservice/io_fops.c
+++ b/ioservice/io_fops.c
@@ -41,6 +41,11 @@
 #include "fop/fom_generic.h"
 #include "ioservice/cob_foms.h"
 #include "file/file.h"
+#include "lib/finject.h"
+#ifdef __KERNEL__
+  #undef M0_ADDB_CT_CREATE_DEFINITION
+  #include "m0t1fs/linux_kernel/m0t1fs.h"
+#endif
 
 /**
  * This addb ctx would be used only to post for exception records
@@ -1230,6 +1235,9 @@ static void io_fop_ivec_prepare(struct m0_fop *res_fop,
 
 static int io_fop_di_prepare(struct m0_fop *fop)
 {
+#ifndef __KERNEL__
+	return 0;
+#else
 	uint64_t		   size;
 	struct m0_fop_cob_rw	  *rw;
 	struct m0_io_indexvec_seq *io_info;
@@ -1239,7 +1247,11 @@ static int io_fop_di_prepare(struct m0_fop *fop)
 	struct m0_file		  *file;
 	uint32_t		   i;
 	m0_bcount_t		   bsize;
+	struct m0t1fs_sb          *sb;
+	struct m0_rm_domain       *rdom;
 
+	if (M0_FI_ENABLED("skip_di_for_ut"))
+		return 0;
 	M0_PRE(fop != NULL);
 
 	rbulk = m0_fop_to_rpcbulk(fop);
@@ -1247,7 +1259,9 @@ static int io_fop_di_prepare(struct m0_fop *fop)
 	M0_ASSERT(m0_mutex_is_locked(&rbulk->rb_mutex));
 	rw = io_rw_get(fop);
 	io_info = &rw->crw_ivecs;
-	file = m0_resource_to_file(&rw->crw_gfid);
+	sb = m0_fop_to_sb(fop);
+	rdom = m0t1fs_rmsvc_domain_get(&sb->csb_reqh);
+	file = m0_resource_to_file(&rw->crw_gfid, rdom->rd_types[M0_RM_FLOCK_RT]);
 	if (file->fi_di_ops->do_out_shift(file) == 0)
 		return 0;
 	bsize = M0_BITS(file->fi_di_ops->do_in_shift(file));
@@ -1282,6 +1296,7 @@ cleanup:
 		--i;
 	}
 	return -ENOMEM;
+#endif
 }
 
 static void io_fop_bulkbuf_move(struct m0_fop *src, struct m0_fop *dest)
@@ -1360,6 +1375,7 @@ M0_INTERNAL int m0_io_fop_prepare(struct m0_fop *fop)
 	int		       rc;
 	struct m0_rpc_bulk    *rbulk;
 	enum m0_net_queue_type q;
+	M0_ENTRY();
 
 	M0_PRE(fop != NULL);
 	M0_PRE(m0_is_io_fop(fop));
@@ -1387,7 +1403,7 @@ M0_INTERNAL int m0_io_fop_prepare(struct m0_fop *fop)
 		rc = io_fop_di_prepare(fop);
 err:
 	m0_mutex_unlock(&rbulk->rb_mutex);
-	return rc;
+	return M0_RC(rc);
 }
 
 /*
diff --git a/ioservice/ut/bulkio_client.c b/ioservice/ut/bulkio_client.c
index 10fc933..bad350e 100644
--- a/ioservice/ut/bulkio_client.c
+++ b/ioservice/ut/bulkio_client.c
@@ -26,6 +26,7 @@
 #include "rpc/rpc.h"		/* m0_rpc_bulk, m0_rpc_bulk_buf */
 #include "net/lnet/lnet.h"
 #include "file/file.h"
+#include "lib/finject.h"
 
 #ifdef __KERNEL__
 #include "m0t1fs/linux_kernel/m0t1fs.h"
@@ -151,20 +152,20 @@ static void bulkclient_test(void)
 	struct m0_rm_domain     *rm_dom;
 	struct m0_file           file;
 
+	struct m0_rm_resource_type flock_rt = {
+		.rt_name = "File Lock Resource Type"
+	};
+
 	M0_ALLOC_PTR(iofop);
 	M0_ASSERT(iofop != NULL);
 	M0_SET0(iofop);
 	M0_SET0(&nd);
 
-#ifndef __KERNEL__
 	M0_ALLOC_PTR(rm_dom);
 	M0_ASSERT(rm_dom != NULL);
 	m0_rm_domain_init(rm_dom);
-	rc = m0_file_lock_type_register(rm_dom);
+	rc = m0_file_lock_type_register(rm_dom, &flock_rt);
 	M0_ASSERT(rc == 0);
-#else
-	rm_dom = m0t1fs_rmsvc_domain_get();
-#endif
 
 	xprt = &m0_net_lnet_xprt;
 	rc = m0_net_domain_init(&nd, xprt, &m0_addb_proc_ctx);
@@ -263,6 +264,9 @@ static void bulkclient_test(void)
 	M0_UT_ASSERT(!rbuf1->bb_flags & M0_RPC_BULK_NETBUF_ALLOCATED);
 
 	M0_UT_ASSERT(rbuf->bb_nbuf != NULL);
+	/* In normal code path, an io_request is allocated. io_request embeds io_fop.
+	 * In this UT, only io_fop is allocated here. So, skip di_prepare here. */
+	m0_fi_enable("io_fop_di_prepare", "skip_di_for_ut");
 	rc = m0_io_fop_prepare(&iofop->if_fop);
 	M0_UT_ASSERT(rc == 0);
 	rw = io_rw_get(&iofop->if_fop);
@@ -411,11 +415,9 @@ static void bulkclient_test(void)
 	m0_free(iofop);
 	m0_net_domain_fini(&nd);
 	m0_file_fini(&file);
-#ifndef __KERNEL__
-	m0_file_lock_type_deregister();
+	m0_file_lock_type_deregister(&flock_rt);
 	m0_rm_domain_fini(rm_dom);
 	m0_free(rm_dom);
-#endif
 }
 
 const struct m0_test_suite bulkio_client_ut = {
diff --git a/ioservice/ut/bulkio_common.c b/ioservice/ut/bulkio_common.c
index e47c83b..059d7a3 100644
--- a/ioservice/ut/bulkio_common.c
+++ b/ioservice/ut/bulkio_common.c
@@ -397,8 +397,11 @@ void bulkio_params_init(struct bulkio_params *bp)
 	bp->bp_rfops = NULL;
 	bp->bp_wfops = NULL;
 
+	bp->bp_flock_rt.rt_name = "File Lock Resource Type";
+
 	m0_rm_domain_init(&bp->bp_rdom);
-	rc = m0_file_lock_type_register(&bp->bp_rdom);
+	rc = m0_file_lock_type_register(&bp->bp_rdom, &bp->bp_flock_rt);
+
 	M0_ASSERT(rc == 0);
 
 }
@@ -430,7 +433,7 @@ void bulkio_params_fini(struct bulkio_params *bp)
 
 	m0_free(bp->bp_cdbname);
 	m0_free(bp->bp_slogfile);
-	m0_file_lock_type_deregister();
+	m0_file_lock_type_deregister(&bp->bp_flock_rt);
 	m0_rm_domain_fini(&bp->bp_rdom);
 }
 
diff --git a/ioservice/ut/bulkio_common.h b/ioservice/ut/bulkio_common.h
index 296155d..0549d8e 100644
--- a/ioservice/ut/bulkio_common.h
+++ b/ioservice/ut/bulkio_common.h
@@ -105,6 +105,7 @@ struct bulkio_params {
 	struct m0_net_xprt		 *bp_xprt;
 
 	struct m0_rm_domain		 bp_rdom;
+	struct m0_rm_resource_type       bp_flock_rt;
 	struct m0_file			 bp_file[IO_FIDS_NR];
 };
 
diff --git a/layout/layout.c b/layout/layout.c
index 493f252..4262831 100644
--- a/layout/layout.c
+++ b/layout/layout.c
@@ -770,7 +770,6 @@ M0_INTERNAL int m0_layout_type_register(struct m0_layout_domain *dom,
 	M0_PRE(m0_layout__domain_invariant(dom));
 	M0_PRE(lt != NULL);
 	M0_PRE(IS_IN_ARRAY(lt->lt_id, dom->ld_type));
-	M0_PRE(lt->lt_ref_count == 0);
 	M0_PRE(lt->lt_ops != NULL);
 
 	M0_ENTRY("Layout-type-id %lu, domain %p",
@@ -809,7 +808,6 @@ M0_INTERNAL void m0_layout_type_unregister(struct m0_layout_domain *dom,
 	M0_ENTRY("Layout-type-id %lu, domain %p",
 		 (unsigned long)lt->lt_id, dom);
 	m0_mutex_lock(&dom->ld_lock);
-	M0_PRE(lt->lt_ref_count == 0);
 	lt->lt_ops->lto_unregister(dom, lt);
 	dom->ld_type[lt->lt_id] = NULL;
 	max_recsize_update(dom);
@@ -825,7 +823,6 @@ M0_INTERNAL int m0_layout_enum_type_register(struct m0_layout_domain *dom,
 	M0_PRE(m0_layout__domain_invariant(dom));
 	M0_PRE(let != NULL);
 	M0_PRE(IS_IN_ARRAY(let->let_id, dom->ld_enum));
-	M0_PRE(let->let_ref_count == 0);
 	M0_PRE(let->let_ops != NULL);
 
 	M0_ENTRY("Enum_type_id %lu, domain %p",
@@ -863,7 +860,6 @@ M0_INTERNAL void m0_layout_enum_type_unregister(struct m0_layout_domain *dom,
 	M0_ENTRY("Enum_type_id %lu, domain %p",
 		 (unsigned long)let->let_id, dom);
 	m0_mutex_lock(&dom->ld_lock);
-	M0_PRE(let->let_ref_count == 0);
 	let->let_ops->leto_unregister(dom, let);
 	dom->ld_enum[let->let_id] = NULL;
 	max_recsize_update(dom);
diff --git a/layout/ut/layout.c b/layout/ut/layout.c
index a997b6a..cd32f1c 100644
--- a/layout/ut/layout.c
+++ b/layout/ut/layout.c
@@ -88,23 +88,6 @@ static int test_init(void)
 	rc = m0_layout_domain_init(&domain, &dbenv);
 	M0_ASSERT(rc == 0);
 
-#ifdef __KERNEL__
-	/*
-	 * A layout type can be registered with only one domain at a time.
-	 * As a part of the kernel UT, all the available layout types and enum
-	 * types have been registered with the domain
-	 * "m0t1fs_globals.g_layout_dom".
-	 * (This happpens during the module load operation, by performing
-	 * m0_layout_standard_types_register(&m0t1fs_globals.g_layout_dom)
-	 * through m0t1fs_init()). Hence, performing
-	 * m0_layout_standard_types_unregister(&m0t1fs_globals.g_layout_dom)
-	 * here to temporarily unregister all the available layout types and
-	 * enum types from the domain "m0t1fs_globals.g_layout_dom". Those will
-	 * be registered back in test_fini().
-	 */
-	m0_layout_standard_types_unregister(&m0t1fs_globals.g_layout_dom);
-#endif
-
 	/* Register all the standard layout types and enum types. */
 	rc = m0_layout_standard_types_register(&domain);
 	M0_ASSERT(rc == 0);
@@ -115,11 +98,6 @@ static int test_init(void)
 static int test_fini(void)
 {
 	m0_layout_standard_types_unregister(&domain);
-
-#ifdef __KERNEL__
-	m0_layout_standard_types_register(&m0t1fs_globals.g_layout_dom);
-#endif
-
 	m0_layout_domain_fini(&domain);
 	m0_dbenv_fini(&dbenv);
 
diff --git a/lib/bitmap.c b/lib/bitmap.c
index ba5861e..205adef 100644
--- a/lib/bitmap.c
+++ b/lib/bitmap.c
@@ -104,6 +104,19 @@ M0_INTERNAL bool m0_bitmap_get(const struct m0_bitmap *map, size_t idx)
 }
 M0_EXPORTED(m0_bitmap_get);
 
+M0_INTERNAL size_t m0_bitmap_ffz(const struct m0_bitmap *map)
+{
+	size_t idx;
+
+	/* use linux find_first_zero_bit() ? */
+	for (idx = 0; idx < map->b_nr; idx++) {
+		if (!m0_bitmap_get(map, idx))
+			return idx;
+	}
+	return -1;
+}
+M0_EXPORTED(m0_bitmap_ffz);
+
 M0_INTERNAL void m0_bitmap_set(struct m0_bitmap *map, size_t idx, bool val)
 {
 	M0_ASSERT(idx < map->b_nr && map->b_words != NULL);
diff --git a/lib/bitmap.h b/lib/bitmap.h
index 3e5cfca..b4565cc 100644
--- a/lib/bitmap.h
+++ b/lib/bitmap.h
@@ -85,6 +85,14 @@ M0_INTERNAL void m0_bitmap_fini(struct m0_bitmap *map);
 M0_INTERNAL bool m0_bitmap_get(const struct m0_bitmap *map, size_t idx);
 
 /**
+   Find first zero (a.k.a unset, false) bit from a bitmap.
+
+   @param map bitmap to query
+   @return index of the first zero bit. If no zero bit found, -1 is returned.
+ */
+M0_INTERNAL size_t m0_bitmap_ffz(const struct m0_bitmap *map);
+
+/**
    Set a bit value in a bitmap.
 
    @param map bitmap to modify
diff --git a/m0t1fs/linux_kernel/dir.c b/m0t1fs/linux_kernel/dir.c
index 8fa2a16..55f3491 100644
--- a/m0t1fs/linux_kernel/dir.c
+++ b/m0t1fs/linux_kernel/dir.c
@@ -279,6 +279,7 @@ static int m0t1fs_create(struct inode     *dir,
 	struct m0t1fs_inode      *ci;
 	struct m0t1fs_mdop        mo;
 	struct inode             *inode;
+	struct m0_fid             new_fid;
 	int                       rc;
 
 	M0_ENTRY();
@@ -287,13 +288,13 @@ static int m0t1fs_create(struct inode     *dir,
 	       dentry->d_name.name, dir->i_ino,
 	       FID_P(m0t1fs_inode_fid(M0T1FS_I(dir))));
 
-	/* new_inode() will call m0t1fs_alloc_inode() using super_operations */
-	inode = new_inode(sb);
+	m0t1fs_fid_alloc(csb, &new_fid);
+	inode = iget_locked(sb, fid_hash(&new_fid));
 	if (inode == NULL)
 		return M0_RC(-ENOMEM);
 	ci = M0T1FS_I(inode);
 	m0t1fs_fs_lock(csb);
-	m0t1fs_fid_alloc(csb, &ci->ci_fid);
+	ci->ci_fid = new_fid;
 
 	inode->i_mode = mode;
 	inode->i_uid = current_fsuid();
@@ -316,9 +317,8 @@ static int m0t1fs_create(struct inode     *dir,
 
 	ci->ci_layout_id = csb->csb_layout_id; /* layout id for new file */
 	m0t1fs_file_lock_init(ci, csb);
-
-	insert_inode_hash(inode);
-	mark_inode_dirty(inode);
+	if ((inode->i_state & I_NEW) != 0)
+		unlock_new_inode(inode);
 
 	rc = m0t1fs_inode_layout_init(ci);
 	if (rc != 0)
@@ -986,7 +986,8 @@ out:
 	return rc;
 }
 
-static int m0t1fs_mds_cob_fop_populate(const struct m0t1fs_mdop *mo,
+static int m0t1fs_mds_cob_fop_populate(struct m0t1fs_sb         *csb,
+				       const struct m0t1fs_mdop *mo,
 				       struct m0_fop            *fop)
 {
 	struct m0_fop_create    *create;
@@ -1082,7 +1083,7 @@ static int m0t1fs_mds_cob_fop_populate(const struct m0t1fs_mdop *mo,
 			 * for any type of layout.
 			 */
 			layout->l_buf.b_count = m0_layout_max_recsize(
-						&m0t1fs_globals.g_layout_dom);
+						&csb->csb_layout_dom);
 			layout->l_buf.b_addr = m0_alloc(layout->l_buf.b_count);
 			if (layout->l_buf.b_addr == NULL) {
 				rc = -ENOMEM;
@@ -1191,7 +1192,7 @@ static int m0t1fs_mds_cob_op(struct m0t1fs_sb            *csb,
 		goto out;
 	}
 
-	rc = m0t1fs_mds_cob_fop_populate(mo, fop);
+	rc = m0t1fs_mds_cob_fop_populate(csb, mo, fop);
 	if (rc != 0) {
 		M0_LOG(M0_ERROR,
 		       "m0t1fs_mds_cob_fop_populate() failed with %d", rc);
@@ -1297,7 +1298,7 @@ int m0t1fs_layout_op(struct m0t1fs_sb *csb, enum m0_layout_opcode op,
 	struct m0_fop_layout_rep *rep = NULL;
 	int                       rc;
 	struct m0_layout         *layout = NULL;
-	struct m0_layout_domain  *ldom = &m0t1fs_globals.g_layout_dom;
+	struct m0_layout_domain  *ldom = &csb->csb_layout_dom;
 
 	M0_ENTRY();
 
diff --git a/m0t1fs/linux_kernel/file.c b/m0t1fs/linux_kernel/file.c
index d609f57..24cd160 100644
--- a/m0t1fs/linux_kernel/file.c
+++ b/m0t1fs/linux_kernel/file.c
@@ -44,6 +44,8 @@
 #include "lib/hash.h"	    /* m0_htable */
 #include "sns/parity_repair.h"  /*m0_sns_repair_spare_map() */
 #include "m0t1fs/linux_kernel/file_internal.h"
+#include "m0t1fs/m0t1fs_addb.h"
+
 
 /**
    @page iosnsrepair I/O with SNS and SNS repair.
@@ -3342,7 +3344,7 @@ static int ioreq_iosm_handle(struct io_request *req)
 	struct inode	    *inode;
 	struct target_ioreq *ti;
 
-	M0_ENTRY("io_request %p", req);
+	M0_ENTRY("io_request %p sb = %p", req, file_to_sb(req->ir_file));
 	M0_PRE_EX(io_request_invariant(req));
 
 	for (map = 0; map < req->ir_iomap_nr; ++map) {
@@ -4686,6 +4688,19 @@ static void failure_vector_mismatch(struct io_req_fop *irfop)
 	M0_LOG(M0_DEBUG, "<<<VERSION MISMATCH!");
 }
 
+M0_INTERNAL struct m0t1fs_sb *m0_fop_to_sb(struct m0_fop *fop)
+{
+	struct m0_io_fop  *iofop;
+	struct io_req_fop *irfop;
+	struct io_request *ioreq;
+
+	iofop = container_of(fop, struct m0_io_fop, if_fop);
+	irfop = bob_of(iofop, struct io_req_fop, irf_iofop, &iofop_bobtype);
+	ioreq  = bob_of(irfop->irf_tioreq->ti_nwxfer, struct io_request,
+			ir_nwxfer, &ioreq_bobtype);
+	return file_to_sb(ioreq->ir_file);
+}
+
 static void io_bottom_half(struct m0_sm_group *grp, struct m0_sm_ast *ast)
 {
 	int                         rc;
@@ -4982,11 +4997,15 @@ static inline uint32_t io_seg_size(void)
 	return sizeof(struct m0_ioseg);
 }
 
-static inline uint32_t io_di_size(const struct io_request *req)
+static uint32_t io_di_size(const struct io_request *req)
 {
-	struct m0_file *file;
+	struct m0_file      *file;
+	struct m0t1fs_sb    *sb;
+	struct m0_rm_domain *rdom;
 
-	file = m0_resource_to_file(file_to_fid(req->ir_file));
+	sb = file_to_sb(req->ir_file);
+	rdom = m0t1fs_rmsvc_domain_get(&sb->csb_reqh);
+	file = m0_resource_to_file(file_to_fid(req->ir_file), rdom->rd_types[M0_RM_FLOCK_RT]);
 	if (file->fi_di_ops->do_out_shift(file) == 0)
 		return 0;
 	return file->fi_di_ops->do_out_shift(file) * M0_DI_ELEMENT_SIZE;
diff --git a/m0t1fs/linux_kernel/inode.c b/m0t1fs/linux_kernel/inode.c
index 264e51f..69ee9b2 100644
--- a/m0t1fs/linux_kernel/inode.c
+++ b/m0t1fs/linux_kernel/inode.c
@@ -98,11 +98,11 @@ M0_INTERNAL void m0t1fs_inode_cache_fini(void)
 	M0_LEAVE();
 }
 
-M0_INTERNAL struct m0_rm_domain *m0t1fs_rmsvc_domain_get(void)
+M0_INTERNAL struct m0_rm_domain *m0t1fs_rmsvc_domain_get(struct m0_reqh *reqh)
 {
 	return m0_rm_svc_domain_get(
 		m0_reqh_service_find(m0_reqh_service_type_find("rmservice"),
-				     &m0t1fs_globals.g_reqh));
+				     reqh));
 }
 
 static inline uint64_t m0t1fs_rm_container(const struct m0t1fs_sb *csb)
@@ -111,7 +111,7 @@ static inline uint64_t m0t1fs_rm_container(const struct m0t1fs_sb *csb)
 }
 
 M0_INTERNAL void m0t1fs_file_lock_init(struct m0t1fs_inode    *ci,
-				       const struct m0t1fs_sb *csb)
+				       struct m0t1fs_sb *csb)
 {
 	struct m0_rm_domain *rdom;
 	const struct m0_fid *fid = &ci->ci_fid;
@@ -119,7 +119,7 @@ M0_INTERNAL void m0t1fs_file_lock_init(struct m0t1fs_inode    *ci,
 	M0_ENTRY();
 
 	M0_LOG(M0_INFO, FID_F, FID_P(fid));
-	rdom = m0t1fs_rmsvc_domain_get();
+	rdom = m0t1fs_rmsvc_domain_get(&csb->csb_reqh);
 	M0_ASSERT(rdom != NULL);
 	/**
 	 * @todo Get di type from configuration.
@@ -138,6 +138,7 @@ M0_INTERNAL void m0t1fs_file_lock_init(struct m0t1fs_inode    *ci,
 M0_INTERNAL void m0t1fs_file_lock_fini(struct m0t1fs_inode *ci)
 {
 	int rc;
+	M0_ENTRY();
 
 	m0_rm_owner_windup(&ci->ci_fowner);
 	rc = m0_rm_owner_timedwait(&ci->ci_fowner, M0_BITS(ROS_FINAL),
@@ -146,6 +147,7 @@ M0_INTERNAL void m0t1fs_file_lock_fini(struct m0t1fs_inode *ci)
 	m0_file_owner_fini(&ci->ci_fowner);
 	m0_file_fini(&ci->ci_flock);
 	m0_rm_remote_fini(&ci->ci_creditor);
+	M0_LEAVE();
 }
 
 static void m0t1fs_inode_init(struct m0t1fs_inode *ci)
@@ -203,7 +205,8 @@ M0_INTERNAL void m0t1fs_destroy_inode(struct inode *inode)
 
 	M0_ENTRY("inode: %p, fid: "FID_F, inode, FID_P(fid));
 	if (m0_fid_is_set(fid) && !m0t1fs_inode_is_root(inode)) {
-		m0_layout_instance_fini(ci->ci_layout_instance);
+		if (ci->ci_layout_instance != NULL)
+			m0_layout_instance_fini(ci->ci_layout_instance);
 		m0t1fs_file_lock_fini(ci);
 	}
 	m0t1fs_inode_fini(ci);
@@ -353,7 +356,7 @@ out:
 /**
    XXX Temporary implementation of simple hash on fid
  */
-static unsigned long fid_hash(const struct m0_fid *fid)
+unsigned long fid_hash(const struct m0_fid *fid)
 {
 	M0_ENTRY();
 	M0_LEAVE("hash: %lu", (unsigned long) fid->f_key);
@@ -416,7 +419,7 @@ static int m0t1fs_build_layout_instance(struct m0t1fs_sb           *csb,
 	M0_PRE(fid != NULL);
 	M0_PRE(linst != NULL);
 
-	layout = m0_layout_find(&m0t1fs_globals.g_layout_dom, layout_id);
+	layout = m0_layout_find(&csb->csb_layout_dom, layout_id);
 	if (layout == NULL) {
 		rc = m0t1fs_layout_op(csb, M0_LAYOUT_OP_LOOKUP,
 				      layout_id, &layout);
diff --git a/m0t1fs/linux_kernel/m0t1fs.c b/m0t1fs/linux_kernel/m0t1fs.c
index b9ef430..0f963ec 100644
--- a/m0t1fs/linux_kernel/m0t1fs.c
+++ b/m0t1fs/linux_kernel/m0t1fs.c
@@ -26,48 +26,38 @@
 #define M0_TRACE_SUBSYSTEM M0_TRACE_SUBSYS_M0T1FS
 #include "lib/trace.h"  /* M0_LOG and M0_ENTRY */
 #include "lib/memory.h"
-#include "lib/uuid.h"   /* m0_uuid_generate */
-#include "net/lnet/lnet.h"
 #include "fid/fid.h"
 #include "ioservice/io_fops.h"
 #include "mdservice/md_fops.h"
 #include "rpc/rpclib.h"
 #include "rm/rm.h"
+#include "net/lnet/lnet_core_types.h"
+
+#include "m0t1fs/m0t1fs_addb.h"
 
 static char *node_uuid = "00000000-0000-0000-0000-000000000000"; /* nil UUID */
 module_param(node_uuid, charp, S_IRUGO);
 MODULE_PARM_DESC(node_uuid, "UUID of Mero node");
 
-static char *local_addr = "0@lo:12345:45:6";
+char *local_addr = "0@lo:12345:45:";
 
 module_param(local_addr, charp, S_IRUGO);
 MODULE_PARM_DESC(local_addr, "End-point address of m0t1fs "
-		 "e.g. 172.18.50.40@o2ib1:12345:34:1");
+		 "e.g. 172.18.50.40@o2ib1:12345:34:\n"
+		 "the tmid will be generated and filled by every mount");
 
-static uint32_t tm_recv_queue_min_len = M0_NET_TM_RECV_QUEUE_DEF_LEN;
+uint32_t tm_recv_queue_min_len = M0_NET_TM_RECV_QUEUE_DEF_LEN;
 module_param(tm_recv_queue_min_len , int, S_IRUGO);
 MODULE_PARM_DESC(tm_recv_queue_min_len, "TM receive queue minimum length");
 
-static uint32_t max_rpc_msg_size = M0_RPC_DEF_MAX_RPC_MSG_SIZE;
+uint32_t max_rpc_msg_size = M0_RPC_DEF_MAX_RPC_MSG_SIZE;
 module_param(max_rpc_msg_size, int, S_IRUGO);
 MODULE_PARM_DESC(max_rpc_msg_size, "Maximum RPC message size");
 
-static int  m0t1fs_net_init(void);
-static void m0t1fs_net_fini(void);
-
-static int  m0t1fs_rpc_init(void);
-static void m0t1fs_rpc_fini(void);
-
-static int  m0t1fs_addb_mon_total_io_size_init(void);
-static void m0t1fs_addb_mon_total_io_size_fini(void);
-
-static int  m0t1fs_layout_init(void);
-static void m0t1fs_layout_fini(void);
-
-static int m0t1fs_reqh_services_start(void);
-static void m0t1fs_reqh_services_stop(void);
-
 struct m0_addb_ctx m0t1fs_addb_ctx;
+struct m0_bitmap   m0t1fs_client_ep_tmid;
+struct m0_mutex    m0t1fs_mutex;
+uint32_t           m0t1fs_addb_mon_rw_io_size_key;
 
 static struct file_system_type m0t1fs_fs_type = {
 	.owner        = THIS_MODULE,
@@ -79,11 +69,6 @@ static struct file_system_type m0t1fs_fs_type = {
 
 #define M0T1FS_DB_NAME "m0t1fs.db"
 
-struct m0t1fs_globals m0t1fs_globals = {
-	.g_xprt       = &m0_net_lnet_xprt,
-	.g_db_name    = M0T1FS_DB_NAME,
-};
-
 M0_INTERNAL const char *m0t1fs_param_node_uuid_get(void)
 {
 	return node_uuid;
@@ -116,12 +101,20 @@ M0_INTERNAL int m0t1fs_init(void)
 
 	M0_ADDB_MONITOR_STATS_TYPE_REGISTER(&m0_addb_rt_m0t1fs_mon_io_size,
 					    "io_size");
-
-	m0t1fs_globals.g_laddr = local_addr;
+	m0t1fs_addb_mon_rw_io_size_key = m0_reqh_lockers_allot();
+	m0_mutex_init(&m0t1fs_mutex);
+	/*
+	 * [0 - M0_NET_LNET_TMID_MAX / 2] for clients.
+	 * [M0_NET_LNET_TMID_MAX / 2 - M0_NET_LNET_TMID_MAX] for server ep.
+	 */
+	rc = m0_bitmap_init(&m0t1fs_client_ep_tmid, M0_NET_LNET_TMID_MAX / 2);
+	if (rc != 0)
+		goto out;
+	m0_bitmap_set(&m0t1fs_client_ep_tmid, 0, true);
 
 	rc = m0_ioservice_fop_init();
 	if (rc != 0)
-		goto out;
+		goto out_bitmap;
 
 	rc = m0_mdservice_fop_init();
 	if (rc != 0)
@@ -131,43 +124,22 @@ M0_INTERNAL int m0t1fs_init(void)
 	if (rc != 0)
 		goto mdservice_fini;
 
-	rc = m0t1fs_net_init();
-	if (rc != 0)
-		goto icache_fini;
-
-	rc = m0t1fs_rpc_init();
-	if (rc != 0)
-		goto net_fini;
-
-	rc = m0t1fs_addb_mon_total_io_size_init();
-	if (rc != 0)
-		goto rpc_fini;
-
-	rc = m0t1fs_layout_init();
-	if (rc != 0)
-		goto addb_mon_fini;
-
 	rc = register_filesystem(&m0t1fs_fs_type);
 	if (rc != 0)
-		goto layout_fini;
+		goto icache_fini;
 
 	M0_LEAVE("rc: 0");
 	return 0;
 
-layout_fini:
-	m0t1fs_layout_fini();
-addb_mon_fini:
-	m0t1fs_addb_mon_total_io_size_fini();
-rpc_fini:
-	m0t1fs_rpc_fini();
-net_fini:
-	m0t1fs_net_fini();
 icache_fini:
 	m0t1fs_inode_cache_fini();
 mdservice_fini:
         m0_mdservice_fop_fini();
 ioservice_fini:
         m0_ioservice_fop_fini();
+out_bitmap:
+	m0_bitmap_fini(&m0t1fs_client_ep_tmid);
+	m0_mutex_fini(&m0t1fs_mutex);
 out:
 	m0_addb_ctx_fini(&m0t1fs_addb_ctx);
 
@@ -182,295 +154,14 @@ M0_INTERNAL void m0t1fs_fini(void)
 
 	(void)unregister_filesystem(&m0t1fs_fs_type);
 
-	m0t1fs_layout_fini();
-	m0t1fs_rpc_fini();
-	m0t1fs_net_fini();
 	m0t1fs_inode_cache_fini();
 	m0_mdservice_fop_fini();
 	m0_ioservice_fop_fini();
 
+	m0_bitmap_fini(&m0t1fs_client_ep_tmid);
+	m0_mutex_fini(&m0t1fs_mutex);
 	m0_addb_ctx_fini(&m0t1fs_addb_ctx);
 
 	M0_LEAVE();
 }
-
-static int m0t1fs_net_init(void)
-{
-	struct m0_net_xprt   *xprt;
-	struct m0_net_domain *ndom;
-	int		      rc;
-
-	M0_ENTRY();
-
-	xprt =  m0t1fs_globals.g_xprt;
-	ndom = &m0t1fs_globals.g_ndom;
-
-	rc = m0_net_xprt_init(xprt);
-	if (rc != 0)
-		goto out;
-
-	/** @todo replace &m0_addb_proc_ctx */
-	rc = m0_net_domain_init(ndom, xprt, &m0_addb_proc_ctx);
-	if (rc != 0)
-		m0_net_xprt_fini(xprt);
-out:
-	M0_LEAVE("rc: %d", rc);
-	return rc;
-}
-
-static void m0t1fs_net_fini(void)
-{
-	M0_ENTRY();
-
-	m0_net_domain_fini(&m0t1fs_globals.g_ndom);
-	m0_net_xprt_fini(m0t1fs_globals.g_xprt);
-
-	M0_LEAVE();
-}
-
-static int m0t1fs_rpc_init(void)
-{
-	struct m0_dbenv           *dbenv       = &m0t1fs_globals.g_dbenv;
-	char                      *db_name     =  m0t1fs_globals.g_db_name;
-	struct m0_rpc_machine     *rpc_machine = &m0t1fs_globals.g_rpc_machine;
-	struct m0_reqh            *reqh        = &m0t1fs_globals.g_reqh;
-	struct m0_net_domain      *ndom        = &m0t1fs_globals.g_ndom;
-	const char                *laddr       =  m0t1fs_globals.g_laddr;
-	struct m0_net_buffer_pool *buffer_pool = &m0t1fs_globals.g_buffer_pool;
-	struct m0_fol             *fol         = &m0t1fs_globals.g_fol;
-	struct m0_net_transfer_mc *tm;
-	int                        rc;
-	uint32_t		   bufs_nr;
-	uint32_t		   tms_nr;
-
-	M0_ENTRY();
-
-	tms_nr	 = 1;
-	bufs_nr  = m0_rpc_bufs_nr(tm_recv_queue_min_len, tms_nr);
-
-	rc = m0_rpc_net_buffer_pool_setup(ndom, buffer_pool,
-					  bufs_nr, tms_nr);
-	if (rc != 0)
-		goto pool_fini;
-
-	rc = m0_dbenv_init(dbenv, db_name, 0);
-	if (rc != 0)
-		goto pool_fini;
-
-	rc = M0_REQH_INIT(reqh,
-			  .rhia_dtm          = (void*)1,
-			  .rhia_db           = NULL,
-			  .rhia_mdstore      = (void*)1,
-			  .rhia_fol          = fol,
-			  .rhia_svc          = (void*)1);
-	if (rc != 0)
-		goto dbenv_fini;
-	rc = m0_rpc_machine_init(rpc_machine, ndom, laddr, reqh,
-				 buffer_pool, M0_BUFFER_ANY_COLOUR,
-				 max_rpc_msg_size, tm_recv_queue_min_len);
-	if (rc != 0)
-		goto reqh_fini;
-
-	m0_reqh_start(reqh);
-	tm = &rpc_machine->rm_tm;
-	M0_ASSERT(tm->ntm_recv_pool == buffer_pool);
-
-	m0_reqh_rpc_mach_tlink_init_at_tail(rpc_machine,
-					    &reqh->rh_rpc_machines);
-
-	/* Start resource manager service */
-	rc = m0t1fs_reqh_services_start();
-	if (rc != 0)
-		goto reqh_fini;
-	return M0_RC(0);
-
-reqh_fini:
-	m0_reqh_fini(reqh);
-dbenv_fini:
-	m0_dbenv_fini(dbenv);
-pool_fini:
-	m0_rpc_net_buffer_pool_cleanup(buffer_pool);
-	M0_LEAVE("rc: %d", rc);
-	M0_ASSERT(rc != 0);
-	return rc;
-}
-
-static void m0t1fs_mon_rw_io_watch(const struct m0_addb_monitor *mon,
-				   const struct m0_addb_rec     *rec,
-				   struct m0_reqh               *reqh)
-{
-	struct m0_addb_sum_rec                  *sum_rec;
-	struct m0t1fs_addb_mon_sum_data_io_size *sum_data =
-				&m0t1fs_globals.g_addb_mon_sum_data_rw_io_size;
-
-	if (m0_addb_rec_rid_make(M0_ADDB_BRT_DP, M0T1FS_ADDB_RECID_IO_FINISH)
-	    == rec->ar_rid) {
-		sum_rec = mon->am_ops->amo_sum_rec(mon, reqh);
-		M0_ASSERT(sum_rec != NULL);
-
-		m0_mutex_lock(&sum_rec->asr_mutex);
-		if (rec->ar_data.au64s_data[0] == IRT_READ) {
-			sum_data->sd_rio += rec->ar_data.au64s_data[1];
-			sum_rec->asr_dirty = true;
-		} else if (rec->ar_data.au64s_data[0] == IRT_WRITE) {
-			sum_data->sd_wio += rec->ar_data.au64s_data[1];
-			sum_rec->asr_dirty = true;
-		}
-		else
-			M0_IMPOSSIBLE("Invalid IO state");
-		m0_mutex_unlock(&sum_rec->asr_mutex);
-
-	}
-}
-
-static struct m0_addb_sum_rec *
-m0t1fs_mon_rw_io_sum_rec(const struct m0_addb_monitor *mon,
-		         struct m0_reqh               *reqh)
-{
-	struct m0_addb_sum_rec *sum_rec;
-
-	m0_rwlock_read_lock(&reqh->rh_rwlock);
-	sum_rec = m0_reqh_lockers_get(reqh,
-			m0t1fs_globals.g_addb_mon_rw_io_size_key);
-	m0_rwlock_read_unlock(&reqh->rh_rwlock);
-
-	return sum_rec;
-}
-
-const struct m0_addb_monitor_ops m0t1fs_addb_mon_rw_io_ops = {
-	.amo_watch   = m0t1fs_mon_rw_io_watch,
-	.amo_sum_rec = m0t1fs_mon_rw_io_sum_rec
-};
-
-static int m0t1fs_addb_mon_total_io_size_init(void)
-{
-	struct m0_addb_sum_rec *sum_rec;
-	struct m0_reqh         *reqh = &m0t1fs_globals.g_reqh;
-	uint32_t               *key = &m0t1fs_globals.g_addb_mon_rw_io_size_key;
-	uint64_t               *sum_data =
-		     (uint64_t *)&m0t1fs_globals.g_addb_mon_sum_data_rw_io_size;
-	uint32_t                sum_rec_nr =
-		     sizeof (m0t1fs_globals.g_addb_mon_sum_data_rw_io_size) /
-					     sizeof (uint64_t);
-	M0_ALLOC_PTR(sum_rec);
-	if (sum_rec == NULL)
-		return M0_RC(-ENOMEM);
-
-	m0_addb_monitor_init(&m0t1fs_globals.g_addb_mon_rw_io_size,
-			     &m0t1fs_addb_mon_rw_io_ops);
-
-	m0_addb_monitor_sum_rec_init(sum_rec, &m0_addb_rt_m0t1fs_mon_io_size,
-				     sum_data, sum_rec_nr);
-
-	*key = m0_reqh_lockers_allot();
-
-	m0_rwlock_write_lock(&reqh->rh_rwlock);
-	m0_reqh_lockers_set(reqh, *key, sum_rec);
-	m0_rwlock_write_unlock(&reqh->rh_rwlock);
-
-	m0_addb_monitor_add(reqh, &m0t1fs_globals.g_addb_mon_rw_io_size);
-
-	return 0;
-}
-
-static void m0t1fs_addb_mon_total_io_size_fini(void)
-{
-	struct m0_addb_sum_rec *sum_rec;
-	struct m0_addb_monitor *mon = &m0t1fs_globals.g_addb_mon_rw_io_size;
-	struct m0_reqh         *reqh = &m0t1fs_globals.g_reqh;
-
-	sum_rec = mon->am_ops->amo_sum_rec(mon, &m0t1fs_globals.g_reqh);
-
-	m0_addb_monitor_del(reqh, mon);
-
-	m0_rwlock_write_lock(&reqh->rh_rwlock);
-	m0_reqh_lockers_clear(reqh, m0t1fs_globals.g_addb_mon_rw_io_size_key);
-	m0_rwlock_write_unlock(&reqh->rh_rwlock);
-	m0_addb_monitor_sum_rec_fini(sum_rec);
-	m0_free(sum_rec);
-	m0_addb_monitor_fini(mon);
-}
-
-static void m0t1fs_rpc_fini(void)
-{
-	M0_ENTRY();
-
-	m0t1fs_reqh_services_stop();
-	m0_reqh_rpc_mach_tlink_del_fini(&m0t1fs_globals.g_rpc_machine);
-	m0_rpc_machine_fini(&m0t1fs_globals.g_rpc_machine);
-	m0_reqh_fini(&m0t1fs_globals.g_reqh);
-	m0_dbenv_fini(&m0t1fs_globals.g_dbenv);
-	m0_rpc_net_buffer_pool_cleanup(&m0t1fs_globals.g_buffer_pool);
-
-	M0_LEAVE();
-}
-
-static int m0t1fs_layout_init(void)
-{
-	int rc;
-
-	M0_ENTRY();
-
-	rc = m0_layout_domain_init(&m0t1fs_globals.g_layout_dom,
-				   &m0t1fs_globals.g_dbenv);
-	if (rc == 0) {
-		rc = m0_layout_standard_types_register(
-						&m0t1fs_globals.g_layout_dom);
-		if (rc != 0)
-			m0_layout_domain_fini(&m0t1fs_globals.g_layout_dom);
-	}
-
-	return M0_RC(rc);
-}
-
-static void m0t1fs_layout_fini(void)
-{
-	M0_ENTRY();
-
-	m0_layout_standard_types_unregister(&m0t1fs_globals.g_layout_dom);
-	m0_layout_domain_fini(&m0t1fs_globals.g_layout_dom);
-
-	M0_LEAVE();
-}
-
-static int m0t1fs_service_start(const char *sname)
-{
-	int                          rc;
-	struct m0_reqh              *reqh = &m0t1fs_globals.g_reqh;
-	struct m0_reqh_service_type *stype;
-	struct m0_reqh_service      *service;
-	struct m0_uint128            uuid;
-
-	stype = m0_reqh_service_type_find(sname);
-	if (stype == NULL)
-		return M0_RC(-EINVAL);
-	rc = m0_reqh_service_allocate(&service, stype, NULL);
-	if (rc != 0)
-		return M0_RC(rc);
-	m0_uuid_generate(&uuid);
-	m0_reqh_service_init(service, reqh, &uuid);
-	rc = m0_reqh_service_start(service);
-
-	return M0_RC(rc);
-}
-
-static int m0t1fs_reqh_services_start(void)
-{
-	int rc;
-
-	rc = m0t1fs_service_start(M0_ADDB_SVC_NAME);
-	if (rc)
-		goto err;
-	rc = m0t1fs_service_start("rmservice");
-	if (rc)
-		goto err;
-	return M0_RC(rc);
-err:
-	m0t1fs_reqh_services_stop();
-	return M0_RC(rc);
-}
-
-static void m0t1fs_reqh_services_stop(void)
-{
-	m0_reqh_services_terminate(&m0t1fs_globals.g_reqh);
-}
+#undef M0_TRACE_SUBSYSTEM
diff --git a/m0t1fs/linux_kernel/m0t1fs.h b/m0t1fs/linux_kernel/m0t1fs.h
index 34a9c0d..6c461a5 100644
--- a/m0t1fs/linux_kernel/m0t1fs.h
+++ b/m0t1fs/linux_kernel/m0t1fs.h
@@ -40,8 +40,9 @@
 #include "ioservice/io_fops.h"    /* m0_fop_cob_create_fopt */
 #include "mdservice/md_fops.h"    /* m0_fop_create_fopt */
 #include "conf/schema.h"          /* m0_conf_service_type */
-#include "m0t1fs/m0t1fs_addb.h"
 #include "file/file.h"		  /* m0_file */
+#include "be/be.h"
+#include "be/ut/helper.h"
 
 /**
   @defgroup m0t1fs m0t1fs
@@ -419,26 +420,9 @@ enum io_req_type {
         IRT_TYPE_NR,
 };
 
-/** Anything that is global to m0t1fs module goes in this singleton structure.
-    There is only one, global, instance of this type. */
-struct m0t1fs_globals {
-	struct m0_net_xprt                     *g_xprt;
-	/** local endpoint address module parameter */
-	const char                             *g_laddr;
-	char                                   *g_db_name;
-	struct m0_net_domain                    g_ndom;
-	struct m0_rpc_machine                   g_rpc_machine;
-	struct m0_reqh                          g_reqh;
-	struct m0_dbenv                         g_dbenv;
-	struct m0_fol                           g_fol;
-	struct m0_net_buffer_pool               g_buffer_pool;
-	struct m0_layout_domain                 g_layout_dom;
-	struct m0_addb_monitor                  g_addb_mon_rw_io_size;
-	uint32_t                                g_addb_mon_rw_io_size_key;
-	struct m0t1fs_addb_mon_sum_data_io_size g_addb_mon_sum_data_rw_io_size;
-};
-
-extern struct m0t1fs_globals m0t1fs_globals;
+extern char *local_addr;
+extern uint32_t tm_recv_queue_min_len;
+extern uint32_t max_rpc_msg_size;
 
 /**
    For each <mounted_fs, target_service> pair, there is one instance of
@@ -485,79 +469,99 @@ struct m0t1fs_container_location_map {
  */
 struct m0t1fs_sb {
 	/** service context of MGS. Not a member of csb_service_contexts */
-	struct m0t1fs_service_context csb_mgs;
+	struct m0t1fs_service_context          csb_mgs;
 
 	/** number of contexts in csb_service_contexts list, that have
 	    ACTIVE rpc connection and rpc session.
 	    csb_nr_active_contexts <= m0_tlist_length(&csb_service_contexts) */
-	uint32_t                      csb_nr_active_contexts;
+	uint32_t                               csb_nr_active_contexts;
 
 	/** list of m0t1fs_service_context objects hanging using sc_link.
 	    tlist descriptor: svc_ctx_tl */
-	struct m0_tl                  csb_service_contexts;
+	struct m0_tl                            csb_service_contexts;
 
 	/** Total number of containers. */
-	uint32_t                      csb_nr_containers;
+	uint32_t                                csb_nr_containers;
 
 	/** pool width */
-	uint32_t                      csb_pool_width;
+	uint32_t                                csb_pool_width;
 
-	struct m0_pool                csb_pool;
+	struct m0_pool                          csb_pool;
 
 	/** used by temporary implementation of m0t1fs_fid_alloc(). */
-	uint64_t                      csb_next_key;
+	uint64_t                                csb_next_key;
 
 	struct
-	m0t1fs_container_location_map csb_cl_map;
+	m0t1fs_container_location_map           csb_cl_map;
 
 	/** mutex that serialises all file and directory operations */
-	struct m0_mutex               csb_mutex;
+	struct m0_mutex                         csb_mutex;
 
 	/** File layout ID */
-	uint64_t                      csb_layout_id;
+	uint64_t                                csb_layout_id;
 
 	/** Layout for file */
-	struct m0_layout             *csb_file_layout;
+	struct m0_layout                       *csb_file_layout;
 
 	/**
 	 * Flag indicating if m0t1fs mount is active or not.
 	 * Flag is set when m0t1fs is mounted and is reset by unmount thread.
 	 */
-	bool                          csb_active;
+	bool                                    csb_active;
 
 	/**
 	 * Instantaneous count of pending io requests.
 	 * Every io request increments this value while initializing
 	 * and decrements it while finalizing.
 	 */
-	struct m0_atomic64            csb_pending_io_nr;
+	struct m0_atomic64                      csb_pending_io_nr;
 
 	/** Special thread which runs ASTs from io requests. */
-	struct m0_thread              csb_astthread;
+	struct m0_thread                        csb_astthread;
 
 	/**
 	 * Channel on which unmount thread will wait. It will be signalled
 	 * by AST thread while exiting.
 	 */
-	struct m0_chan                csb_iowait;
+	struct m0_chan                          csb_iowait;
 
 	/** State machine group used for all IO requests. */
-	struct m0_sm_group            csb_iogroup;
+	struct m0_sm_group                      csb_iogroup;
 
 	/** Root fid, retrieved from mdservice in mount time. */
-	struct m0_fid                 csb_root_fid;
+	struct m0_fid                           csb_root_fid;
 
 	/** Maximal allowed namelen (retrived from mdservice) */
-	int                           csb_namelen;
+	int                                     csb_namelen;
 
 	/** Run-time addb context for each mount point */
-	struct m0_addb_ctx            csb_addb_ctx;
+	struct m0_addb_ctx                      csb_addb_ctx;
 
 	/** Read[0] and write[1] I/O request statistics */
-	struct m0_addb_io_stats       csb_io_stats[2];
+	struct m0_addb_io_stats                 csb_io_stats[2];
 
 	/** Degraded mode Read[0] and write[1] I/O request statistics */
-	struct m0_addb_io_stats       csb_dgio_stats[2];
+	struct m0_addb_io_stats                 csb_dgio_stats[2];
+
+	struct m0_net_xprt                     *csb_xprt;
+	/** local endpoint address module parameter */
+	char                                   *csb_laddr;
+	char                                   *csb_db_name;
+	struct m0_net_domain                    csb_ndom;
+	struct m0_rpc_machine                   csb_rpc_machine;
+	struct m0_reqh                          csb_reqh;
+	struct m0_dbenv                         csb_dbenv;
+	struct m0_fol                           csb_fol;
+	struct m0_net_buffer_pool               csb_buffer_pool;
+	struct m0_layout_domain                 csb_layout_dom;
+
+	struct m0_addb_monitor                  csb_addb_mon_rw_io_size;
+	struct m0t1fs_addb_mon_sum_data_io_size csb_addb_mon_sum_data_rw_io_size;
+	struct m0_be_ut_backend                 csb_ut_be;
+	struct m0_be_ut_seg                     csb_ut_seg;
+
+	/** lnet tmid for client ep */
+	size_t                                  csb_tmid;
 };
 
 struct m0t1fs_filedata {
@@ -659,10 +663,10 @@ M0_INTERNAL int m0t1fs_inode_layout_init(struct m0t1fs_inode *ci);
 M0_INTERNAL struct m0_fid
 m0t1fs_ios_cob_fid(const struct m0t1fs_inode *ci, int index);
 
-M0_INTERNAL struct m0_rm_domain *m0t1fs_rmsvc_domain_get(void);
+M0_INTERNAL struct m0_rm_domain *m0t1fs_rmsvc_domain_get(struct m0_reqh *reqh);
 
 M0_INTERNAL void m0t1fs_file_lock_init(struct m0t1fs_inode    *ci,
-				       const struct m0t1fs_sb *csb);
+				       struct m0t1fs_sb *csb);
 
 M0_INTERNAL void m0t1fs_file_lock_fini(struct m0t1fs_inode *ci);
 
@@ -763,6 +767,8 @@ M0_INTERNAL const struct m0_fid *
 		m0t1fs_inode_fid(const struct m0t1fs_inode *ci);
 
 void m0t1fs_fid_alloc(struct m0t1fs_sb *csb, struct m0_fid *out);
+unsigned long fid_hash(const struct m0_fid *fid);
+M0_INTERNAL struct m0t1fs_sb *m0_fop_to_sb(struct m0_fop *fop);
 
 #endif /* __MERO_M0T1FS_M0T1FS_H__ */
 
diff --git a/m0t1fs/linux_kernel/st/m0t1fs_client_inc.sh b/m0t1fs/linux_kernel/st/m0t1fs_client_inc.sh
index 6f027b3..2bdac5b 100644
--- a/m0t1fs/linux_kernel/st/m0t1fs_client_inc.sh
+++ b/m0t1fs/linux_kernel/st/m0t1fs_client_inc.sh
@@ -1,6 +1,6 @@
 mount_m0t1fs()
 {
-	if [ $# -ne 5 ]
+	if [ $# -ne 5 -a $# -ne 6 ]
 	then
 		echo "Usage: mount_m0t1fs <mount_dir> <unit_size (in Kbytes)> <N> <K> <p>"
 		return 1
@@ -11,6 +11,7 @@ mount_m0t1fs()
 	local N=$3
 	local K=$4
 	local P=$5
+	local mountop=$6
 
 	# Create mount directory
 	sudo mkdir -p $m0t1fs_mount_dir || {
@@ -67,7 +68,7 @@ EOF`"
 
 	echo "Mounting file system..."
 
-	cmd="sudo mount -t m0t1fs -o profile=$PROF_OPT,local_conf='$CONF' \
+	cmd="sudo mount -t m0t1fs -o profile=$PROF_OPT,local_conf='$CONF',$mountop \
 	    none $m0t1fs_mount_dir"
 	echo $cmd
 	eval $cmd || {
@@ -98,6 +99,25 @@ unmount_and_clean()
 	done
 }
 
+unmount_m0t1fs()
+
+{	if [ $# -ne 1 ]
+	then
+		echo "Usage: unmount_m0t1fs <mount_dir>"
+		return 1
+	fi
+
+	local m0t1fs_mount_dir=$1
+	echo "Unmounting file system ..."
+	umount $m0t1fs_mount_dir &>/dev/null
+
+	sleep 2
+
+	echo "Cleaning up test directory..."
+	rm -rf $m0t1fs_mount_dir &>/dev/null
+}
+
+
 bulkio_test()
 {
 	local_input=$MERO_M0T1FS_TEST_DIR/file1.data
@@ -307,6 +327,7 @@ file_creation_test()
 	    >> $MERO_TEST_LOGFILE
 	for ((i=0; i<$nr_files; ++i)); do
 		touch $MERO_M0T1FS_MOUNT_DIR/file$i >> $MERO_TEST_LOGFILE || break
+		echo '0123456789abcdef' > $MERO_M0T1FS_MOUNT_DIR/file$i >> $MERO_TEST_LOGFILE || break
 		ls -li $MERO_M0T1FS_MOUNT_DIR/file$i >> $MERO_TEST_LOGFILE || break
 	done
 	unmount_and_clean &>> $MERO_TEST_LOGFILE
@@ -340,6 +361,86 @@ file_creation_test()
 	return 0
 }
 
+multi_client_test()
+{
+	local nr_clients=$1
+	local mount_dir_1=${MERO_M0T1FS_MOUNT_DIR}aa
+	local mount_dir_2=${MERO_M0T1FS_MOUNT_DIR}bb
+	local mount_dir_3=${MERO_M0T1FS_MOUNT_DIR}cc
+
+	mount_m0t1fs ${mount_dir_1} 4 $NR_DATA $NR_PARITY $POOL_WIDTH "fid_start=4" &>> $MERO_TEST_LOGFILE || {
+		cat $MERO_TEST_LOGFILE
+		return 1
+	}
+	df
+	mount_m0t1fs ${mount_dir_2} 4 $NR_DATA $NR_PARITY $POOL_WIDTH "fid_start=1004" &>> $MERO_TEST_LOGFILE || {
+		cat $MERO_TEST_LOGFILE
+		unmount_m0t1fs ${mount_dir_1} &>> $MERO_TEST_LOGFILE
+		return 1
+	}
+	df
+	mount_m0t1fs ${mount_dir_3} 4 $NR_DATA $NR_PARITY $POOL_WIDTH "fid_start=2004" &>> $MERO_TEST_LOGFILE || {
+		cat $MERO_TEST_LOGFILE
+		unmount_m0t1fs ${mount_dir_1} &>> $MERO_TEST_LOGFILE
+		unmount_m0t1fs ${mount_dir_2} &>> $MERO_TEST_LOGFILE
+		return 1
+	}
+	echo "Three clients mounted:"
+	mount
+	mkdir ${mount_dir_1}/dir1
+	mkdir ${mount_dir_2}/dir2
+	mkdir ${mount_dir_3}/dir3
+	cp -av /bin/ls ${mount_dir_1}/dir1/obj1
+	cp -av /bin/ls ${mount_dir_2}/dir2/obj2
+	cp -av /bin/ls ${mount_dir_3}/dir3/obj3
+	ls -liR ${mount_dir_1}
+	ls -liR ${mount_dir_2}
+	ls -liR ${mount_dir_3}
+
+	diff /bin/ls ${mount_dir_1}/dir1/obj1 || echo "Obj1 creation failure"
+	diff /bin/ls ${mount_dir_1}/dir2/obj2 || echo "Obj2 creation failure"
+	diff /bin/ls ${mount_dir_1}/dir3/obj3 || echo "Obj3 creation failure"
+
+	diff /bin/ls ${mount_dir_1}/dir1/obj1 || echo "Obj1 creation failure"
+	diff /bin/ls ${mount_dir_2}/dir2/obj2 || echo "Obj2 creation failure"
+	diff /bin/ls ${mount_dir_3}/dir3/obj3 || echo "Obj3 creation failure"
+
+	unmount_m0t1fs ${mount_dir_1} &>> $MERO_TEST_LOGFILE
+	unmount_m0t1fs ${mount_dir_2} &>> $MERO_TEST_LOGFILE
+	unmount_m0t1fs ${mount_dir_3} &>> $MERO_TEST_LOGFILE
+	echo "First round done."
+	mount_m0t1fs ${mount_dir_1} 4 $NR_DATA $NR_PARITY $POOL_WIDTH "fid_start=4" &>> $MERO_TEST_LOGFILE || {
+		cat $MERO_TEST_LOGFILE
+		return 1
+	}
+	mount_m0t1fs ${mount_dir_2} 4 $NR_DATA $NR_PARITY $POOL_WIDTH "fid_start=1004" &>> $MERO_TEST_LOGFILE || {
+		cat $MERO_TEST_LOGFILE
+		return 1
+	}
+	mount_m0t1fs ${mount_dir_3} 4 $NR_DATA $NR_PARITY $POOL_WIDTH "fid_start=2004" &>> $MERO_TEST_LOGFILE || {
+		cat $MERO_TEST_LOGFILE
+		return 1
+	}
+	echo "Three clients mounted:"
+	mount
+	ls -liR ${mount_dir_1}
+	ls -liR ${mount_dir_2}
+	ls -liR ${mount_dir_3}
+
+	md5sum /bin/ls
+	md5sum ${mount_dir_1}/dir1/obj1
+	md5sum ${mount_dir_2}/dir2/obj2
+	md5sum ${mount_dir_3}/dir3/obj3
+
+	unmount_m0t1fs ${mount_dir_1} &>> $MERO_TEST_LOGFILE
+	unmount_m0t1fs ${mount_dir_2} &>> $MERO_TEST_LOGFILE
+	unmount_m0t1fs ${mount_dir_3} &>> $MERO_TEST_LOGFILE
+	echo "Second round done"
+	df
+	return 0
+}
+
+
 rmw_test()
 {
 	for unit_size in 4 8 16 32
@@ -370,7 +471,7 @@ rmw_test()
 m0t1fs_system_tests()
 {
 	file_creation_test $MAX_NR_FILES || {
-                echo "Failed: File creation test failed."
+		echo "Failed: File creation test failed."
 		return 1
 	}
 
diff --git a/m0t1fs/linux_kernel/st/m0t1fs_common_inc.sh b/m0t1fs/linux_kernel/st/m0t1fs_common_inc.sh
index 6c75d6d..d6c9be9 100644
--- a/m0t1fs/linux_kernel/st/m0t1fs_common_inc.sh
+++ b/m0t1fs/linux_kernel/st/m0t1fs_common_inc.sh
@@ -43,14 +43,14 @@ MERO_STOB_DOMAIN="ad -d disks.conf"
 
 # list of server end points
 EP=(
-    12345:33:101   # MDS  EP
-    12345:33:102   # IOS1 EP
-    12345:33:103   # IOS2 EP
-    12345:33:104   # IOS3 EP
-    12345:33:105   # IOS4 EP
+    12345:33:1001   # MDS  EP
+    12345:33:1002   # IOS1 EP
+    12345:33:1003   # IOS2 EP
+    12345:33:1004   # IOS3 EP
+    12345:33:1005   # IOS4 EP
 )
 
-SNS_CLI_EP="12345:33:301"
+SNS_CLI_EP="12345:33:991"
 
 PREPARE_STORAGE="-p"
 POOL_WIDTH=$(expr ${#EP[*]} - 1)
@@ -83,7 +83,8 @@ load_kernel_module()
 	server_nid=${server_nid:-$lnet_nid}
 
 	# Client end point (m0mero module local_addr)
-	LADDR="$lnet_nid:12345:33:1"
+	# last component in this addr will be generated and filled in m0mero.
+	LADDR="$lnet_nid:12345:33:"
 
 	mero_module_path=$MERO_CORE_ROOT/mero
 	mero_module=$MERO_MODULE
diff --git a/m0t1fs/linux_kernel/st/m0t1fs_multi_clients.sh b/m0t1fs/linux_kernel/st/m0t1fs_multi_clients.sh
new file mode 100755
index 0000000..db2fb01
--- /dev/null
+++ b/m0t1fs/linux_kernel/st/m0t1fs_multi_clients.sh
@@ -0,0 +1,45 @@
+#!/bin/sh
+
+#set -x
+
+. `dirname $0`/common.sh
+. `dirname $0`/m0t1fs_common_inc.sh
+. `dirname $0`/m0t1fs_client_inc.sh
+. `dirname $0`/m0t1fs_server_inc.sh
+. `dirname $0`/m0t1fs_rsink.sh
+
+main()
+{
+	NODE_UUID=`uuidgen`
+	mero_service start
+	if [ $? -ne "0" ]
+	then
+		echo "Failed to start Mero Service."
+		return 1
+	fi
+
+	multi_client_test $NR_CLIENTS
+	rc=$?
+
+	# mero_service stop --collect-addb
+	mero_service stop
+	if [ $? -ne "0" ]
+	then
+		echo "Failed to stop Mero Service."
+		return 1
+	fi
+
+	if [ $rc -ne "0" ]
+	then
+		echo "Failed m0t1fs multi-clients tests."
+		return 1
+	fi
+
+	echo "m0t1fs multi-clients tests status: SUCCESS."
+	echo "Test log available at $MERO_TEST_LOGFILE."
+
+	return $rc
+}
+
+trap unprepare EXIT
+main
diff --git a/m0t1fs/linux_kernel/st/m0t1fs_test.sh b/m0t1fs/linux_kernel/st/m0t1fs_test.sh
index 7e3f999..62d188e 100755
--- a/m0t1fs/linux_kernel/st/m0t1fs_test.sh
+++ b/m0t1fs/linux_kernel/st/m0t1fs_test.sh
@@ -51,5 +51,4 @@ main()
 }
 
 trap unprepare EXIT
-
 main
diff --git a/m0t1fs/linux_kernel/st/st b/m0t1fs/linux_kernel/st/st
index 9b1abb4..df67910 100755
--- a/m0t1fs/linux_kernel/st/st
+++ b/m0t1fs/linux_kernel/st/st
@@ -27,9 +27,9 @@ export_lnet_nid_endpoints() {
     ##
     ## The PID value of 12345 is used by Lustre in the kernel and is
     ## the only value currently supported.
-    export M0T1FS_ENDPOINT="$LNET_NID:12345:34:6"
-    export IOS0_ENDPOINT="$LNET_NID:12345:34:1"
-    export IOS1_ENDPOINT="$LNET_NID:12345:34:2"
+    export M0T1FS_ENDPOINT="$LNET_NID:12345:34:"
+    export IOS0_ENDPOINT="$LNET_NID:12345:34:1001"
+    export IOS1_ENDPOINT="$LNET_NID:12345:34:1002"
     export MDS_ENDPOINT="$IOS0_ENDPOINT"
     export RMS_ENDPOINT="$IOS0_ENDPOINT"
     export CONFD_ENDPOINT="$IOS0_ENDPOINT"
@@ -293,9 +293,9 @@ say '  Test: m0t1fs local_conf'
 _mount local || _fini $?
 umount $SANDBOX_DIR/mnt
 
-say '  Test: m0t1fs confd'
-_mount net || _fini $?
-umount $SANDBOX_DIR/mnt
+#say '  Test: m0t1fs confd'
+#_mount net || _fini $?
+#umount $SANDBOX_DIR/mnt
 
 ## "conf-reqh" demo: start another instance of m0d, which configures
 ## itself retrieving data from confd.
diff --git a/m0t1fs/linux_kernel/super.c b/m0t1fs/linux_kernel/super.c
index a38ea88..21a462a 100644
--- a/m0t1fs/linux_kernel/super.c
+++ b/m0t1fs/linux_kernel/super.c
@@ -36,20 +36,16 @@
 #include "conf/confc.h"    /* m0_confc */
 #include "rpc/rpclib.h"    /* m0_rcp_client_connect */
 #include "addb/addb.h"
+#include "lib/uuid.h"   /* m0_uuid_generate */
+#include "net/lnet/lnet.h"
 #include "rpc/rpc_internal.h"
-
-static int m0t1fs_layout_build(const uint64_t         layout_id,
-			       const uint32_t         N,
-			       const uint32_t         K,
-			       const uint32_t         pool_width,
-			       const uint64_t         unit_size,
-			       struct m0_layout_enum *le,
-			       struct m0_layout     **layout);
-
-static int m0t1fs_cob_id_enum_build(const uint32_t pool_width,
-				    struct m0_layout_enum **lay_enum);
+#include "m0t1fs/m0t1fs_addb.h"
+#include "net/lnet/lnet_core_types.h"
 
 extern struct io_mem_stats iommstats;
+extern struct m0_bitmap    m0t1fs_client_ep_tmid;
+extern struct m0_mutex     m0t1fs_mutex;
+extern uint32_t            m0t1fs_addb_mon_rw_io_size_key;
 
 M0_INTERNAL void io_bob_tlists_init(void);
 
@@ -118,6 +114,8 @@ m0t1fs_container_id_to_session(const struct m0t1fs_sb *csb,
 
 	M0_ENTRY();
 	M0_PRE(container_id <= csb->csb_nr_containers);
+	M0_LOG(M0_DEBUG, "container_id=%llu csb->csb_nr_containers=%u",
+			 container_id, csb->csb_nr_containers);
 
 	ctx = csb->csb_cl_map.clm_map[container_id];
 	M0_ASSERT(ctx != NULL);
@@ -503,7 +501,7 @@ static int connect_to_service(const char *addr, enum m0_conf_service_type type,
 
 	m0t1fs_service_context_init(ctx, csb, type);
 	rc = m0_rpc_client_connect(&ctx->sc_conn, &ctx->sc_session,
-				   &m0t1fs_globals.g_rpc_machine, addr,
+				   &csb->csb_rpc_machine, addr,
 				   M0T1FS_MAX_NR_RPC_IN_FLIGHT);
 	if (rc == 0) {
 		svc_ctx_tlist_add_tail(&csb->csb_service_contexts, ctx);
@@ -597,13 +595,14 @@ out:
 	return M0_RC(rc);
 }
 
-static int configure_addb_rpc_sink(struct m0_addb_mc *addb_mc)
+static int configure_addb_rpc_sink(struct m0t1fs_sb *csb,
+				   struct m0_addb_mc *addb_mc)
 {
 
 	if (!m0_addb_mc_has_rpc_sink(addb_mc)) {
 		int rc = m0_addb_mc_configure_rpc_sink(addb_mc,
-						&m0t1fs_globals.g_rpc_machine,
-						&m0t1fs_globals.g_reqh,
+						&csb->csb_rpc_machine,
+						&csb->csb_reqh,
 						M0_ADDB_RPCSINK_TS_INIT_PAGES,
 						M0_ADDB_RPCSINK_TS_MAX_PAGES,
 						M0_ADDB_RPCSINK_TS_PAGE_SIZE);
@@ -729,7 +728,8 @@ static void m0t1fs_poolmach_destroy(struct m0_poolmach *mach)
 	m0_free(mach);
 }
 
-static int cl_map_build(struct m0t1fs_sb *csb, uint32_t nr_ios,
+static int cl_map_build(struct m0t1fs_sb       *csb,
+			uint32_t                nr_ios,
 			const struct fs_params *fs_params)
 {
 	struct m0t1fs_service_context        *ctx;
@@ -759,6 +759,8 @@ static int cl_map_build(struct m0t1fs_sb *csb, uint32_t nr_ios,
 	if (nr_data_containers % nr_ios != 0)
 		++nr_cont_per_svc;
 	M0_LOG(M0_DEBUG, "nr_cont_per_svc = %d", nr_cont_per_svc);
+	M0_LOG(M0_DEBUG, "%d active contexts. csb_nr_containers = %d",
+		         csb->csb_nr_active_contexts, csb->csb_nr_containers);
 
 	M0_SET0(map);
 
@@ -774,8 +776,9 @@ static int cl_map_build(struct m0t1fs_sb *csb, uint32_t nr_ios,
 		case M0_CST_IOS:
 			for (i = 0;
 			     i < nr_cont_per_svc && cur <= nr_data_containers;
-			     ++i, ++cur)
+			     ++i, ++cur) {
 				map->clm_map[cur] = ctx;
+			}
 			break;
 
 		case M0_CST_MGS:
@@ -799,7 +802,8 @@ static int cl_map_build(struct m0t1fs_sb *csb, uint32_t nr_ios,
 /* ----------------------------------------------------------------
  * Layout
  * ---------------------------------------------------------------- */
-static int m0t1fs_layout_build(const uint64_t         layout_id,
+static int m0t1fs_layout_build(struct m0t1fs_sb      *csb,
+			       const uint64_t         layout_id,
 			       const uint32_t         N,
 			       const uint32_t         K,
 			       const uint32_t         pool_width,
@@ -824,7 +828,7 @@ static int m0t1fs_layout_build(const uint64_t         layout_id,
 	m0_uint128_init(&pl_attr.pa_seed, "upjumpandpumpim,");
 
 	*layout = NULL;
-	rc = m0_pdclust_build(&m0t1fs_globals.g_layout_dom,
+	rc = m0_pdclust_build(&csb->csb_layout_dom,
 			      layout_id, &pl_attr, le,
 			      &pdlayout);
 	if (rc == 0)
@@ -833,7 +837,8 @@ static int m0t1fs_layout_build(const uint64_t         layout_id,
 	return M0_RC(rc);
 }
 
-static int m0t1fs_cob_id_enum_build(const uint32_t pool_width,
+static int m0t1fs_cob_id_enum_build(struct m0t1fs_sb *csb,
+				    const uint32_t pool_width,
 				    struct m0_layout_enum **lay_enum)
 {
 	struct m0_layout_linear_attr  lin_attr;
@@ -853,7 +858,7 @@ static int m0t1fs_cob_id_enum_build(const uint32_t pool_width,
 	};
 
 	*lay_enum = NULL;
-	rc = m0_linear_enum_build(&m0t1fs_globals.g_layout_dom,
+	rc = m0_linear_enum_build(&csb->csb_layout_dom,
 				  &lin_attr, &lle);
 	if (rc == 0)
 		*lay_enum = &lle->lle_base;
@@ -904,9 +909,9 @@ try_again:
 		break;
 	} while (1);
 
-	rc = m0t1fs_cob_id_enum_build(fs_params->fs_pool_width, &layout_enum);
+	rc = m0t1fs_cob_id_enum_build(csb, fs_params->fs_pool_width, &layout_enum);
 	if (rc == 0) {
-		rc = m0t1fs_layout_build(csb->csb_layout_id,
+		rc = m0t1fs_layout_build(csb, csb->csb_layout_id,
 					 fs_params->fs_nr_data_units,
 					 fs_params->fs_nr_parity_units,
 					 fs_params->fs_pool_width,
@@ -948,12 +953,319 @@ static void m0t1fs_sb_layout_fini(struct m0t1fs_sb *csb)
 	M0_LEAVE();
 }
 
+static int m0t1fs_service_start(const char *sname, struct m0_reqh *reqh)
+{
+	int                          rc;
+	struct m0_reqh_service_type *stype;
+	struct m0_reqh_service      *service;
+	struct m0_uint128            uuid;
+
+	stype = m0_reqh_service_type_find(sname);
+	if (stype == NULL)
+		return M0_RC(-EINVAL);
+	rc = m0_reqh_service_allocate(&service, stype, NULL);
+	if (rc != 0)
+		return M0_RC(rc);
+	m0_uuid_generate(&uuid);
+	m0_reqh_service_init(service, reqh, &uuid);
+	rc = m0_reqh_service_start(service);
+
+	return M0_RC(rc);
+}
+
+int m0t1fs_reqh_services_start(struct m0t1fs_sb *csb)
+{
+	struct m0_reqh *reqh = &csb->csb_reqh;
+	int rc;
+
+	rc = m0t1fs_service_start(M0_ADDB_SVC_NAME, reqh);
+	if (rc)
+		goto err;
+	rc = m0t1fs_service_start("rmservice", reqh);
+	if (rc)
+		goto err;
+	return M0_RC(rc);
+err:
+	m0_reqh_services_terminate(reqh);
+	return M0_RC(rc);
+}
+
+int m0t1fs_net_init(struct m0t1fs_sb *csb)
+{
+	struct m0_net_xprt   *xprt;
+	struct m0_net_domain *ndom;
+	int		      rc;
+	char                 *laddr;
+
+	M0_ENTRY();
+	laddr = m0_alloc(M0_NET_LNET_NIDSTR_SIZE * 2);
+
+	csb->csb_xprt  = &m0_net_lnet_xprt;;
+	m0_mutex_lock(&m0t1fs_mutex);
+	csb->csb_tmid = m0_bitmap_ffz(&m0t1fs_client_ep_tmid);
+	if (csb->csb_tmid < 0) {
+		m0_mutex_unlock(&m0t1fs_mutex);
+		goto out;
+	}
+	m0_bitmap_set(&m0t1fs_client_ep_tmid, csb->csb_tmid, true);
+	m0_mutex_unlock(&m0t1fs_mutex);
+
+	snprintf(laddr, M0_NET_LNET_NIDSTR_SIZE * 2,
+		 "%s%d", local_addr, (int)csb->csb_tmid);
+	M0_LOG(M0_DEBUG, "local ep is %s", laddr);
+	csb->csb_laddr = laddr;
+	xprt =  csb->csb_xprt;
+	ndom = &csb->csb_ndom;
+
+	rc = m0_net_xprt_init(xprt);
+	if (rc != 0)
+		goto out;
+
+	/** @todo replace &m0_addb_proc_ctx */
+	rc = m0_net_domain_init(ndom, xprt, &m0_addb_proc_ctx);
+	if (rc != 0)
+		m0_net_xprt_fini(xprt);
+out:
+	M0_LEAVE("rc: %d", rc);
+	return rc;
+}
+
+void m0t1fs_net_fini(struct m0t1fs_sb *csb)
+{
+	M0_ENTRY();
+
+	m0_net_domain_fini(&csb->csb_ndom);
+	m0_net_xprt_fini(csb->csb_xprt);
+	m0_free(csb->csb_laddr);
+	m0_mutex_lock(&m0t1fs_mutex);
+	m0_bitmap_set(&m0t1fs_client_ep_tmid, csb->csb_tmid, false);
+	m0_mutex_unlock(&m0t1fs_mutex);
+
+	M0_LEAVE();
+}
+
+int m0t1fs_rpc_init(struct m0t1fs_sb *csb)
+{
+	struct m0_dbenv           *dbenv       = &csb->csb_dbenv;
+	char                      *db_name     =  csb->csb_db_name;
+	struct m0_rpc_machine     *rpc_machine = &csb->csb_rpc_machine;
+	struct m0_reqh            *reqh        = &csb->csb_reqh;
+	struct m0_net_domain      *ndom        = &csb->csb_ndom;
+	const char                *laddr       =  csb->csb_laddr;
+	struct m0_net_buffer_pool *buffer_pool = &csb->csb_buffer_pool;
+	struct m0_fol             *fol         = &csb->csb_fol;
+	struct m0_net_transfer_mc *tm;
+	int                        rc;
+	uint32_t		   bufs_nr;
+	uint32_t		   tms_nr;
+
+	M0_ENTRY();
+
+	/* Init BE. */
+	m0_be_ut_backend_init(&csb->csb_ut_be);
+	m0_be_ut_seg_init(&csb->csb_ut_seg,
+			  &csb->csb_ut_be, 1ULL << 24);
+	m0_be_ut_seg_allocator_init(&csb->csb_ut_seg,
+				    &csb->csb_ut_be);
+
+	tms_nr	 = 1;
+	bufs_nr  = m0_rpc_bufs_nr(tm_recv_queue_min_len, tms_nr);
+
+	rc = m0_rpc_net_buffer_pool_setup(ndom, buffer_pool,
+					  bufs_nr, tms_nr);
+	if (rc != 0)
+		goto pool_fini;
+
+	rc = m0_dbenv_init(dbenv, db_name, 0);
+	if (rc != 0)
+		goto pool_fini;
+
+	rc = M0_REQH_INIT(reqh,
+			  .rhia_dtm = (void*)1,
+			  .rhia_db = &csb->csb_ut_seg.bus_seg,
+			  .rhia_mdstore = (void*)1,
+			  .rhia_fol = fol,
+			  .rhia_svc = (void*)1);
+	if (rc != 0)
+		goto dbenv_fini;
+	rc = m0_rpc_machine_init(rpc_machine, ndom, laddr, reqh,
+				 buffer_pool, M0_BUFFER_ANY_COLOUR,
+				 max_rpc_msg_size, tm_recv_queue_min_len);
+	if (rc != 0)
+		goto reqh_fini;
+	m0_reqh_start(reqh);
+	tm = &rpc_machine->rm_tm;
+	M0_ASSERT(tm->ntm_recv_pool == buffer_pool);
+
+	m0_reqh_rpc_mach_tlink_init_at_tail(rpc_machine,
+					    &reqh->rh_rpc_machines);
+
+	return M0_RC(rc);
+
+reqh_fini:
+	m0_reqh_fini(reqh);
+dbenv_fini:
+	m0_dbenv_fini(dbenv);
+pool_fini:
+	m0_rpc_net_buffer_pool_cleanup(buffer_pool);
+	m0_be_ut_seg_allocator_fini(&csb->csb_ut_seg,
+				    &csb->csb_ut_be);
+	m0_be_ut_seg_fini(&csb->csb_ut_seg);
+	m0_be_ut_backend_fini(&csb->csb_ut_be);
+	M0_LEAVE("rc: %d", rc);
+	M0_ASSERT(rc != 0);
+	return rc;
+}
+
+struct m0t1fs_sb *reqh2sb(struct m0_reqh *reqh)
+{
+	return container_of(reqh, struct m0t1fs_sb, csb_reqh);
+}
+
+static void m0t1fs_mon_rw_io_watch(const struct m0_addb_monitor *mon,
+				   const struct m0_addb_rec     *rec,
+				   struct m0_reqh               *reqh)
+{
+	struct m0_addb_sum_rec                  *sum_rec;
+	struct m0t1fs_addb_mon_sum_data_io_size *sum_data =
+				&reqh2sb(reqh)->csb_addb_mon_sum_data_rw_io_size;
+
+	if (m0_addb_rec_rid_make(M0_ADDB_BRT_DP, M0T1FS_ADDB_RECID_IO_FINISH)
+	    == rec->ar_rid) {
+		sum_rec = mon->am_ops->amo_sum_rec(mon, reqh);
+		M0_ASSERT(sum_rec != NULL);
+
+		m0_mutex_lock(&sum_rec->asr_mutex);
+		if (rec->ar_data.au64s_data[0] == IRT_READ) {
+			sum_data->sd_rio += rec->ar_data.au64s_data[1];
+			sum_rec->asr_dirty = true;
+		} else if (rec->ar_data.au64s_data[0] == IRT_WRITE) {
+			sum_data->sd_wio += rec->ar_data.au64s_data[1];
+			sum_rec->asr_dirty = true;
+		}
+		else
+			M0_IMPOSSIBLE("Invalid IO state");
+		m0_mutex_unlock(&sum_rec->asr_mutex);
+
+	}
+}
+
+static struct m0_addb_sum_rec *
+m0t1fs_mon_rw_io_sum_rec(const struct m0_addb_monitor *mon,
+		         struct m0_reqh               *reqh)
+{
+	struct m0_addb_sum_rec *sum_rec;
+
+	m0_rwlock_read_lock(&reqh->rh_rwlock);
+	sum_rec = m0_reqh_lockers_get(reqh, m0t1fs_addb_mon_rw_io_size_key);
+	m0_rwlock_read_unlock(&reqh->rh_rwlock);
+
+	return sum_rec;
+}
+
+const struct m0_addb_monitor_ops m0t1fs_addb_mon_rw_io_ops = {
+	.amo_watch   = m0t1fs_mon_rw_io_watch,
+	.amo_sum_rec = m0t1fs_mon_rw_io_sum_rec
+};
+
+int m0t1fs_addb_mon_total_io_size_init(struct m0t1fs_sb *csb)
+{
+	struct m0_addb_sum_rec *sum_rec;
+	struct m0_reqh         *reqh = &csb->csb_reqh;
+	uint64_t               *sum_data =
+		     (uint64_t *)&csb->csb_addb_mon_sum_data_rw_io_size;
+	uint32_t                sum_rec_nr =
+		     sizeof (csb->csb_addb_mon_sum_data_rw_io_size) /
+					     sizeof (uint64_t);
+	M0_ALLOC_PTR(sum_rec);
+	if (sum_rec == NULL)
+		return M0_RC(-ENOMEM);
+
+	m0_addb_monitor_init(&csb->csb_addb_mon_rw_io_size,
+			     &m0t1fs_addb_mon_rw_io_ops);
+
+	m0_addb_monitor_sum_rec_init(sum_rec, &m0_addb_rt_m0t1fs_mon_io_size,
+				     sum_data, sum_rec_nr);
+
+	m0_rwlock_write_lock(&reqh->rh_rwlock);
+	m0_reqh_lockers_set(reqh, m0t1fs_addb_mon_rw_io_size_key, sum_rec);
+	m0_rwlock_write_unlock(&reqh->rh_rwlock);
+
+	m0_addb_monitor_add(reqh, &csb->csb_addb_mon_rw_io_size);
+
+	return 0;
+}
+
+void m0t1fs_addb_mon_total_io_size_fini(struct m0t1fs_sb *csb)
+{
+	struct m0_addb_sum_rec *sum_rec;
+	struct m0_addb_monitor *mon = &csb->csb_addb_mon_rw_io_size;
+	struct m0_reqh         *reqh = &csb->csb_reqh;
+
+	sum_rec = mon->am_ops->amo_sum_rec(mon, &csb->csb_reqh);
+
+	m0_addb_monitor_del(reqh, mon);
+
+	m0_rwlock_write_lock(&reqh->rh_rwlock);
+	m0_reqh_lockers_clear(reqh, m0t1fs_addb_mon_rw_io_size_key);
+	m0_rwlock_write_unlock(&reqh->rh_rwlock);
+	m0_addb_monitor_sum_rec_fini(sum_rec);
+	m0_free(sum_rec);
+	m0_addb_monitor_fini(mon);
+}
+
+void m0t1fs_rpc_fini(struct m0t1fs_sb *csb)
+{
+	M0_ENTRY();
+
+	m0_reqh_services_terminate(&csb->csb_reqh);
+	m0_reqh_rpc_mach_tlink_del_fini(&csb->csb_rpc_machine);
+	m0_rpc_machine_fini(&csb->csb_rpc_machine);
+	m0_reqh_fini(&csb->csb_reqh);
+	m0_dbenv_fini(&csb->csb_dbenv);
+	m0_rpc_net_buffer_pool_cleanup(&csb->csb_buffer_pool);
+	m0_be_ut_seg_allocator_fini(&csb->csb_ut_seg,
+				    &csb->csb_ut_be);
+	m0_be_ut_seg_fini(&csb->csb_ut_seg);
+	m0_be_ut_backend_fini(&csb->csb_ut_be);
+
+	M0_LEAVE();
+}
+
+int m0t1fs_layout_init(struct m0t1fs_sb *csb)
+{
+	int rc;
+
+	M0_ENTRY();
+
+	rc = m0_layout_domain_init(&csb->csb_layout_dom,
+				   &csb->csb_dbenv);
+	if (rc == 0) {
+		rc = m0_layout_standard_types_register(
+						&csb->csb_layout_dom);
+		if (rc != 0)
+			m0_layout_domain_fini(&csb->csb_layout_dom);
+	}
+
+	return M0_RC(rc);
+}
+
+void m0t1fs_layout_fini(struct m0t1fs_sb *csb)
+{
+	M0_ENTRY();
+
+	m0_layout_standard_types_unregister(&csb->csb_layout_dom);
+	m0_layout_domain_fini(&csb->csb_layout_dom);
+
+	M0_LEAVE();
+}
+
+
 static int m0t1fs_setup(struct m0t1fs_sb *csb, const struct mount_opts *mops)
 {
 	struct m0t1fs_service_context *ctx;
 	struct m0_confc                confc;
 	struct m0_conf_obj            *fs;
-	struct m0_reqh                *reqh = &m0t1fs_globals.g_reqh;
 	const char                    *ep_addr;
 	struct m0_fid                  prof_fid;
 	uint32_t                       nr_ios = 0;
@@ -964,12 +1276,28 @@ static int m0t1fs_setup(struct m0t1fs_sb *csb, const struct mount_opts *mops)
 	M0_ENTRY();
 	M0_PRE(csb->csb_astthread.t_state == TS_RUNNING);
 
+	rc = m0t1fs_net_init(csb);
+	if (rc != 0)
+		goto err_return;
+
+	rc = m0t1fs_rpc_init(csb);
+	if (rc != 0)
+		goto err_net_fini;
+
+	rc = m0t1fs_addb_mon_total_io_size_init(csb);
+	if (rc != 0)
+		goto err_rpc_fini;
+
+	rc = m0t1fs_layout_init(csb);
+	if (rc != 0)
+		goto err_addb_mon_fini;
+
 	csb->csb_next_key = mops->mo_fid_start;
 
 	rc = m0_fid_sscanf(mops->mo_profile, &prof_fid);
 	if (rc != 0) {
 		M0_LOG(M0_FATAL, "Cannot parse profile `%s'", mops->mo_profile);
-		return M0_RC(rc);
+		goto err_layout_fini;
 	}
 
 	m0_fid_tset(&prof_fid, M0_CONF_PROFILE_TYPE.cot_ftype.ft_id,
@@ -977,13 +1305,14 @@ static int m0t1fs_setup(struct m0t1fs_sb *csb, const struct mount_opts *mops)
 
 	if (!m0_conf_fid_is_valid(&prof_fid)) {
 		M0_LOG(M0_FATAL, "Wrong profile fid "FID_F, FID_P(&prof_fid));
-		return M0_RC(-EINVAL);
+		rc = -EINVAL;
+		goto err_layout_fini;
 	}
 	rc = m0_confc_init(&confc, &csb->csb_iogroup, &prof_fid,
-			   mops->mo_confd, &m0t1fs_globals.g_rpc_machine,
+			   mops->mo_confd, &csb->csb_rpc_machine,
 			   mops->mo_local_conf);
 	if (rc != 0)
-		return M0_RC(rc);
+		goto err_layout_fini;
 
 	rc = m0_confc_open_sync(&fs, confc.cc_root,
 				M0_CONF_PROFILE_FILESYSTEM_FID);
@@ -1002,7 +1331,7 @@ static int m0t1fs_setup(struct m0t1fs_sb *csb, const struct mount_opts *mops)
 	} m0_tlist_endfor;
 	if (stats_svc_is_provided) {
 		ep_addr = ctx->sc_conn.c_rpcchan->rc_destep->nep_addr;
-		m0_addb_monitor_setup(reqh, &ctx->sc_conn, ep_addr);
+		m0_addb_monitor_setup(&csb->csb_reqh, &ctx->sc_conn, ep_addr);
 		M0_LOG(M0_DEBUG, "Stats service connected");
 	} else
 		M0_LOG(M0_WARN, "Stats service not connected");
@@ -1010,7 +1339,7 @@ static int m0t1fs_setup(struct m0t1fs_sb *csb, const struct mount_opts *mops)
 	if (rc != 0)
 		goto end;
 
-	rc = configure_addb_rpc_sink(&m0_addb_gmc);
+	rc = configure_addb_rpc_sink(csb, &m0_addb_gmc);
 	if (rc != 0)
 		goto err_disconnect;
 
@@ -1028,11 +1357,16 @@ static int m0t1fs_setup(struct m0t1fs_sb *csb, const struct mount_opts *mops)
 	if (rc != 0)
 		goto err_poolmach_destroy;
 
+	/* Start resource manager service */
+	rc = m0t1fs_reqh_services_start(csb);
+	if (rc != 0)
+		goto err_poolmach_destroy;
+
 	rc = m0t1fs_sb_layout_init(csb, &fs_params);
-	if (rc == 0)
-		goto end;
+	if (rc != 0)
+		goto err_poolmach_destroy;
+	return M0_RC(rc);
 
-	m0t1fs_sb_layout_fini(csb);
 err_poolmach_destroy:
 	m0t1fs_poolmach_destroy(csb->csb_pool.po_mach);
 err_pool_fini:
@@ -1043,9 +1377,17 @@ addb_mc_unconf:
 	m0_addb_mc_init(&m0_addb_gmc);
 err_disconnect:
 	disconnect_from_services(csb);
-
 end:
 	m0_confc_fini(&confc);
+err_layout_fini:
+	m0t1fs_layout_fini(csb);
+err_addb_mon_fini:
+	m0t1fs_addb_mon_total_io_size_fini(csb);
+err_rpc_fini:
+	m0t1fs_rpc_fini(csb);
+err_net_fini:
+	m0t1fs_net_fini(csb);
+err_return:
 	return M0_RC(rc);
 }
 
@@ -1058,6 +1400,10 @@ static void m0t1fs_teardown(struct m0t1fs_sb *csb)
 	m0_addb_mc_fini(&m0_addb_gmc);
 	m0_addb_mc_init(&m0_addb_gmc);
 	disconnect_from_services(csb);
+	m0t1fs_layout_fini(csb);
+	m0t1fs_addb_mon_total_io_size_fini(csb);
+	m0t1fs_rpc_fini(csb);
+	m0t1fs_net_fini(csb);
 }
 
 static int m0t1fs_root_alloc(struct super_block *sb)
diff --git a/m0t1fs/linux_kernel/ut/file.c b/m0t1fs/linux_kernel/ut/file.c
index 06b6f00..421af76 100644
--- a/m0t1fs/linux_kernel/ut/file.c
+++ b/m0t1fs/linux_kernel/ut/file.c
@@ -88,6 +88,12 @@ static struct m0t1fs_service_context msc;
 M0_TL_DESCR_DECLARE(rpcbulk, M0_EXTERN);
 M0_TL_DECLARE(rpcbulk, M0_INTERNAL, struct m0_rpc_bulk_buf);
 
+int m0t1fs_layout_init(struct m0t1fs_sb *csb);
+int m0t1fs_addb_mon_total_io_size_init(struct m0t1fs_sb *csb);
+int m0t1fs_rpc_init(struct m0t1fs_sb *csb);
+int m0t1fs_net_init(struct m0t1fs_sb *csb);
+int m0t1fs_reqh_services_start(struct m0t1fs_sb *csb);
+
 static int file_io_ut_init(void)
 {
         int		  rc;
@@ -107,6 +113,20 @@ static int file_io_ut_init(void)
         m0_atomic64_set(&csb.csb_pending_io_nr, 0);
         io_bob_tlists_init();
 
+        rc = m0t1fs_net_init(&csb);
+        M0_ASSERT(rc == 0);
+
+        rc = m0t1fs_rpc_init(&csb);
+        M0_ASSERT(rc == 0);
+
+        rc = m0t1fs_addb_mon_total_io_size_init(&csb);
+        M0_ASSERT(rc == 0);
+
+        rc = m0t1fs_layout_init(&csb);
+        M0_ASSERT(rc == 0);
+        rc = m0t1fs_reqh_services_start(&csb);
+        M0_ASSERT(rc == 0);
+
         /* Tries to build a layout. */
         llattr = (struct m0_layout_linear_attr) {
                 .lla_nr = LAY_N + 2 * LAY_K,
@@ -114,7 +134,7 @@ static int file_io_ut_init(void)
                 .lla_B  = ATTR_B_CONST,
         };
         llenum = NULL;
-        rc = m0_linear_enum_build(&m0t1fs_globals.g_layout_dom, &llattr,
+        rc = m0_linear_enum_build(&csb.csb_layout_dom, &llattr,
 			          &llenum);
         M0_ASSERT(rc == 0);
 
@@ -128,7 +148,7 @@ static int file_io_ut_init(void)
 
         };
         m0_uint128_init(&pdattr.pa_seed, "upjumpandpumpim,");
-        rc = m0_pdclust_build(&m0t1fs_globals.g_layout_dom, csb.csb_layout_id,
+        rc = m0_pdclust_build(&csb.csb_layout_dom, csb.csb_layout_id,
 			      &pdattr, &llenum->lle_base, &pdlay);
         M0_ASSERT(rc == 0);
         M0_ASSERT(pdlay != NULL);
@@ -669,6 +689,11 @@ static void nw_xfer_ops_test(void)
 	m0_indexvec_free(&ivec);
 }
 
+void m0t1fs_layout_fini(struct m0t1fs_sb *csb);
+void m0t1fs_addb_mon_total_io_size_fini(struct m0t1fs_sb *csb);
+void m0t1fs_rpc_fini(struct m0t1fs_sb *csb);
+void m0t1fs_net_fini(struct m0t1fs_sb *csb);
+
 static int file_io_ut_fini(void)
 {
 	m0t1fs_file_lock_fini(&ci);
@@ -682,6 +707,12 @@ static int file_io_ut_fini(void)
 	/* Finalizes the m0_pdclust_layout type. */
 	m0_layout_put(&pdlay->pl_base.sl_base);
 	m0_poolmach_fini(csb.csb_pool.po_mach);
+
+	m0t1fs_layout_fini(&csb);
+	m0t1fs_addb_mon_total_io_size_fini(&csb);
+	m0t1fs_rpc_fini(&csb);
+	m0t1fs_net_fini(&csb);
+
 	return 0;
 }
 
@@ -697,7 +728,6 @@ static void target_ioreq_test(void)
 	int		           cnt;
 	int                        rc;
 	void		          *aligned_buf;
-	struct m0_net_domain      *ndom;
 	struct iovec               iovec_arr[IOVEC_NR];
 	struct m0_indexvec        *ivec;
 	struct pargrp_iomap       *map;
@@ -712,8 +742,7 @@ static void target_ioreq_test(void)
 	size = IOVEC_NR * PAGE_CACHE_SIZE;
 	req.ir_sm.sm_state = IRS_READING;
 
-	ndom = &m0t1fs_globals.g_ndom;
-	conn.c_rpc_machine = &m0t1fs_globals.g_rpc_machine;
+	conn.c_rpc_machine = &csb.csb_rpc_machine;
 	session.s_conn = &conn;
 
 	aligned_buf = m0_alloc_aligned(M0_0VEC_ALIGN, M0_0VEC_SHIFT);
@@ -908,8 +937,8 @@ static void dgmode_readio_test(void)
 	M0_ALLOC_PTR(conn);
 	M0_UT_ASSERT(conn != NULL);
 	session->s_conn = conn;
-	conn->c_rpc_machine = &m0t1fs_globals.g_rpc_machine;
-	conn->c_rpc_machine->rm_tm.ntm_dom = &m0t1fs_globals.g_ndom;
+	conn->c_rpc_machine = &csb.csb_rpc_machine;
+	conn->c_rpc_machine->rm_tm.ntm_dom = &csb.csb_ndom;
 	ti->ti_session = session;
 
 	/* Creates IO fops from pages. */
diff --git a/mdservice/md_foms.c b/mdservice/md_foms.c
index cec5af3..41ba44c 100644
--- a/mdservice/md_foms.c
+++ b/mdservice/md_foms.c
@@ -159,6 +159,9 @@ static int m0_md_create(struct m0_mdstore   *md,
 	}
 	if (scob)
 		m0_cob_put(scob);
+	M0_LOG(M0_DEBUG, "create \"%.*s\" finished with %d and lid=%d",
+	       (int)attr->ca_name.b_nob, (char *)attr->ca_name.b_addr, rc,
+	       (int)attr->ca_lid);
 	return rc;
 }
 
@@ -754,6 +757,7 @@ static int m0_md_tick_lookup(struct m0_fom *fom)
 out:
 	M0_LOG(M0_DEBUG, "Lookup for \"%.*s\" finished with %d",
 	       (int)name.b_nob, (char *)name.b_addr, rc);
+
 	rep->l_body.b_rc = rc;
 	m0_fom_phase_move(fom, rc, rc != 0 ? M0_FOPH_FAILURE : M0_FOPH_SUCCESS);
 	return M0_FSO_AGAIN;
@@ -786,7 +790,7 @@ static int m0_md_tick_getattr(struct m0_fom *fom)
 	M0_ASSERT(fop_rep != NULL);
 	rep = m0_fop_data(fop_rep);
 
-	M0_LOG(M0_DEBUG, "Getattr for "FID_F" started", FID_P(&body->b_pfid));
+	M0_LOG(M0_DEBUG, "Getattr for "FID_F" started", FID_P(&body->b_tfid));
 
 	/**
 	 * Init some fop fields (full path) that require mdstore and other
@@ -808,7 +812,7 @@ static int m0_md_tick_getattr(struct m0_fom *fom)
 	}
 out:
 	M0_LOG(M0_DEBUG, "Getattr for "FID_F" finished with %d",
-	       FID_P(&body->b_pfid), rc);
+	       FID_P(&body->b_tfid), rc);
 	rep->g_body.b_rc = rc;
 	m0_fom_phase_move(fom, rc, rc != 0 ? M0_FOPH_FAILURE : M0_FOPH_SUCCESS);
 	return M0_FSO_AGAIN;
diff --git a/mdstore/mdstore.c b/mdstore/mdstore.c
index aecfd4b..c46d8cb 100644
--- a/mdstore/mdstore.c
+++ b/mdstore/mdstore.c
@@ -728,6 +728,9 @@ M0_INTERNAL int m0_mdstore_getattr(struct m0_mdstore       *md,
 		       (unsigned)cob->co_nsrec.cnr_linkno,
 		       (unsigned)cob->co_nsrec.cnr_cntr,
 		       (unsigned)attr->ca_nlink);
+		M0_LOG(M0_DEBUG, "size:%u, lid:%u",
+		       (unsigned)attr->ca_size,
+		       (unsigned)attr->ca_lid);
 	}
 
 	/*
diff --git a/net/tm.c b/net/tm.c
index 2279e26..fda8cb9 100644
--- a/net/tm.c
+++ b/net/tm.c
@@ -223,6 +223,7 @@ M0_INTERNAL void m0_net_tm_fini(struct m0_net_transfer_mc *tm)
 {
 	struct m0_net_domain *dom = tm->ntm_dom;
 	int i;
+	M0_ENTRY();
 
 	/* wait for ongoing event processing to drain without holding lock:
 	   events modify state and end point refcounts
@@ -272,13 +273,14 @@ M0_INTERNAL void m0_net_tm_fini(struct m0_net_transfer_mc *tm)
 	m0_list_link_fini(&tm->ntm_dom_linkage);
 
 	m0_mutex_unlock(&dom->nd_mutex);
-	return;
+	M0_LEAVE();;
 }
 M0_EXPORTED(m0_net_tm_fini);
 
 M0_INTERNAL int m0_net_tm_start(struct m0_net_transfer_mc *tm, const char *addr)
 {
 	int rc;
+	M0_ENTRY();
 
 	M0_ASSERT(addr != NULL);
 	M0_PRE(tm != NULL);
@@ -303,7 +305,7 @@ M0_INTERNAL int m0_net_tm_start(struct m0_net_transfer_mc *tm, const char *addr)
 	M0_POST(m0_net__tm_invariant(tm));
 	m0_mutex_unlock(&tm->ntm_mutex);
 	M0_ASSERT(rc <= 0);
-	return rc;
+	return M0_RC(rc);
 }
 M0_EXPORTED(m0_net_tm_start);
 
@@ -311,6 +313,7 @@ M0_INTERNAL int m0_net_tm_stop(struct m0_net_transfer_mc *tm, bool abort)
 {
 	int rc;
 	enum m0_net_tm_state oldstate;
+	M0_ENTRY();
 
 	m0_mutex_lock(&tm->ntm_mutex);
 	M0_PRE(m0_net__tm_invariant(tm));
@@ -330,7 +333,7 @@ M0_INTERNAL int m0_net_tm_stop(struct m0_net_transfer_mc *tm, bool abort)
 	M0_POST(m0_net__tm_invariant(tm));
 	m0_mutex_unlock(&tm->ntm_mutex);
 	M0_ASSERT(rc <= 0);
-	return rc;
+	return M0_RC(rc);
 }
 M0_EXPORTED(m0_net_tm_stop);
 
diff --git a/reqh/reqh.c b/reqh/reqh.c
index b4e6244..1ed59cb 100644
--- a/reqh/reqh.c
+++ b/reqh/reqh.c
@@ -781,7 +781,7 @@ M0_INTERNAL void m0_reqh_stats_post_addb(struct m0_reqh *reqh)
 	m0_rwlock_read_unlock(&reqh->rh_rwlock);
 
 	for (i = 0; i < m0_reqh_nr_localities(reqh); i++)
-		m0_fom_locality_post_stats(&reqh->rh_fom_dom.fd_localities[i]);
+		m0_fom_locality_post_stats(reqh->rh_fom_dom.fd_localities[i]);
 }
 
 M0_INTERNAL uint64_t m0_reqh_nr_localities(const struct m0_reqh *reqh)
diff --git a/rm/rm_service.c b/rm/rm_service.c
index a951509..5737330 100644
--- a/rm/rm_service.c
+++ b/rm/rm_service.c
@@ -179,8 +179,10 @@ static int rms_start(struct m0_reqh_service *service)
 
 	m0_rm_domain_init(&rms->rms_dom);
 
+	rms->rms_flock_rt.rt_name = "File Lock Resource Type";
+
 	/** Register various resource types */
-	m0_file_lock_type_register(&rms->rms_dom);
+	m0_file_lock_type_register(&rms->rms_dom, &rms->rms_flock_rt);
 
 	return M0_RC(0);
 }
@@ -213,7 +215,7 @@ static void rms_stop(struct m0_reqh_service *service)
 		m0_free(owner);
 	} m0_tl_endfor;
 
-	m0_file_lock_type_deregister();
+	m0_file_lock_type_deregister(&rms->rms_flock_rt);
 	m0_rm_domain_fini(&rms->rms_dom);
 
 	M0_LEAVE();
diff --git a/rm/rm_service.h b/rm/rm_service.h
index e23306f..ca45c34 100644
--- a/rm/rm_service.h
+++ b/rm/rm_service.h
@@ -70,13 +70,19 @@
 
 struct m0_reqh_rm_service {
 	/** Request handler service representation */
-	struct m0_reqh_service rms_svc;
+	struct m0_reqh_service     rms_svc;
+
 	/** Resource manager domain */
-	struct m0_rm_domain    rms_dom;
+	struct m0_rm_domain        rms_dom;
+
+	/** Supported type: file lock */
+	struct m0_rm_resource_type rms_flock_rt;
+
 	/** Owners this service has created. */
-	struct m0_tl           rms_owners;
+	struct m0_tl               rms_owners;
+
 	/** rms_magic == M0_RM_SERVICE_MAGIC */
-	uint64_t               rms_magic;
+	uint64_t                   rms_magic;
 };
 
 M0_INTERNAL int m0_rms_register(void);
diff --git a/rpc/it/st.sh b/rpc/it/st.sh
index b27bd59..1b5463d 100755
--- a/rpc/it/st.sh
+++ b/rpc/it/st.sh
@@ -1,5 +1,4 @@
 #!/bin/bash
-
 CWD=$(cd "$( dirname "$0")" && pwd)
 SRC="$CWD/../.."
 
diff --git a/scripts/m0 b/scripts/m0
index cd79203..9353eb2 100755
--- a/scripts/m0
+++ b/scripts/m0
@@ -75,6 +75,9 @@ run_st() {
     ## Degraded-mode IO ST
     $SUDO "$SRC/m0t1fs/linux_kernel/st/m0t1fs_dgmode_io.sh"
 
+    ## multi-clients support ST
+    $SUDO "$SRC/m0t1fs/linux_kernel/st/m0t1fs_multi_clients.sh"
+
     ## Pool machine query/set testing.
     $SUDO "$SRC/m0t1fs/linux_kernel/st/m0t1fs_poolmach.sh"
 
diff --git a/stats/stats_srv.c b/stats/stats_srv.c
index aa44231..1086c48 100644
--- a/stats/stats_srv.c
+++ b/stats/stats_srv.c
@@ -208,8 +208,6 @@ const struct m0_fom_type_ops stats_query_fom_type_ops;
 struct m0_sm_conf stats_update_fom_sm_conf;
 struct m0_sm_conf stats_query_fom_sm_conf;
 
-static int stats_add(struct m0_tl *stats_list, struct m0_stats_sum *sum);
-
 #define SUM_DATA_SIZE(sum_data) (sum_data->ss_data.au64s_nr * sizeof(uint64_t))
 
 /*
-- 
1.8.3.2

