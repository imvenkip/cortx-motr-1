From 91ac9343b8bbc663075470fe9e2134ae5d300aeb Mon Sep 17 00:00:00 2001
From: Maxim Medved <max_medved@xyratex.com>
Date: Tue, 14 Jan 2014 17:27:03 +0200
Subject: [PATCH 48/96] be/fl: moved from be/alloc to its own files

---
 be/Makefile.sub    |   2 +
 be/alloc.c         | 291 --------------------------------------------
 be/alloc.h         |  58 +--------
 be/fl.c            | 344 +++++++++++++++++++++++++++++++++++++++++++++++++++++
 be/fl.h            | 105 ++++++++++++++++
 be/ut/Makefile.sub |   1 +
 be/ut/alloc.c      | 116 ------------------
 be/ut/fl.c         | 157 ++++++++++++++++++++++++
 8 files changed, 610 insertions(+), 464 deletions(-)
 create mode 100644 be/fl.c
 create mode 100644 be/fl.h
 create mode 100644 be/ut/fl.c

diff --git a/be/Makefile.sub b/be/Makefile.sub
index 6be105e..36b6a6d 100644
--- a/be/Makefile.sub
+++ b/be/Makefile.sub
@@ -6,6 +6,7 @@ nobase_mero_include_HEADERS += be/alloc.h           \
 			       be/engine.h	    \
                                be/extmap.h          \
                                be/extmap_internal.h \
+                               be/fl.h              \
                                be/io.h              \
                                be/list.h            \
                                be/log.h             \
@@ -32,6 +33,7 @@ mero_libmero_la_SOURCES += be/alloc.c     	\
 			   be/extmap_xc.c	\
 			   be/domain.c		\
 			   be/engine.c       	\
+			   be/fl.c       	\
 			   be/io.c        	\
 			   be/list.c      	\
 			   be/log.c       	\
diff --git a/be/alloc.c b/be/alloc.c
index 1ba1fd1..ff61c1e 100644
--- a/be/alloc.c
+++ b/be/alloc.c
@@ -171,297 +171,6 @@ M0_TL_DESCR_DEFINE(chunks_all, "list of all chunks in m0_be_allocator",
 		   M0_BE_ALLOC_ALL_LINK_MAGIC, M0_BE_ALLOC_ALL_MAGIC);
 M0_TL_DEFINE(chunks_all, static, struct be_alloc_chunk);
 
-M0_TL_DESCR_DEFINE(chunks_free, "XXX list of free chunks in m0_be_allocator",
-		   static, struct be_alloc_chunk,
-		   bac_linkage_free, bac_magic_free,
-		   M0_BE_ALLOC_FREE_LINK_MAGIC, M0_BE_ALLOC_FREE_MAGIC);
-M0_TL_DEFINE(chunks_free, static, struct be_alloc_chunk);
-
-M0_TL_DESCR_DEFINE(chunk_sizes, "DOCUMENTME",
-		   static, struct m0_be_fl_size,
-		   bfs_size_link, bfs_size_link_magic,
-	/* XXX */  M0_BE_ALLOC_FREE_LINK_MAGIC + 1, M0_BE_ALLOC_FREE_MAGIC + 1);
-M0_TL_DEFINE(chunk_sizes, static, struct be_alloc_chunk);
-
-static struct m0_be_list *be_fl_list(struct m0_be_fl *fl, unsigned long index)
-{
-	M0_PRE(index < ARRAY_SIZE(fl->bfl_free));
-
-	return &fl->bfl_free[index].bfs_list;
-};
-
-static bool be_fl_list_is_empty(struct m0_be_fl *fl, unsigned long index)
-{
-	bool empty;
-
-	M0_BE_OP_SYNC(op,
-		      empty = m0_be_list_is_empty(be_fl_list(fl, index), &op));
-	return empty;
-}
-
-M0_INTERNAL void m0_be_fl_init(struct m0_be_fl *fl, struct m0_be_seg *seg)
-{
-	int i;
-
-	m0_be_list_init(&fl->bfl_free_list, seg);
-	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
-		m0_be_list_init(be_fl_list(fl, i), seg);
-		m0_be_tlink_init(be_fl_list(fl, i), &fl->bfl_free_list);
-	}
-
-	/* XXX temporary solution to make capturing checkers pass */
-	m0_be_reg__write(&M0_BE_REG_PTR(seg, fl));	/* XXX */
-}
-
-M0_INTERNAL void m0_be_fl_fini(struct m0_be_fl *fl)
-{
-	struct m0_be_seg *seg = fl->bfl_free_list.bl_seg;
-	int		  i;
-
-	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
-		m0_be_tlink_fini(be_fl_list(fl, i), &fl->bfl_free_list);
-		m0_be_list_fini(be_fl_list(fl, i));
-	}
-	m0_be_list_fini(&fl->bfl_free_list);
-
-	/* XXX temporary solution to make capturing checkers pass */
-	m0_be_reg__write(&M0_BE_REG_PTR(seg, fl));	/* XXX */
-}
-
-M0_INTERNAL void m0_be_fl_create(struct m0_be_fl *fl,
-				 struct m0_be_tx *tx,
-				 struct m0_be_seg *seg)
-{
-	int i;
-
-	M0_BE_OP_SYNC(op, m0_be_list_create(
-		    &fl->bfl_free_list, tx, &op, seg, &chunk_sizes_tl));
-	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
-		M0_BE_OP_SYNC(op, m0_be_list_create(
-			be_fl_list(fl, i), tx, &op, seg, &chunks_free_tl));
-		M0_BE_OP_SYNC(op,
-		      m0_be_tlink_create(be_fl_list(fl, i), tx, &op,
-					 &fl->bfl_free_list));
-	}
-}
-
-M0_INTERNAL void m0_be_fl_destroy(struct m0_be_fl *fl, struct m0_be_tx *tx)
-{
-	int i;
-
-	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
-		M0_BE_OP_SYNC(op,
-		      m0_be_tlink_destroy(be_fl_list(fl, i), tx, &op,
-					  &fl->bfl_free_list));
-		M0_BE_OP_SYNC(op, m0_be_list_destroy(be_fl_list(fl, i),
-						     tx, &op));
-	}
-	M0_BE_OP_SYNC(op, m0_be_list_destroy(&fl->bfl_free_list, tx, &op));
-}
-
-M0_INTERNAL unsigned long m0_be_fl_index_round_up(struct m0_be_fl *fl,
-						  m0_bcount_t size)
-{
-	unsigned long index;
-
-	index = m0_align(size, M0_BE_FL_STEP) / M0_BE_FL_STEP;
-	return index > M0_BE_FL_NR ? M0_BE_FL_NR : index;
-}
-
-M0_INTERNAL unsigned long m0_be_fl_index_round_down_chunk(struct m0_be_fl *fl,
-						  struct be_alloc_chunk *chunk)
-{
-	unsigned long index;
-
-	index = chunk->bac_size / M0_BE_FL_STEP;
-	return index > M0_BE_FL_NR ? M0_BE_FL_NR : index;
-}
-
-M0_INTERNAL bool m0_be_fl__invariant(struct m0_be_fl *fl)
-{
-	struct be_alloc_chunk *chunk;
-	struct m0_be_fl_size  *fl_size;
-	struct m0_be_fl_size  *prev;
-	bool		       empty;
-	int		       i;
-
-	/* check if there is only empty lists in bfl_free_list */
-	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
-		M0_BE_OP_SYNC(op, empty =
-			      m0_be_list_is_empty(be_fl_list(fl, i), &op));
-		if (_0C(equi(m0_tlink_is_in(&chunk_sizes_tl, &fl->bfl_free[i]),
-			     empty)))
-			return false;
-	}
-	/* check if bfl_free_list is ordered */
-	prev = NULL;
-	m0_tlist_for(&chunk_sizes_tl, &fl->bfl_free_list.bl_list, fl_size) {
-		if (_0C(prev >= fl_size))
-			return false;
-		prev = fl_size;
-	} m0_tlist_endfor;
-	/* check if each bfs_list contains chunks with appropriate size */
-	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
-		m0_tlist_for(&chunks_free_tl,
-			     &be_fl_list(fl, i)->bl_list, chunk) {
-			if (_0C(m0_be_fl_index_round_down_chunk(fl,
-								chunk) != i))
-				return false;
-		} m0_tlist_endfor;
-	}
-	return true;
-}
-
-/* XXX naming */
-M0_INTERNAL void m0_be_fl_add_size(struct m0_be_fl *fl,
-				   struct m0_be_tx *tx,
-				   unsigned long index)
-{
-	struct m0_be_fl_size *fl_size;
-	struct m0_be_fl_size *fl_size_new = &fl->bfl_free[index];
-
-	m0_tlist_for(&chunk_sizes_tl, &fl->bfl_free_list.bl_list, fl_size) {
-		if (fl_size > fl_size_new)
-			break;
-	} m0_tlist_endfor;
-	if (fl_size > fl_size_new) {
-		M0_BE_OP_SYNC(op, m0_be_list_add_before(&fl->bfl_free_list,
-							&op, tx, fl_size,
-							fl_size_new));
-	} else {
-		M0_BE_OP_SYNC(op, m0_be_list_add_tail(&fl->bfl_free_list,
-						      &op, tx, fl_size_new));
-	}
-}
-
-M0_INTERNAL void m0_be_fl_del_size(struct m0_be_fl *fl,
-				   struct m0_be_tx *tx,
-				   unsigned long index)
-{
-	M0_BE_OP_SYNC(op, m0_be_list_del(&fl->bfl_free_list,
-					 &op, tx, &fl->bfl_free[index]));
-}
-
-M0_INTERNAL void m0_be_fl_add(struct m0_be_fl *fl,
-			      struct m0_be_tx *tx,
-			      struct be_alloc_chunk *chunk)
-{
-	unsigned long index = m0_be_fl_index_round_down_chunk(fl, chunk);
-	bool	      empty;
-
-	M0_PRE_EX(m0_be_fl__invariant(fl));
-
-	empty = be_fl_list_is_empty(fl, index);
-	if (empty)
-		m0_be_fl_add_size(fl, tx, index);
-	M0_BE_OP_SYNC(op, m0_be_tlink_create(chunk, tx, &op,
-					     be_fl_list(fl, index)));
-	M0_BE_OP_SYNC(op, m0_be_list_add(be_fl_list(fl, index),
-					 &op, tx, chunk));
-
-	M0_POST_EX(m0_be_fl__invariant(fl));
-}
-
-M0_INTERNAL void m0_be_fl_del(struct m0_be_fl *fl,
-			      struct m0_be_tx *tx,
-			      struct be_alloc_chunk *chunk)
-{
-	unsigned long index = m0_be_fl_index_round_down_chunk(fl, chunk);
-	bool	      empty;
-
-	M0_PRE_EX(m0_be_fl__invariant(fl));
-
-	M0_BE_OP_SYNC(op, m0_be_list_del(be_fl_list(fl, index),
-					 &op, tx, chunk));
-	M0_BE_OP_SYNC(op, m0_be_tlink_destroy(chunk, tx, &op,
-					      be_fl_list(fl, index)));
-	empty = be_fl_list_is_empty(fl, index);
-	if (empty)
-		m0_be_fl_del_size(fl, tx, index);
-
-	M0_POST_EX(m0_be_fl__invariant(fl));
-}
-
-M0_INTERNAL void m0_be_fl_resize(struct m0_be_fl *fl,
-				 struct m0_be_tx *tx,
-				 struct be_alloc_chunk *chunk,
-				 m0_bcount_t size)
-{
-	m0_be_fl_del(fl, tx, chunk);
-	chunk->bac_size = size;
-	m0_be_fl_add(fl, tx, chunk);
-}
-
-/** find empty chunk with size at least 'size' */
-M0_INTERNAL struct be_alloc_chunk *m0_be_fl_pick(struct m0_be_fl *fl,
-						 m0_bcount_t size)
-{
-	struct be_alloc_chunk *chunk;
-	struct be_alloc_chunk *iter;
-	unsigned long	       index;
-	struct m0_be_list     *flist;
-	int		       i;
-
-	M0_PRE_EX(m0_be_fl__invariant(fl));
-
-	for (index = m0_be_fl_index_round_up(fl, size);
-	     index < ARRAY_SIZE(fl->bfl_free); ++index) {
-		if (!be_fl_list_is_empty(fl, index))
-			break;
-	}
-
-	flist = index == ARRAY_SIZE(fl->bfl_free) ? NULL :
-						    be_fl_list(fl, index);
-	chunk = flist == NULL ? NULL : chunks_free_tlist_head(&flist->bl_list);
-	if (index == M0_BE_FL_NR && chunk != NULL) {
-		chunk = NULL;
-		i = 0;
-		m0_tlist_for(&chunks_free_tl, &flist->bl_list, iter) {
-			if (iter->bac_size > size &&
-			    ergo(chunk != NULL,
-				 chunk->bac_size > iter->bac_size)) {
-				chunk = iter;
-			}
-			++i;
-			if (i >= M0_BE_FL_PICK_SCAN_LIMIT && chunk != NULL)
-				break;
-		} m0_tlist_endfor;
-	}
-	M0_POST(ergo(chunk != NULL, chunk->bac_size >= size));
-	return chunk;
-}
-
-M0_INTERNAL void m0_be_fl_credit(struct m0_be_fl *fl,
-				 enum m0_be_fl_op fl_op,
-				 struct m0_be_tx_credit *accum)
-{
-	switch (fl_op) {
-	case M0_BFL_CREATE:
-	case M0_BFL_DESTROY:
-		/* XXX make proper credit calculation */
-		m0_be_tx_credit_add(accum, &M0_BE_TX_CREDIT(0x1000, 0x10000));
-		break;
-	case M0_BFL_ADD:
-		m0_be_list_credit(&fl->bfl_free_list, M0_BLO_INSERT, 1, accum);
-		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_TLINK_CREATE, 1,
-				  accum);
-		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_INSERT, 1, accum);
-		break;
-	case M0_BFL_DEL:
-		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_DELETE, 1, accum);
-		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_TLINK_DESTROY, 1,
-				  accum);
-		m0_be_list_credit(&fl->bfl_free_list, M0_BLO_DELETE, 1, accum);
-		break;
-	case M0_BFL_RESIZE:
-		m0_be_fl_credit(fl, M0_BFL_DEL, accum);
-		m0_be_fl_credit(fl, M0_BFL_ADD, accum);
-		break;
-	default:
-		M0_ASSERT_INFO(false, "fl_op = %d", fl_op);
-	}
-}
-
 /* XXX use these accessors everywhere */
 static struct m0_be_list *be_alloc_list_chunks(struct m0_be_allocator *a)
 {
diff --git a/be/alloc.h b/be/alloc.h
index c5079df..e136624 100644
--- a/be/alloc.h
+++ b/be/alloc.h
@@ -26,6 +26,7 @@
 #include "lib/mutex.h"
 
 #include "be/list.h"	/* m0_be_list */
+#include "be/fl.h"	/* m0_be_fl */
 
 struct m0_be_op;
 struct m0_be_seg;
@@ -40,63 +41,6 @@ struct m0_be_tx_credit;
  */
 
 enum {
-	M0_BE_FL_STEP = 8,	/**< each size is increased to this boundary */
-	M0_BE_FL_NR = 128,	/*<* number of free lists for each size */
-	M0_BE_FL_PICK_SCAN_LIMIT = 0x10, /**< scan limit for searching in
-					      chunks with size >=
-					      M0_BE_FL_NR * M0_BE_FL_STEP */
-};
-
-enum m0_be_fl_op {
-	M0_BFL_CREATE,
-	M0_BFL_DESTROY,
-	M0_BFL_ADD,
-	M0_BFL_DEL,
-	M0_BFL_RESIZE,
-};
-
-/** m0_be free list for some size of chunks */
-struct m0_be_fl_size {
-	struct m0_be_list bfs_list;
-	struct m0_tlink	  bfs_size_link;
-	uint64_t	  bfs_size_link_magic;
-};
-
-/** m0_be free list */
-struct m0_be_fl {
-	struct m0_be_fl_size bfl_free[M0_BE_FL_NR + 1];
-	struct m0_be_list    bfl_free_list;
-};
-
-struct be_alloc_chunk;
-
-M0_INTERNAL void m0_be_fl_init(struct m0_be_fl *fl, struct m0_be_seg *seg);
-M0_INTERNAL void m0_be_fl_fini(struct m0_be_fl *fl);
-M0_INTERNAL bool m0_be_fl__invariant(struct m0_be_fl *fl);
-
-M0_INTERNAL void m0_be_fl_create(struct m0_be_fl *fl,
-				 struct m0_be_tx *tx,
-				 struct m0_be_seg *seg);
-M0_INTERNAL void m0_be_fl_destroy(struct m0_be_fl *fl, struct m0_be_tx *tx);
-
-M0_INTERNAL void m0_be_fl_add(struct m0_be_fl *fl,
-			      struct m0_be_tx *tx,
-			      struct be_alloc_chunk *chunk);
-M0_INTERNAL void m0_be_fl_del(struct m0_be_fl *fl,
-			      struct m0_be_tx *tx,
-			      struct be_alloc_chunk *chunk);
-M0_INTERNAL void m0_be_fl_resize(struct m0_be_fl *fl,
-				 struct m0_be_tx *tx,
-				 struct be_alloc_chunk *chunk,
-				 m0_bcount_t size);
-M0_INTERNAL struct be_alloc_chunk *m0_be_fl_pick(struct m0_be_fl *fl,
-						 m0_bcount_t size);
-
-M0_INTERNAL void m0_be_fl_credit(struct m0_be_fl *fl,
-				 enum m0_be_fl_op fl_op,
-				 struct m0_be_tx_credit *accum);
-
-enum {
 	/**
 	 * Allocated memory will be aligned using at least this shift.
 	 * @see m0_be_alloc(), m0_be_allocator_credit().
diff --git a/be/fl.c b/be/fl.c
new file mode 100644
index 0000000..773a8ab
--- /dev/null
+++ b/be/fl.c
@@ -0,0 +1,344 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2014 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Maxim Medved <max_medved@xyratex.com>
+ * Original creation date: 14-Jan-2014
+ */
+
+#include "be/fl.h"
+
+#include "lib/assert.h"		/* M0_PRE */
+#include "lib/misc.h"		/* ARRAY_SIZE */
+
+#include "mero/magic.h"		/* M0_BE_ALLOC_FREE_LINK_MAGIC */
+
+#include "be/op.h"		/* M0_BE_OP_SYNC */
+#include "be/seg.h"		/* m0_be_reg__write */
+#include "be/tx_credit.h"	/* m0_be_tx_credit */
+#include "be/alloc_internal.h"	/* be_alloc_chunk */
+
+/**
+ * @addtogroup be
+ *
+ * @{
+ */
+
+M0_TL_DESCR_DEFINE(chunks_free, "XXX list of free chunks in m0_be_allocator",
+		   static, struct be_alloc_chunk,
+		   bac_linkage_free, bac_magic_free,
+		   M0_BE_ALLOC_FREE_LINK_MAGIC, M0_BE_ALLOC_FREE_MAGIC);
+M0_TL_DEFINE(chunks_free, static, struct be_alloc_chunk);
+
+M0_TL_DESCR_DEFINE(chunk_sizes, "DOCUMENTME",
+		   static, struct m0_be_fl_size,
+		   bfs_size_link, bfs_size_link_magic,
+	/* XXX */  M0_BE_ALLOC_FREE_LINK_MAGIC + 1, M0_BE_ALLOC_FREE_MAGIC + 1);
+M0_TL_DEFINE(chunk_sizes, static, struct be_alloc_chunk);
+
+static struct m0_be_list *be_fl_list(struct m0_be_fl *fl, unsigned long index)
+{
+	M0_PRE(index < ARRAY_SIZE(fl->bfl_free));
+
+	return &fl->bfl_free[index].bfs_list;
+};
+
+static bool be_fl_list_is_empty(struct m0_be_fl *fl, unsigned long index)
+{
+	bool empty;
+
+	M0_BE_OP_SYNC(op,
+		      empty = m0_be_list_is_empty(be_fl_list(fl, index), &op));
+	return empty;
+}
+
+M0_INTERNAL void m0_be_fl_init(struct m0_be_fl *fl, struct m0_be_seg *seg)
+{
+	int i;
+
+	m0_be_list_init(&fl->bfl_free_list, seg);
+	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
+		m0_be_list_init(be_fl_list(fl, i), seg);
+		m0_be_tlink_init(be_fl_list(fl, i), &fl->bfl_free_list);
+	}
+
+	/* XXX temporary solution to make capturing checkers pass */
+	m0_be_reg__write(&M0_BE_REG_PTR(seg, fl));	/* XXX */
+}
+
+M0_INTERNAL void m0_be_fl_fini(struct m0_be_fl *fl)
+{
+	struct m0_be_seg *seg = fl->bfl_free_list.bl_seg;
+	int		  i;
+
+	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
+		m0_be_tlink_fini(be_fl_list(fl, i), &fl->bfl_free_list);
+		m0_be_list_fini(be_fl_list(fl, i));
+	}
+	m0_be_list_fini(&fl->bfl_free_list);
+
+	/* XXX temporary solution to make capturing checkers pass */
+	m0_be_reg__write(&M0_BE_REG_PTR(seg, fl));	/* XXX */
+}
+
+M0_INTERNAL void m0_be_fl_create(struct m0_be_fl *fl,
+				 struct m0_be_tx *tx,
+				 struct m0_be_seg *seg)
+{
+	int i;
+
+	M0_BE_OP_SYNC(op, m0_be_list_create(
+		    &fl->bfl_free_list, tx, &op, seg, &chunk_sizes_tl));
+	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
+		M0_BE_OP_SYNC(op, m0_be_list_create(
+			be_fl_list(fl, i), tx, &op, seg, &chunks_free_tl));
+		M0_BE_OP_SYNC(op,
+		      m0_be_tlink_create(be_fl_list(fl, i), tx, &op,
+					 &fl->bfl_free_list));
+	}
+}
+
+M0_INTERNAL void m0_be_fl_destroy(struct m0_be_fl *fl, struct m0_be_tx *tx)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
+		M0_BE_OP_SYNC(op,
+		      m0_be_tlink_destroy(be_fl_list(fl, i), tx, &op,
+					  &fl->bfl_free_list));
+		M0_BE_OP_SYNC(op, m0_be_list_destroy(be_fl_list(fl, i),
+						     tx, &op));
+	}
+	M0_BE_OP_SYNC(op, m0_be_list_destroy(&fl->bfl_free_list, tx, &op));
+}
+
+M0_INTERNAL unsigned long m0_be_fl_index_round_up(struct m0_be_fl *fl,
+						  m0_bcount_t size)
+{
+	unsigned long index;
+
+	index = m0_align(size, M0_BE_FL_STEP) / M0_BE_FL_STEP;
+	return index > M0_BE_FL_NR ? M0_BE_FL_NR : index;
+}
+
+M0_INTERNAL unsigned long m0_be_fl_index_round_down_chunk(struct m0_be_fl *fl,
+						  struct be_alloc_chunk *chunk)
+{
+	unsigned long index;
+
+	index = chunk->bac_size / M0_BE_FL_STEP;
+	return index > M0_BE_FL_NR ? M0_BE_FL_NR : index;
+}
+
+M0_INTERNAL bool m0_be_fl__invariant(struct m0_be_fl *fl)
+{
+	struct be_alloc_chunk *chunk;
+	struct m0_be_fl_size  *fl_size;
+	struct m0_be_fl_size  *prev;
+	bool		       empty;
+	int		       i;
+
+	/* check if there is only empty lists in bfl_free_list */
+	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
+		M0_BE_OP_SYNC(op, empty =
+			      m0_be_list_is_empty(be_fl_list(fl, i), &op));
+		if (_0C(equi(m0_tlink_is_in(&chunk_sizes_tl, &fl->bfl_free[i]),
+			     empty)))
+			return false;
+	}
+	/* check if bfl_free_list is ordered */
+	prev = NULL;
+	m0_tlist_for(&chunk_sizes_tl, &fl->bfl_free_list.bl_list, fl_size) {
+		if (_0C(prev >= fl_size))
+			return false;
+		prev = fl_size;
+	} m0_tlist_endfor;
+	/* check if each bfs_list contains chunks with appropriate size */
+	for (i = 0; i < ARRAY_SIZE(fl->bfl_free); ++i) {
+		m0_tlist_for(&chunks_free_tl,
+			     &be_fl_list(fl, i)->bl_list, chunk) {
+			if (_0C(m0_be_fl_index_round_down_chunk(fl,
+								chunk) != i))
+				return false;
+		} m0_tlist_endfor;
+	}
+	return true;
+}
+
+/* XXX naming */
+M0_INTERNAL void m0_be_fl_add_size(struct m0_be_fl *fl,
+				   struct m0_be_tx *tx,
+				   unsigned long index)
+{
+	struct m0_be_fl_size *fl_size;
+	struct m0_be_fl_size *fl_size_new = &fl->bfl_free[index];
+
+	m0_tlist_for(&chunk_sizes_tl, &fl->bfl_free_list.bl_list, fl_size) {
+		if (fl_size > fl_size_new)
+			break;
+	} m0_tlist_endfor;
+	if (fl_size > fl_size_new) {
+		M0_BE_OP_SYNC(op, m0_be_list_add_before(&fl->bfl_free_list,
+							&op, tx, fl_size,
+							fl_size_new));
+	} else {
+		M0_BE_OP_SYNC(op, m0_be_list_add_tail(&fl->bfl_free_list,
+						      &op, tx, fl_size_new));
+	}
+}
+
+M0_INTERNAL void m0_be_fl_del_size(struct m0_be_fl *fl,
+				   struct m0_be_tx *tx,
+				   unsigned long index)
+{
+	M0_BE_OP_SYNC(op, m0_be_list_del(&fl->bfl_free_list,
+					 &op, tx, &fl->bfl_free[index]));
+}
+
+M0_INTERNAL void m0_be_fl_add(struct m0_be_fl *fl,
+			      struct m0_be_tx *tx,
+			      struct be_alloc_chunk *chunk)
+{
+	unsigned long index = m0_be_fl_index_round_down_chunk(fl, chunk);
+	bool	      empty;
+
+	M0_PRE_EX(m0_be_fl__invariant(fl));
+
+	empty = be_fl_list_is_empty(fl, index);
+	if (empty)
+		m0_be_fl_add_size(fl, tx, index);
+	M0_BE_OP_SYNC(op, m0_be_tlink_create(chunk, tx, &op,
+					     be_fl_list(fl, index)));
+	M0_BE_OP_SYNC(op, m0_be_list_add(be_fl_list(fl, index),
+					 &op, tx, chunk));
+
+	M0_POST_EX(m0_be_fl__invariant(fl));
+}
+
+M0_INTERNAL void m0_be_fl_del(struct m0_be_fl *fl,
+			      struct m0_be_tx *tx,
+			      struct be_alloc_chunk *chunk)
+{
+	unsigned long index = m0_be_fl_index_round_down_chunk(fl, chunk);
+	bool	      empty;
+
+	M0_PRE_EX(m0_be_fl__invariant(fl));
+
+	M0_BE_OP_SYNC(op, m0_be_list_del(be_fl_list(fl, index),
+					 &op, tx, chunk));
+	M0_BE_OP_SYNC(op, m0_be_tlink_destroy(chunk, tx, &op,
+					      be_fl_list(fl, index)));
+	empty = be_fl_list_is_empty(fl, index);
+	if (empty)
+		m0_be_fl_del_size(fl, tx, index);
+
+	M0_POST_EX(m0_be_fl__invariant(fl));
+}
+
+M0_INTERNAL void m0_be_fl_resize(struct m0_be_fl *fl,
+				 struct m0_be_tx *tx,
+				 struct be_alloc_chunk *chunk,
+				 m0_bcount_t size)
+{
+	m0_be_fl_del(fl, tx, chunk);
+	chunk->bac_size = size;
+	m0_be_fl_add(fl, tx, chunk);
+}
+
+/** find empty chunk with size at least 'size' */
+M0_INTERNAL struct be_alloc_chunk *m0_be_fl_pick(struct m0_be_fl *fl,
+						 m0_bcount_t size)
+{
+	struct be_alloc_chunk *chunk;
+	struct be_alloc_chunk *iter;
+	unsigned long	       index;
+	struct m0_be_list     *flist;
+	int		       i;
+
+	M0_PRE_EX(m0_be_fl__invariant(fl));
+
+	for (index = m0_be_fl_index_round_up(fl, size);
+	     index < ARRAY_SIZE(fl->bfl_free); ++index) {
+		if (!be_fl_list_is_empty(fl, index))
+			break;
+	}
+
+	flist = index == ARRAY_SIZE(fl->bfl_free) ? NULL :
+						    be_fl_list(fl, index);
+	chunk = flist == NULL ? NULL : chunks_free_tlist_head(&flist->bl_list);
+	if (index == M0_BE_FL_NR && chunk != NULL) {
+		chunk = NULL;
+		i = 0;
+		m0_tlist_for(&chunks_free_tl, &flist->bl_list, iter) {
+			if (iter->bac_size > size &&
+			    ergo(chunk != NULL,
+				 chunk->bac_size > iter->bac_size)) {
+				chunk = iter;
+			}
+			++i;
+			if (i >= M0_BE_FL_PICK_SCAN_LIMIT && chunk != NULL)
+				break;
+		} m0_tlist_endfor;
+	}
+	M0_POST(ergo(chunk != NULL, chunk->bac_size >= size));
+	return chunk;
+}
+
+M0_INTERNAL void m0_be_fl_credit(struct m0_be_fl *fl,
+				 enum m0_be_fl_op fl_op,
+				 struct m0_be_tx_credit *accum)
+{
+	switch (fl_op) {
+	case M0_BFL_CREATE:
+	case M0_BFL_DESTROY:
+		/* XXX make proper credit calculation */
+		m0_be_tx_credit_add(accum, &M0_BE_TX_CREDIT(0x1000, 0x10000));
+		break;
+	case M0_BFL_ADD:
+		m0_be_list_credit(&fl->bfl_free_list, M0_BLO_INSERT, 1, accum);
+		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_TLINK_CREATE, 1,
+				  accum);
+		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_INSERT, 1, accum);
+		break;
+	case M0_BFL_DEL:
+		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_DELETE, 1, accum);
+		m0_be_list_credit(be_fl_list(fl, 0), M0_BLO_TLINK_DESTROY, 1,
+				  accum);
+		m0_be_list_credit(&fl->bfl_free_list, M0_BLO_DELETE, 1, accum);
+		break;
+	case M0_BFL_RESIZE:
+		m0_be_fl_credit(fl, M0_BFL_DEL, accum);
+		m0_be_fl_credit(fl, M0_BFL_ADD, accum);
+		break;
+	default:
+		M0_ASSERT_INFO(false, "fl_op = %d", fl_op);
+	}
+}
+
+
+/** @} end of be group */
+
+/*
+ *  Local variables:
+ *  c-indentation-style: "K&R"
+ *  c-basic-offset: 8
+ *  tab-width: 8
+ *  fill-column: 80
+ *  scroll-step: 1
+ *  End:
+ */
+/*
+ * vim: tabstop=8 shiftwidth=8 noexpandtab textwidth=80 nowrap
+ */
diff --git a/be/fl.h b/be/fl.h
new file mode 100644
index 0000000..e3bb3cc
--- /dev/null
+++ b/be/fl.h
@@ -0,0 +1,105 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2014 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Maxim Medved <max_medved@xyratex.com>
+ * Original creation date: 14-Jan-2014
+ */
+
+#pragma once
+
+#ifndef __MERO_BE_FL_H__
+#define __MERO_BE_FL_H__
+
+#include "be/list.h"	/* m0_be_list */
+
+/**
+ * @defgroup be
+ *
+ * @{
+ */
+
+enum {
+	M0_BE_FL_STEP = 8,	/**< each size is increased to this boundary */
+	M0_BE_FL_NR = 128,	/*<* number of free lists for each size */
+	M0_BE_FL_PICK_SCAN_LIMIT = 0x10, /**< scan limit for searching in
+					      chunks with size >=
+					      M0_BE_FL_NR * M0_BE_FL_STEP */
+};
+
+enum m0_be_fl_op {
+	M0_BFL_CREATE,
+	M0_BFL_DESTROY,
+	M0_BFL_ADD,
+	M0_BFL_DEL,
+	M0_BFL_RESIZE,
+};
+
+/** m0_be free list for some size of chunks */
+struct m0_be_fl_size {
+	struct m0_be_list bfs_list;
+	struct m0_tlink	  bfs_size_link;
+	uint64_t	  bfs_size_link_magic;
+};
+
+/** m0_be free list */
+struct m0_be_fl {
+	struct m0_be_fl_size bfl_free[M0_BE_FL_NR + 1];
+	struct m0_be_list    bfl_free_list;
+};
+
+struct be_alloc_chunk;
+
+M0_INTERNAL void m0_be_fl_init(struct m0_be_fl *fl, struct m0_be_seg *seg);
+M0_INTERNAL void m0_be_fl_fini(struct m0_be_fl *fl);
+M0_INTERNAL bool m0_be_fl__invariant(struct m0_be_fl *fl);
+
+M0_INTERNAL void m0_be_fl_create(struct m0_be_fl *fl,
+				 struct m0_be_tx *tx,
+				 struct m0_be_seg *seg);
+M0_INTERNAL void m0_be_fl_destroy(struct m0_be_fl *fl, struct m0_be_tx *tx);
+
+M0_INTERNAL void m0_be_fl_add(struct m0_be_fl *fl,
+			      struct m0_be_tx *tx,
+			      struct be_alloc_chunk *chunk);
+M0_INTERNAL void m0_be_fl_del(struct m0_be_fl *fl,
+			      struct m0_be_tx *tx,
+			      struct be_alloc_chunk *chunk);
+M0_INTERNAL void m0_be_fl_resize(struct m0_be_fl *fl,
+				 struct m0_be_tx *tx,
+				 struct be_alloc_chunk *chunk,
+				 m0_bcount_t size);
+M0_INTERNAL struct be_alloc_chunk *m0_be_fl_pick(struct m0_be_fl *fl,
+						 m0_bcount_t size);
+
+M0_INTERNAL void m0_be_fl_credit(struct m0_be_fl *fl,
+				 enum m0_be_fl_op fl_op,
+				 struct m0_be_tx_credit *accum);
+
+/** @} end of be group */
+#endif /* __MERO_BE_FL_H__ */
+
+/*
+ *  Local variables:
+ *  c-indentation-style: "K&R"
+ *  c-basic-offset: 8
+ *  tab-width: 8
+ *  fill-column: 80
+ *  scroll-step: 1
+ *  End:
+ */
+/*
+ * vim: tabstop=8 shiftwidth=8 noexpandtab textwidth=80 nowrap
+ */
diff --git a/be/ut/Makefile.sub b/be/ut/Makefile.sub
index 9838294..c8df8d1 100644
--- a/be/ut/Makefile.sub
+++ b/be/ut/Makefile.sub
@@ -2,6 +2,7 @@ ut_libmero_ut_la_SOURCES += be/ut/alloc.c           \
                             be/ut/btree.c           \
                             be/ut/domain.c          \
                             be/ut/extmap.c          \
+                            be/ut/fl.c              \
                             be/ut/helper.c          \
                             be/ut/helper.h          \
                             be/ut/io.c              \
diff --git a/be/ut/alloc.c b/be/ut/alloc.c
index 4aea8ec..265d409 100644
--- a/be/ut/alloc.c
+++ b/be/ut/alloc.c
@@ -230,122 +230,6 @@ M0_INTERNAL void m0_be_ut_alloc_info(void)
 	m0_be_ut_backend_fini(&be_ut_alloc_backend);
 }
 
-enum {
-	BE_UT_FL_CHUNK_NR  = 0x100,
-	BE_UT_FL_ITER	   = 0x800,
-	BE_UT_FL_SEG_SIZE  = 0x10000,
-	BE_UT_FL_OP_PER_TX = 0x10,
-	BE_UT_FL_SIZE_MAX  = M0_BE_FL_STEP * (M0_BE_FL_NR + 0x10),
-};
-
-static struct m0_be_ut_backend be_ut_fl_backend;
-
-static unsigned int be_ut_fl_rand(unsigned int max, unsigned int *seed)
-{
-	return rand_r(seed) % max;
-}
-
-static m0_bcount_t be_ut_fl_rand_size(unsigned int *seed)
-{
-	return be_ut_fl_rand(BE_UT_FL_SIZE_MAX, seed);
-}
-
-void m0_be_ut_fl(void)
-{
-	static struct m0_be_ut_backend *ut_be = &be_ut_fl_backend;
-	static struct m0_be_ut_seg	ut_seg;
-	static struct m0_be_tx		tx;
-	struct be_alloc_chunk	       *chunks;
-	int			       *chunks_used;
-	struct m0_be_tx_credit		cred;
-	struct m0_be_fl		       *fl;
-	struct m0_be_seg	       *seg = &ut_seg.bus_seg;
-	unsigned int			seed = 0;
-	void			       *addr;
-	int				i;
-	int				rc;
-	int				index;
-	bool				move_chunk;
-	m0_bcount_t			size;
-
-	m0_be_ut_backend_init(ut_be);
-	m0_be_ut_seg_init(&ut_seg, ut_be, BE_UT_FL_SEG_SIZE);
-
-	addr	= seg->bs_addr + m0_be_seg_reserved(seg);
-	fl	= (struct m0_be_fl *)addr;
-	addr   += sizeof *fl;
-	chunks	= (struct be_alloc_chunk *)addr;
-
-	m0_be_fl_init(fl, seg);
-	m0_be_ut_seg_check_persistence(&ut_seg);
-
-	M0_BE_UT_TRANSACT(ut_be, NULL, tx, cred,
-			  m0_be_fl_credit(NULL, M0_BFL_CREATE, &cred),
-			  m0_be_fl_create(fl, tx, seg));
-
-	M0_ALLOC_ARR(chunks_used, BE_UT_FL_CHUNK_NR);
-	M0_ASSERT(chunks_used != NULL);
-
-	for (i = 0; i < BE_UT_FL_ITER; ++i) {
-		if ((i % BE_UT_FL_OP_PER_TX) == 0) {
-			M0_SET0(&tx);
-			m0_be_ut_tx_init(&tx, ut_be);
-
-			cred = M0_BE_TX_CREDIT(0, 0);
-			/* XXX don't use the largest possible credit */
-			m0_be_fl_credit(fl, M0_BFL_RESIZE, &cred);
-			m0_be_tx_credit_mul(&cred, BE_UT_FL_OP_PER_TX);
-			m0_be_tx_prep(&tx, &cred);
-
-			rc = m0_be_tx_open_sync(&tx);
-			M0_ASSERT_INFO(rc == 0, "rc = %d", rc);
-		}
-		index = be_ut_fl_rand(BE_UT_FL_CHUNK_NR, &seed);
-		if (chunks_used[index]) {
-			/* del or resize */
-			move_chunk = be_ut_fl_rand(2, &seed) == 0;
-			if (move_chunk) {
-				size = be_ut_fl_rand_size(&seed);
-				m0_be_fl_resize(fl, &tx, &chunks[index], size);
-				M0_UT_ASSERT(chunks[index].bac_size == size);
-			} else {
-				m0_be_fl_del(fl, &tx, &chunks[index]);
-				chunks_used[index] = false;
-			}
-		} else {
-			/* add */
-			chunks[index].bac_size = be_ut_fl_rand_size(&seed);
-			m0_be_fl_add(fl, &tx, &chunks[index]);
-			chunks_used[index] = true;
-		}
-		if (i + 1 == BE_UT_FL_ITER ||
-		    ((i + 1) % BE_UT_FL_OP_PER_TX) == 0) {
-			m0_be_tx_close_sync(&tx);
-			m0_be_tx_fini(&tx);
-		}
-	}
-
-	for (i = 0; i < BE_UT_FL_CHUNK_NR; ++i) {
-		if (chunks_used[i]) {
-			M0_BE_UT_TRANSACT(ut_be, NULL, tx, cred,
-				  m0_be_fl_credit(NULL, M0_BFL_DEL, &cred),
-				  m0_be_fl_del(fl, tx, &chunks[i]));
-		}
-	}
-
-	m0_free(chunks_used);
-
-	M0_BE_UT_TRANSACT(ut_be, NULL, tx, cred,
-			  m0_be_fl_credit(NULL, M0_BFL_DESTROY, &cred),
-			  m0_be_fl_destroy(fl, tx));
-
-	m0_be_fl_fini(fl);
-	/* m0_be_ut_seg_check_persistence(&ut_seg); */
-
-	m0_be_ut_seg_fini(&ut_seg);
-	m0_be_ut_backend_fini(ut_be);
-}
-
 #undef M0_TRACE_SUBSYSTEM
 
 /*
diff --git a/be/ut/fl.c b/be/ut/fl.c
new file mode 100644
index 0000000..366fa29
--- /dev/null
+++ b/be/ut/fl.c
@@ -0,0 +1,157 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2014 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Maxim Medved <max_medved@xyratex.com>
+ * Original creation date: 14-Jan-2014
+ */
+
+#include "be/fl.h"
+
+#include "ut/ut.h"		/* M0_UT_ASSERT */
+
+#include "be/alloc_internal.h"	/* be_alloc_chunk */
+#include "be/ut/helper.h"	/* m0_be_ut_backend */
+
+#include <stdlib.h>		/* rand_r */
+
+enum {
+	BE_UT_FL_CHUNK_NR  = 0x100,
+	BE_UT_FL_ITER	   = 0x800,
+	BE_UT_FL_SEG_SIZE  = 0x10000,
+	BE_UT_FL_OP_PER_TX = 0x10,
+	BE_UT_FL_SIZE_MAX  = M0_BE_FL_STEP * (M0_BE_FL_NR + 0x10),
+};
+
+static struct m0_be_ut_backend be_ut_fl_backend;
+
+static unsigned int be_ut_fl_rand(unsigned int max, unsigned int *seed)
+{
+	return rand_r(seed) % max;
+}
+
+static m0_bcount_t be_ut_fl_rand_size(unsigned int *seed)
+{
+	return be_ut_fl_rand(BE_UT_FL_SIZE_MAX, seed);
+}
+
+void m0_be_ut_fl(void)
+{
+	static struct m0_be_ut_backend *ut_be = &be_ut_fl_backend;
+	static struct m0_be_ut_seg	ut_seg;
+	static struct m0_be_tx		tx;
+	struct be_alloc_chunk	       *chunks;
+	int			       *chunks_used;
+	struct m0_be_tx_credit		cred;
+	struct m0_be_fl		       *fl;
+	struct m0_be_seg	       *seg = &ut_seg.bus_seg;
+	unsigned int			seed = 0;
+	void			       *addr;
+	int				i;
+	int				rc;
+	int				index;
+	bool				move_chunk;
+	m0_bcount_t			size;
+
+	m0_be_ut_backend_init(ut_be);
+	m0_be_ut_seg_init(&ut_seg, ut_be, BE_UT_FL_SEG_SIZE);
+
+	addr	= seg->bs_addr + m0_be_seg_reserved(seg);
+	fl	= (struct m0_be_fl *)addr;
+	addr   += sizeof *fl;
+	chunks	= (struct be_alloc_chunk *)addr;
+
+	m0_be_fl_init(fl, seg);
+	m0_be_ut_seg_check_persistence(&ut_seg);
+
+	M0_BE_UT_TRANSACT(ut_be, NULL, tx, cred,
+			  m0_be_fl_credit(NULL, M0_BFL_CREATE, &cred),
+			  m0_be_fl_create(fl, tx, seg));
+
+	M0_ALLOC_ARR(chunks_used, BE_UT_FL_CHUNK_NR);
+	M0_ASSERT(chunks_used != NULL);
+
+	for (i = 0; i < BE_UT_FL_ITER; ++i) {
+		if ((i % BE_UT_FL_OP_PER_TX) == 0) {
+			M0_SET0(&tx);
+			m0_be_ut_tx_init(&tx, ut_be);
+
+			cred = M0_BE_TX_CREDIT(0, 0);
+			/* XXX don't use the largest possible credit */
+			m0_be_fl_credit(fl, M0_BFL_RESIZE, &cred);
+			m0_be_tx_credit_mul(&cred, BE_UT_FL_OP_PER_TX);
+			m0_be_tx_prep(&tx, &cred);
+
+			rc = m0_be_tx_open_sync(&tx);
+			M0_ASSERT_INFO(rc == 0, "rc = %d", rc);
+		}
+		index = be_ut_fl_rand(BE_UT_FL_CHUNK_NR, &seed);
+		if (chunks_used[index]) {
+			/* del or resize */
+			move_chunk = be_ut_fl_rand(2, &seed) == 0;
+			if (move_chunk) {
+				size = be_ut_fl_rand_size(&seed);
+				m0_be_fl_resize(fl, &tx, &chunks[index], size);
+				M0_UT_ASSERT(chunks[index].bac_size == size);
+			} else {
+				m0_be_fl_del(fl, &tx, &chunks[index]);
+				chunks_used[index] = false;
+			}
+		} else {
+			/* add */
+			chunks[index].bac_size = be_ut_fl_rand_size(&seed);
+			m0_be_fl_add(fl, &tx, &chunks[index]);
+			chunks_used[index] = true;
+		}
+		if (i + 1 == BE_UT_FL_ITER ||
+		    ((i + 1) % BE_UT_FL_OP_PER_TX) == 0) {
+			m0_be_tx_close_sync(&tx);
+			m0_be_tx_fini(&tx);
+		}
+	}
+
+	for (i = 0; i < BE_UT_FL_CHUNK_NR; ++i) {
+		if (chunks_used[i]) {
+			M0_BE_UT_TRANSACT(ut_be, NULL, tx, cred,
+				  m0_be_fl_credit(NULL, M0_BFL_DEL, &cred),
+				  m0_be_fl_del(fl, tx, &chunks[i]));
+		}
+	}
+
+	m0_free(chunks_used);
+
+	M0_BE_UT_TRANSACT(ut_be, NULL, tx, cred,
+			  m0_be_fl_credit(NULL, M0_BFL_DESTROY, &cred),
+			  m0_be_fl_destroy(fl, tx));
+
+	m0_be_fl_fini(fl);
+	/* m0_be_ut_seg_check_persistence(&ut_seg); */
+
+	m0_be_ut_seg_fini(&ut_seg);
+	m0_be_ut_backend_fini(ut_be);
+}
+
+/*
+ *  Local variables:
+ *  c-indentation-style: "K&R"
+ *  c-basic-offset: 8
+ *  tab-width: 8
+ *  fill-column: 80
+ *  scroll-step: 1
+ *  End:
+ */
+/*
+ * vim: tabstop=8 shiftwidth=8 noexpandtab textwidth=80 nowrap
+ */
-- 
1.8.3.2

