From 2244f0a44c24763ca3e64546d460a0a421436a6c Mon Sep 17 00:00:00 2001
From: Nathan Rutman <nathan_rutman@xyratex.com>
Date: Fri, 10 Dec 2010 10:28:10 -0800
Subject: [PATCH 2/5] DLDI fixes

---
 net/net.h       | 17 ++++++------
 net/net_utils.c | 81 ++++++++++++++++++++++++++++++++++-----------------------
 2 files changed, 56 insertions(+), 42 deletions(-)

diff --git a/net/net.h b/net/net.h
index 3e1fe53..859755a 100644
--- a/net/net.h
+++ b/net/net.h
@@ -82,7 +82,7 @@ void c2_net_xprt_fini(struct c2_net_xprt *xprt);
 enum c2_net_stats_direction {
         NS_STATS_IN  = 0,
         NS_STATS_OUT = 1,
-        NS_STATS_LAST
+        NS_STATS_NR
 };
 
 struct c2_net_stats {
@@ -91,11 +91,11 @@ struct c2_net_stats {
          All counters are 64 bits wide and wrap naturally. We re-zero
          the counters every time we examine the stats so that we have a known
          timebase for rate calculations. */
-        struct timeval   ns_time;
+        struct timeval     ns_time;
         /** Counts how many FOPs have been seen by the service workers */
-        uint64_t         ns_reqs;
+        struct c2_atomic64 ns_reqs;
         /** Bytes inside FOPs, as determined by fop type layout */
-        uint64_t         ns_bytes;
+        struct c2_atomic64 ns_bytes;
         /**
          Counts how many times an idle thread is woken to try to
          receive some data from a transport.
@@ -105,10 +105,9 @@ struct c2_net_stats {
          thing.  The ideal rate of change for this counter will be close
          to but less than the rate of change of the ns_reqs counter.
          */
-        uint64_t         ns_threads_woken;
-        uint64_t         ns_queue_depth;
-        uint32_t         ns_max;      /**< Max load seen so far */
-        bool             ns_got_busy; /**< We can believe max rate */
+        struct c2_atomic64 ns_threads_woken;
+        uint64_t           ns_max;      /**< Max load seen so far */
+        bool               ns_got_busy; /**< We can believe max rate */
 };
 
 /**
@@ -130,7 +129,7 @@ struct c2_net_domain {
 	void               *nd_xprt_private;
 	struct c2_net_xprt *nd_xprt;
         /** Domain network stats */
-        struct c2_net_stats nd_stats[NS_STATS_LAST];
+        struct c2_net_stats nd_stats[NS_STATS_NR];
 	/**
 	   ADDB context for events related to this domain
 	 */
diff --git a/net/net_utils.c b/net/net_utils.c
index 7d87b15..2255395 100644
--- a/net/net_utils.c
+++ b/net/net_utils.c
@@ -43,12 +43,15 @@ void c2_net_domain_stats_init(struct c2_net_domain *dom)
         C2_SET0(&dom->nd_stats);
 
         gettimeofday(&now, NULL);
-        for (i = 0; i < NS_STATS_LAST; i++) {
+        for (i = 0; i < ARRAY_SIZE(dom->nd_stats); i++) {
+                c2_rwlock_init(&dom->nd_stats[i].ns_lock);
                 dom->nd_stats[i].ns_time = now;
                 /** @todo we could add a provision for storing max persistently
                  */
+                /* Lie to avoid division by 0 */
                 dom->nd_stats[i].ns_max = 1;
-                c2_rwlock_init(&dom->nd_stats[i].ns_lock);
+                c2_atomic64_set(&dom->nd_stats[i].ns_threads_woken, 1);
+                c2_atomic64_set(&dom->nd_stats[i].ns_reqs, 1);
         }
 }
 
@@ -56,7 +59,7 @@ void c2_net_domain_stats_fini(struct c2_net_domain *dom)
 {
         int i;
 
-        for (i = 0; i < NS_STATS_LAST; i++) {
+        for (i = 0; i < ARRAY_SIZE(dom->nd_stats); i++) {
                 c2_rwlock_fini(&dom->nd_stats[i].ns_lock);
         }
 }
@@ -64,27 +67,28 @@ void c2_net_domain_stats_fini(struct c2_net_domain *dom)
 /**
  Collect some network loading stats
  */
+/** @todo fm_sizeof used in calls to here gives the size of a "top-most"
+ in-memory fop struct.  All substructures pointed to from the
+ top are allocated deep inside XDR bowels. E.g., for read or
+ write this won't include data buffers size.
+ Either we find a way to extract the total size from sunrpc
+ or we should write a generic fop-type function traversing
+ fop-format tree.
+ Note that even if not accturate, if the number reported is
+ reflective of the actual rate that is sufficient for relative
+ loading estimation.  In fact, # reqs may be a sufficient
+ proxy for bytes. */
 void c2_net_domain_stats_collect(struct c2_net_domain *dom,
                                  enum c2_net_stats_direction dir,
                                  uint64_t bytes,
                                  bool *sleeping)
 {
-        /* For the service worker threads, we serialize stats collection from
-           multiple services in the same domain via this lock. If this turns
-           out to affect performance, we could keep per-service (as opposed to
-           per-domain) stats here, and collect them at reporting time.
-           NS_STATS_OUT are added already serialized under the domain guard,
-           so this is not necessary (or harmful) for that. */
-        c2_rwlock_write_lock(&dom->nd_stats[dir].ns_lock);
-
-        dom->nd_stats[dir].ns_reqs++;
-        dom->nd_stats[dir].ns_bytes += bytes;
-        if (*sleeping == true) {
-                dom->nd_stats[dir].ns_threads_woken++;
+        c2_atomic64_inc(&dom->nd_stats[dir].ns_reqs);
+        c2_atomic64_add(&dom->nd_stats[dir].ns_bytes, bytes);
+        if (*sleeping) {
+                c2_atomic64_inc(&dom->nd_stats[dir].ns_threads_woken);
                 *sleeping = false;
         }
-
-        c2_rwlock_write_unlock(&dom->nd_stats[dir].ns_lock);
 }
 
 /**
@@ -96,41 +100,52 @@ void c2_net_domain_stats_collect(struct c2_net_domain *dom,
 int c2_net_domain_stats_get(struct c2_net_domain *dom,
                             enum c2_net_stats_direction dir)
 {
-        uint64_t interval_usec;
-        uint32_t rate;
+        uint64_t interval_usec, rate, max;
         struct timeval now;
         int rv;
 
         gettimeofday(&now, NULL);
 
-        c2_rwlock_read_lock(&dom->nd_stats[dir].ns_lock);
+        /* We lock here against other callers only -- stats are still being
+           collected while we are here. We therefore reset stats only after
+           we calclate the rate.  The rate may be slightly off because of the
+           ongoing collection. */
+        c2_rwlock_write_lock(&dom->nd_stats[dir].ns_lock);
 
         interval_usec = (now.tv_sec - dom->nd_stats[dir].ns_time.tv_sec) *
             1000000 + now.tv_usec - dom->nd_stats[dir].ns_time.tv_usec;
         interval_usec = max64u(interval_usec, 1);
 
         /* Load based on data rate only, bytes/sec */
-        rate = (uint32_t)(dom->nd_stats[dir].ns_bytes * 1000000 /
-                          interval_usec);
-        dom->nd_stats[dir].ns_max = max32u(dom->nd_stats[dir].ns_max, rate);
-        dom->nd_stats[dir].ns_time = now;
-        rv = rate << 8 / dom->nd_stats[dir].ns_max;
-
-        /* At BOW we might think any data rate is the max. Instead we can use
-           threads_woken == reqs to calculate if we're not busy -- if the
-           req queues don't build up, there is probably more capacity.
+        rate = c2_atomic64_get(&dom->nd_stats[dir].ns_bytes) *
+                          1000000 / interval_usec;
+        max = max64u(dom->nd_stats[dir].ns_max, rate);
+        rv = rate << 8 / max;
+
+        /* At start of world we might think any data rate is the max. Instead
+           we can use threads_woken == reqs to calculate if we're not busy --
+           if the req queues don't build up, there is probably more capacity.
            The converse, high queue depth implies no more network capacity,
            is not true, since queues may be limited by some other resource. */
         if (!dom->nd_stats[dir].ns_got_busy) {
-                if (dom->nd_stats[dir].ns_threads_woken << 8 /
-                    dom->nd_stats[dir].ns_reqs > 230 /* 90% not busy */)
-                        rv = 1;
+                if (c2_atomic64_get(&dom->nd_stats[dir].ns_threads_woken) << 8 /
+                    c2_atomic64_get(&dom->nd_stats[dir].ns_reqs) > 230)
+                        /* at least 90% not busy, report "10% busy" */
+                        rv = 10 << 8 / 100;
                 else
                         /* Once we get a little busy, start trusting max */
                         dom->nd_stats[dir].ns_got_busy = true;
         }
 
-        c2_rwlock_read_unlock(&dom->nd_stats[dir].ns_lock);
+        /* Reset stats */
+        dom->nd_stats[dir].ns_time = now;
+        c2_atomic64_set(&dom->nd_stats[dir].ns_bytes, 0);
+        /* Lie to avoid division by 0 */
+        c2_atomic64_set(&dom->nd_stats[dir].ns_threads_woken, 1);
+        c2_atomic64_set(&dom->nd_stats[dir].ns_reqs, 1);
+        dom->nd_stats[dir].ns_max = max;
+
+        c2_rwlock_write_unlock(&dom->nd_stats[dir].ns_lock);
 
         return rv;
 }
-- 
1.8.3.2

