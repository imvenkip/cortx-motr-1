From cee807613d72c083231cda03ad0ef00212160713 Mon Sep 17 00:00:00 2001
From: "anand.vidwansa" <anand_vidwansa@xyratex.com>
Date: Wed, 24 Jul 2013 01:49:56 -0700
Subject: [PATCH 08/15] bigmemalloc: - Addressed comments from code inspection.
  - Changed name from genarray to varr.  - Changed all concerned APIs.  - Used
 buffers instead of pages.

---
 lib/Kbuild.sub              |   6 +-
 lib/linux_kernel/genarray.c | 407 ------------------------------------------
 lib/linux_kernel/genarray.h | 291 ------------------------------
 lib/linux_kernel/ut/main.c  |   4 +-
 lib/linux_kernel/varr.c     | 419 ++++++++++++++++++++++++++++++++++++++++++++
 lib/linux_kernel/varr.h     | 292 ++++++++++++++++++++++++++++++
 lib/ut/Kbuild.sub           |   2 +-
 lib/ut/genarray.c           | 199 ---------------------
 lib/ut/main.c               |   1 -
 lib/ut/varr.c               | 199 +++++++++++++++++++++
 10 files changed, 916 insertions(+), 904 deletions(-)
 delete mode 100644 lib/linux_kernel/genarray.c
 delete mode 100644 lib/linux_kernel/genarray.h
 create mode 100644 lib/linux_kernel/varr.c
 create mode 100644 lib/linux_kernel/varr.h
 delete mode 100644 lib/ut/genarray.c
 create mode 100644 lib/ut/varr.c

diff --git a/lib/Kbuild.sub b/lib/Kbuild.sub
index 4266524..1ef109c 100644
--- a/lib/Kbuild.sub
+++ b/lib/Kbuild.sub
@@ -30,8 +30,7 @@ m0mero_objects += lib/assert.o \
                   lib/vec.o \
                   lib/vec_xc.o
 
-m0mero_objects += lib/linux_kernel/genarray.o \
-		  lib/linux_kernel/finject_init.o \
+m0mero_objects += lib/linux_kernel/finject_init.o \
                   lib/linux_kernel/kassert.o \
                   lib/linux_kernel/kcookie.o \
                   lib/linux_kernel/kthread.o \
@@ -43,4 +42,5 @@ m0mero_objects += lib/linux_kernel/genarray.o \
                   lib/linux_kernel/processor.o \
                   lib/linux_kernel/rwlock.o \
                   lib/linux_kernel/semaphore.o \
-                  lib/linux_kernel/timer.o
+                  lib/linux_kernel/timer.o \
+		  lib/linux_kernel/varr.o
diff --git a/lib/linux_kernel/genarray.c b/lib/linux_kernel/genarray.c
deleted file mode 100644
index 0a00ff6..0000000
--- a/lib/linux_kernel/genarray.c
+++ /dev/null
@@ -1,407 +0,0 @@
-/* -*- C -*- */
-/*
- * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
- *
- * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
- * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
- * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
- * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
- * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
- * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
- * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
- *
- * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
- * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
- * http://www.xyratex.com/contact
- *
- * Original author: Anand Vidwansa <anand_vidwansa@xyratex.com>
- * Original creation date: 12/17/2012
- */
-
-#include "lib/linux_kernel/genarray.h" /* genarray */
-#include "lib/bob.h"	/* m0_bob_type */
-#include "lib/memory.h"
-#include "lib/misc.h"	/* m0_forall */
-#include "lib/errno.h"	/* Includes appropriate errno header. */
-#include "lib/types.h"	/* Includes appropriate types header. */
-#include "lib/trace.h"	/* M0_ENTRY() */
-
-static const struct m0_bob_type genarray_bobtype;
-
-M0_BOB_DEFINE(static, &genarray_bobtype, genarray);
-
-static const struct m0_bob_type genarray_bobtype = {
-	.bt_name         = "generic_array_bobtype",
-	.bt_magix_offset = offsetof(struct genarray, ga_magic),
-	.bt_magix        = M0_LIB_GENARRAY_MAGIC,
-	.bt_check        = NULL,
-};
-
-M0_INTERNAL int level_find(unsigned long pg);
-static bool genarray_invariant(const struct genarray *arr);
-static int genarray_ln_alloc(struct genarray *arr,
-			     unsigned long    nr,
-			     int              level);
-static int genarray_l0_alloc(struct genarray *arr,
-			     unsigned long   *addr);
-static int genarray_l1_alloc(struct genarray *arr,
-			     unsigned long   *addr,
-			     unsigned long    nr);
-static int genarray_l2_alloc(struct genarray *arr,
-			     unsigned long   *addr,
-			     unsigned long    nr);
-static void genarray_ln_free(struct genarray *arr,
-			     unsigned long   *addr,
-			     int              level);
-static unsigned long page_nr_in_ln(const struct genarray *arr,
-				   int                    level);
-static void genarray_l0_free(struct genarray *arr,
-			     unsigned long   *addr);
-static void genarray_l1_free(struct genarray *arr,
-			     unsigned long   *addr);
-static void genarray_l2_free(struct genarray *arr,
-			     unsigned long   *addr);
-M0_INTERNAL void genarray_fini(struct genarray *arr);
-M0_INTERNAL unsigned long page_index_in_level_n(unsigned long pg,
-						int           level);
-static unsigned long page_nr_left_after_level_n(unsigned long pg,
-						int           level);
-
-M0_INTERNAL unsigned long genarray_obj_nr_in_page(const struct genarray *arr)
-{
-	M0_PRE(arr != NULL);
-	M0_PRE(arr->ga_typwidth > 0);
-
-	return PAGE_CACHE_SIZE / arr->ga_typwidth;
-}
-
-static bool genarray_invariant(const struct genarray *arr)
-{
-	return
-		genarray_bob_check(arr) &&
-		arr->ga_len > 0 &&
-		arr->ga_alloc > 0 &&
-		arr->ga_typwidth > 0 &&
-		M0_0VEC_ALIGN % arr->ga_typwidth == 0 &&
-		m0_forall(i, level_find(cont_nr_for_objs(arr->ga_len,
-			  genarray_obj_nr_in_page(arr))),
-			  (unsigned long *)arr->ga_levels[i] != NULL);
-}
-
-M0_INTERNAL int genarray_init(struct genarray *arr,
-			      uint64_t         len,
-			      size_t           typwidth)
-{
-	int            rc = 0;
-	int            level;
-	unsigned long  page_nr;
-	int            level_nr;
-
-	M0_PRE(arr != NULL);
-	M0_PRE(len  > 0);
-	M0_PRE(typwidth > 0);
-	M0_PRE(PAGE_CACHE_SIZE % typwidth == 0);
-
-	/*
-	 * Since two successive pages are not guaranteed to be contiguous,
-	 * structures bigger than page size can't fit in such array since
-	 * any attempt to dereference structure members can go over a
-	 * page size and can fault the program.
-	 */
-	if (len > (M0_0VEC_ALIGN / typwidth * PAGE_NR_TILL_LEVEL2) ||
-	    typwidth > M0_0VEC_ALIGN)
-		return -EINVAL;
-
-	arr->ga_len      = len;
-	arr->ga_alloc    = arr->ga_dealloc = 0;
-	arr->ga_typwidth = typwidth;
-	arr->ga_levels[GA_LEVEL0] = arr->ga_levels[GA_LEVEL1] =
-		arr->ga_levels[GA_LEVEL2] = 0;
-	genarray_bob_init(arr);
-
-	page_nr  = cont_nr_for_objs(len, genarray_obj_nr_in_page(arr));
-	level_nr = level_find(page_nr);
-
-	for (level = GA_LEVEL0; level <= level_nr; ++level) {
-		rc = genarray_ln_alloc(arr, page_nr_in_ln(arr, level), level);
-		if (rc != 0)
-			break;
-	}
-
-	if (rc != 0)
-		genarray_fini(arr);
-	else
-		M0_POST_EX(genarray_invariant(arr));
-	return rc;
-}
-
-M0_INTERNAL void genarray_fini(struct genarray *arr)
-{
-	int l;
-	int level;
-
-	M0_PRE(arr != NULL);
-	M0_PRE_EX(genarray_invariant(arr));
-
-	level = level_find(arr->ga_len / genarray_obj_nr_in_page(arr));
-	for (l = 0; l <= level; ++l)
-		genarray_ln_free(arr, &arr->ga_levels[l], l);
-
-	M0_POST(arr->ga_alloc == arr->ga_dealloc);
-	genarray_bob_fini(arr);
-	arr->ga_len = 0;
-	arr->ga_typwidth = 0;
-	arr->ga_alloc = arr->ga_dealloc = 0;
-}
-
-M0_INTERNAL unsigned long *genarray_page(const struct genarray *arr,
-					 unsigned long          id)
-{
-	int            level;
-	unsigned long  pg;
-	unsigned long *pgptr;
-
-	M0_PRE(arr != NULL);
-	M0_PRE(id  <  arr->ga_len);
-
-	pg    = id / genarray_obj_nr_in_page(arr);
-	level = level_find(pg);
-	pgptr = (unsigned long *)arr->ga_levels[level];
-
-	if (level == GA_LEVEL0)
-		return pgptr;
-
-	for (; level > 0; --level) {
-		pgptr += page_index_in_level_n(pg, level);
-		pg     = page_nr_left_after_level_n(pg, level);
-		/* Dereferences the page pointer at given offset. */
-		pgptr  = (unsigned long *)*pgptr;
-	}
-
-	M0_POST_EX(genarray_invariant(arr));
-	return pgptr;
-}
-
-static void genarray_l0_free(struct genarray *arr,
-			     unsigned long   *addr)
-{
-	if (*addr != 0) {
-		free_page(*addr);
-		*addr = 0;
-		++arr->ga_dealloc;
-	}
-}
-
-static void genarray_l1_free(struct genarray *arr,
-			     unsigned long   *addr)
-{
-	unsigned long id;
-	unsigned long *ptr;
-
-	M0_PRE(arr  != NULL);
-	M0_PRE(addr != NULL);
-
-	if (*addr != 0) {
-		for (id = 0; id < M0_0VEC_ALIGN / sizeof id; ++id) {
-			ptr = (unsigned long *)*addr;
-			ptr += id;
-			genarray_l0_free(arr, ptr);
-		}
-		genarray_l0_free(arr, addr);
-	}
-}
-
-static void genarray_l2_free(struct genarray *arr,
-			     unsigned long   *addr)
-{
-	unsigned long  id;
-	unsigned long *tier1;
-
-	M0_PRE(arr  != NULL);
-	M0_PRE(addr != NULL);
-
-	if (arr->ga_levels[GA_LEVEL2] != 0) {
-		tier1 = (unsigned long *)(arr->ga_levels[2]);
-		for (id = 0; id < (M0_0VEC_ALIGN / sizeof id) && *tier1 != 0;
-		     ++id, tier1++)
-			genarray_l1_free(arr, tier1);
-		genarray_l0_free(arr, &arr->ga_levels[GA_LEVEL2]);
-	}
-}
-
-static void genarray_ln_free(struct genarray *arr,
-			     unsigned long   *addr,
-			     int              level)
-{
-	M0_PRE(arr  != NULL);
-	M0_PRE(addr != NULL);
-	M0_PRE(level >= GA_LEVEL0 && level < GENARRAY_LEVEL_NR);
-
-	return
-		level == GA_LEVEL0 ? genarray_l0_free(arr, addr) :
-		level == GA_LEVEL1 ? genarray_l1_free(arr, addr) :
-		genarray_l2_free(arr, addr);
-}
-
-static int genarray_l0_alloc(struct genarray *arr,
-			     unsigned long   *addr)
-{
-	M0_PRE(arr  != NULL);
-	M0_PRE(addr != NULL);
-
-	*addr = (unsigned long)get_zeroed_page(GFP_KERNEL);
-	if ((unsigned long *)*addr != NULL) {
-		++arr->ga_alloc;
-		return 0;
-	}
-	return -ENOMEM;
-}
-
-static int genarray_l1_alloc(struct genarray *arr,
-			     unsigned long   *addr,
-			     unsigned long    nr)
-{
-	int            rc;
-	unsigned long  id;
-	unsigned long *pg;
-
-	M0_PRE(arr  != NULL);
-	M0_PRE(addr != NULL);
-	M0_PRE(nr    > 0);
-
-	*addr = (unsigned long)get_zeroed_page(GFP_KERNEL);
-	if ((unsigned long *)*addr == NULL)
-		return -ENOMEM;
-	++arr->ga_alloc;
-	pg = (unsigned long *)*addr;
-	for (id = 0; id < nr; ++id, ++pg) {
-		rc = genarray_l0_alloc(arr, pg);
-		if (rc != 0)
-			break;
-	}
-	return rc;
-}
-
-static int genarray_l2_alloc(struct genarray *arr,
-			     unsigned long   *addr,
-			     unsigned long    nr)
-{
-	int            rc;
-	unsigned long  n;
-	unsigned long  total;
-	unsigned long *pg;
-
-	M0_PRE(arr  != NULL);
-	M0_PRE(addr != NULL);
-	M0_PRE(nr    > 0);
-
-	*addr = (unsigned long)get_zeroed_page(GFP_KERNEL);
-	if ((unsigned long *)*addr == NULL)
-		return -ENOMEM;
-
-	++arr->ga_alloc;
-	pg = (unsigned long *)*addr;
-	for (total = 0; total < nr; total += n, ++pg) {
-		M0_ASSERT((unsigned long *)*pg == NULL);
-		n  = min64u(nr - total, PAGE_NR_IN_LEVEL1);
-		rc = genarray_l1_alloc(arr, pg, n);
-		if (rc != 0)
-			break;
-	}
-	return rc;
-}
-
-static int genarray_ln_alloc(struct genarray *arr,
-			     unsigned long    nr,
-			     int              level)
-{
-	M0_PRE(arr != NULL);
-	M0_PRE(nr   > 0);
-	M0_PRE(level >= GA_LEVEL0 && level <= GENARRAY_LEVEL_NR);
-
-	return
-		level == GA_LEVEL0 ?
-			genarray_l0_alloc(arr, &arr->ga_levels[GA_LEVEL0]) :
-		level == GA_LEVEL1 ?
-			genarray_l1_alloc(arr, &arr->ga_levels[GA_LEVEL1], nr) :
-		genarray_l2_alloc(arr, &arr->ga_levels[GA_LEVEL2], nr);
-}
-
-static uint64_t genarray_obj_nr_in_l0(const struct genarray *arr)
-{
-	return min64u(arr->ga_len, genarray_obj_nr_in_page(arr));
-}
-
-static uint64_t genarray_obj_nr_in_l1(const struct genarray *arr)
-{
-	return min64u(arr->ga_len - genarray_obj_nr_in_l0(arr),
-		      PAGE_NR_IN_LEVEL1 * genarray_obj_nr_in_page(arr));
-}
-
-static uint64_t genarray_obj_nr_till_l1(const struct genarray *arr)
-{
-	return genarray_obj_nr_in_l0(arr) + genarray_obj_nr_in_l1(arr);
-}
-
-static uint64_t genarray_obj_nr_in_l2(const struct genarray *arr)
-{
-	return min64u(arr->ga_len - genarray_obj_nr_till_l1(arr),
-		      PAGE_NR_IN_LEVEL2 * genarray_obj_nr_in_page(arr));
-}
-
-M0_INTERNAL uint64_t genarray_obj_nr_in_ln(const struct genarray *arr,
-					   int                    level)
-{
-	M0_PRE(arr != NULL);
-	M0_PRE(level >= GA_LEVEL0 && level <= GA_LEVEL2);
-
-	return
-		level == 0 ? genarray_obj_nr_in_l0(arr) :
-		level == 1 ? genarray_obj_nr_in_l1(arr) :
-		genarray_obj_nr_in_l2(arr);
-}
-
-static unsigned long page_nr_in_ln(const struct genarray *arr,
-				   int                    level)
-{
-	M0_PRE(arr != NULL);
-	M0_PRE(level >= GA_LEVEL0 && level <= GENARRAY_LEVEL_NR);
-
-	return
-		level == GA_LEVEL0 ? PAGE_NR_IN_LEVEL0 :
-		level == GA_LEVEL1 ?
-		min64u(cont_nr_for_objs(genarray_obj_nr_in_l1(arr),
-				        genarray_obj_nr_in_page(arr)),
-		       PAGE_NR_IN_LEVEL1) :
-		min64u(cont_nr_for_objs(genarray_obj_nr_in_l2(arr),
-				        genarray_obj_nr_in_page(arr)),
-		       PAGE_NR_IN_LEVEL2);
-}
-
-M0_INTERNAL unsigned long page_index_in_level_n(unsigned long    pg,
-						int              level)
-{
-	M0_PRE(level > 0 && level < GENARRAY_LEVEL_NR);
-
-	return
-		level == GA_LEVEL1 ? pg > 0 ? pg - PAGE_NR_IN_LEVEL0 : pg :
-		(pg - PAGE_NR_TILL_LEVEL1) / PAGE_NR_IN_LEVEL1;
-}
-
-static unsigned long page_nr_left_after_level_n(unsigned long pg,
-						int           level)
-{
-	M0_PRE(level > GA_LEVEL0 && level < GENARRAY_LEVEL_NR);
-
-	return level == GA_LEVEL2 ?
-		((pg - PAGE_NR_TILL_LEVEL1) % PAGE_NR_IN_LEVEL1) + 1 : pg;
-}
-
-M0_INTERNAL int level_find(unsigned long pg)
-{
-	M0_PRE(pg < PAGE_NR_TILL_LEVEL2);
-
-	return
-	       pg < PAGE_NR_IN_LEVEL0 ? GA_LEVEL0 :
-	       pg < PAGE_NR_TILL_LEVEL1 ? GA_LEVEL1 : GA_LEVEL2;
-}
diff --git a/lib/linux_kernel/genarray.h b/lib/linux_kernel/genarray.h
deleted file mode 100644
index 21ff365..0000000
--- a/lib/linux_kernel/genarray.h
+++ /dev/null
@@ -1,291 +0,0 @@
-/* -*- C -*- */
-/*
- * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
- *
- * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
- * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
- * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
- * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
- * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
- * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
- * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
- *
- * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
- * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
- * http://www.xyratex.com/contact
- *
- * Original author: Anand Vidwansa <anand_vidwansa@xyratex.com>
- * Original creation date: 12/17/2012
- */
-
-#pragma once
-
-#ifndef __MERO_LIB_LINUX_KERNEL_GEN_ARRAY_H__
-#define __MERO_LIB_LINUX_KERNEL_GEN_ARRAY_H__
-
-#include "lib/vec.h"
-
-#include <linux/pagemap.h> /* PAGE_CACHE_SIZE */
-
-/**
- * Represents a generic array which is meant to be used in kernel space.
- * Typically, linux kernel page allocator does not guarantee allocation
- * of contiguous pages since the address space could be fragmented.
- *
- * It is left to applications to work around this problem.
- * There are 2 possible approaches to resolve this issue.
- * - use vmalloc() instead of kmalloc() OR
- * - use a generic array by  maintaining set of pages
- *   (contiguous/discontiguous) and doing the indexing manually.
- *
- * Often, using vmalloc() is expensive since process page tables have to be
- * rearranged in order to to make the memory look like it is contiguous
- * even if it is not.
- * This can mess with processor TLB (translation lookaside buffer) cache
- * which maintains the latest mapping of virtual to physical addresses,
- * which adds to performance degradation.
- *
- * The second approach is to use a generic array with a set of kernel pages
- * (physical contiguity of pages does not matter) and using manual indexing
- * to iterate over the set of pages.
- *
- * Advantages:
- * - Fairly inexpensive as compared to vmalloc() since no page tables need
- *   to be updated.
- * - An indexing scheme desirable to application can be used.
- * - Can do boundary checking (due to use of metadata about array)
- *
- * Disadvantages:
- * - Existing code which assumes contiguous allocation can not be used as is.
- * - New APIs have to be written to read/write from/to array.
- * - Mimimum one page must be allocated since granularity of allocation is
- *   a page.
- *
- * Here the generic array approach is adopted since it's lightweight and
- * flexible.
- *
- * The structure of generic array is kept something similar to a block map
- * from an on-disk inode which multiple indirections.
- *
- * The current implementation uses 2 levels of indirections as follows.
- * - Maintains array of 3 pages where
- *   - No indirection: First page is used as is, for memory worth
- *     PAGE_CACHE_SIZE (total 4K).
- *
- *   - First indirection: Second page is used to store addresses of pages,
- *     each of which will store PAGE_CACHE_SIZE worth of data (total 2M).
- *
- *   - Second indirection: Third page is used to store pages, each of which
- *     can hold data worth first indirection (total 1G).
- *
- * In all, this implementation can allocate up to 262657 pages.
- * For any allocation requests bigger than this number, an error code
- * is returned.
- */
-
-struct genarray;
-
-enum {
-	GENARRAY_LEVEL_NR   = 3,
-	GA_LEVEL0           = 0,
-	GA_LEVEL1           = GA_LEVEL0 + 1,
-	GA_LEVEL2           = GA_LEVEL1 + 1,
-	PAGE_NR_IN_LEVEL0   = 1,
-	PAGE_NR_IN_LEVEL1   = PAGE_CACHE_SIZE / sizeof (unsigned long),
-	//PAGE_NR_IN_LEVEL1   = M0_0VEC_ALIGN / sizeof (unsigned long),
-	PAGE_NR_IN_LEVEL2   = PAGE_NR_IN_LEVEL1 * PAGE_NR_IN_LEVEL1,
-
-	/** Number of pages till end of level 1. */
-	PAGE_NR_TILL_LEVEL1 = PAGE_NR_IN_LEVEL0 + PAGE_NR_IN_LEVEL1,
-
-	/** Number of pages till end of level 2. */
-	PAGE_NR_TILL_LEVEL2 = PAGE_NR_TILL_LEVEL1 + PAGE_NR_IN_LEVEL2,
-};
-
-struct genarray {
-	/** Number of elements in array. */
-	uint64_t      ga_len;
-
-	/** Type width of object type stored in genarray. */
-	size_t        ga_typwidth;
-
-	/**
-	 * Page levels according to size of array.
-	 * Only the levels which fall within size of array are allocated.
-	 */
-	unsigned long ga_levels[GENARRAY_LEVEL_NR];
-
-	/** Debug field - Number of pages allocated. */
-	unsigned long ga_alloc;
-
-	/** Debug field - Number of pages deallocated. */
-	unsigned long ga_dealloc;
-
-	/** Magic field to cross check sanity of structure. */
-	uint64_t      ga_magic;
-};
-
-/**
- * Initialises a generic array.
- * @param len      Length of array.
- * @param typwidth Type width of object to be stored in array.
- * @pre   arr != NULL && len > 0.
- * @post  genarray_invariant(arr) == true.
- */
-M0_INTERNAL int genarray_init(struct genarray *arr,
-			      uint64_t         len,
-			      size_t           typwidth);
-
-/** Returns number of objects that can fit in one page. */
-M0_INTERNAL unsigned long genarray_obj_nr_in_page(const struct genarray *arr);
-
-/** Returns the level till which objects are accommodated in genarray. */
-M0_INTERNAL int level_find(unsigned long pg);
-
-/** Finds out index in given level for given page index. */
-M0_INTERNAL unsigned long page_index_in_level_n(unsigned long    pg,
-						int              level);
-
-/** Returns number of objects contained in given level. */
-M0_INTERNAL uint64_t genarray_obj_nr_in_ln(const struct genarray *arr,
-					   int                    level);
-
-/**
- * Returns the page in which given object with index id falls.
- * @pre  arr != NULL && id < arr->ga_len.
- * @post genarray_invariant(arr).
- */
-M0_INTERNAL unsigned long *genarray_page(const struct genarray *arr,
-					 unsigned long          id);
-
-#define genarray_ele_get(arr, type, index)			\
-({								\
-	type          *__ptr;					\
-								\
-	__ptr  = (type *)genarray_page(arr, index);		\
-	__ptr += index % genarray_obj_nr_in_page(arr);		\
-	M0_POST(__ptr != NULL);					\
-	__ptr;							\
-})
-
-#define cont_nr_for_objs(nr, obj_nr_in_1_cont)				\
-({									\
-	M0_PRE(obj_nr_in_1_cont > 0);					\
-									\
-	nr / obj_nr_in_1_cont + (nr % obj_nr_in_1_cont == 0 ? 0 : 1);	\
-})
-
-#define genarray_pages_for_obj_n(arr, nr, level)		\
-cont_nr_for_objs(nr, genarray_obj_nr_in_ln(arr, level))
-
-#define genarray_for_l0(arr, var, addr, nr, ...)				\
-({									\
-	uint64_t    id;							\
-	typeof(var) var;						\
-									\
-	var = (typeof(var))(addr);					\
-	for (id = 0; id < (nr); ++id, ++var) {				\
-		if (!({ __VA_ARGS__ ; }))				\
-			break;						\
-	}								\
-	id == (nr);							\
-})
-
-#define genarray_for_l1(arr, var, addr, nr, ...)			\
-({									\
-	uint64_t       l   = 0;						\
-	uint64_t       _t1 = 0;						\
-	uint64_t       _nr = 0;						\
-	unsigned long *_l0 = (unsigned long *)(addr);			\
-	unsigned long *_l1;						\
-									\
-	for (; l < genarray_pages_for_obj_n(arr, nr, GA_LEVEL0); ++l, ++_l0) {	\
-		_nr = min64u(nr - _t1, genarray_obj_nr_in_ln(arr, GA_LEVEL0));\
-		_l1 = (unsigned long *)*_l0;\
-		if (!genarray_for_l0(arr, var, _l1, _nr, __VA_ARGS__))	\
-			break;						\
-		_t1 += _nr;						\
-	}								\
-	_t1 == (nr);							\
-})
-
-#define genarray_for_l2(arr, var, addr, nr, ...)			\
-({									\
-	uint64_t       l   = 0;						\
-	uint64_t       _nr = 0;						\
-	uint64_t       _t2 = 0;						\
-	unsigned long *_l1 = (unsigned long *)(addr);			\
-	unsigned long *_l2;						\
-									\
-	for (; l < genarray_pages_for_obj_n(arr, nr, GA_LEVEL1); ++l, ++_l1) {\
-		_nr = min64u(nr - _t2, genarray_obj_nr_in_ln(arr, GA_LEVEL1));\
-		_l2 = (unsigned long *)*_l1;				\
-		if (!genarray_for_l1(arr, var, _l2, _nr, __VA_ARGS__))	\
-			break;						\
-		_t2 += _nr;						\
-	}								\
-	_t2 == (nr);							\
-})
-
-/**
- * Iterates over all objects stored in genarray performing same
- * operations for every object.
- * This can be used in invariant checking.
- */
-#define genarray_forall(arr, var, type, ...)				\
-({									\
-	bool           cond;						\
-	uint64_t       nr;						\
-	uint64_t       total = 0;					\
-	unsigned long  lev;						\
-	unsigned long *addr;						\
-	type          *var;						\
-	struct genarray *a = (arr);					\
-									\
-	lev  = level_find(a->ga_len / genarray_obj_nr_in_page(a));	\
-	addr = (unsigned long *)a->ga_levels[GA_LEVEL0];		\
-	nr   = genarray_obj_nr_in_ln(a, GA_LEVEL0);			\
-	if (GA_LEVEL0 <= lev) {						\
-		cond = genarray_for_l0(a, var, addr, nr,		\
-				       ({ __VA_ARGS__; }));		\
-		if (cond)						\
-			total += nr;					\
-	}								\
-									\
-	addr = (unsigned long *)a->ga_levels[GA_LEVEL1];		\
-	nr   = genarray_obj_nr_in_ln(a, GA_LEVEL1);			\
-	if (cond && GA_LEVEL1 <= lev) {					\
-		cond = genarray_for_l1(a, var, addr, nr,		\
-				       ({ __VA_ARGS__; }));		\
-		if (cond)						\
-			total += nr;					\
-	}								\
-									\
-	addr = (unsigned long *)a->ga_levels[GA_LEVEL2];		\
-	nr   = genarray_obj_nr_in_ln(a, GA_LEVEL2);			\
-	if (cond && GA_LEVEL2 <= lev) {					\
-		cond = genarray_for_l2(a, var, addr, nr,		\
-				       ({ __VA_ARGS__; }));		\
-		if (cond)						\
-			total += nr;					\
-	}								\
-	total == a->ga_len;						\
-})
-
-/**
- * Finalises a generic array.
- * @pre genarray_invariant(arr) == true
- */
-M0_INTERNAL void genarray_fini(struct genarray *arr);
-
-#endif /* __MERO_LIB_LINUX_KERNEL_GEN_ARRAY_H__ */
-
-/*
- *  Local variables:
- *  c-indentation-style: "K&R"
- *  c-basic-offset: 8
- *  tab-width: 8
- *  fill-column: 80
- *  scroll-step: 1
- *  End:
- */
diff --git a/lib/linux_kernel/ut/main.c b/lib/linux_kernel/ut/main.c
index e61b62c..04227e7 100644
--- a/lib/linux_kernel/ut/main.c
+++ b/lib/linux_kernel/ut/main.c
@@ -47,7 +47,7 @@ M0_INTERNAL void test_memory(void);
 M0_INTERNAL void test_bob(void);
 M0_INTERNAL void m0_ut_lib_buf_test(void);
 M0_INTERNAL void m0_test_lib_uuid(void);
-M0_INTERNAL void test_genarray(void);
+M0_INTERNAL void test_varr(void);
 
 const struct m0_test_suite m0_klibm0_ut = {
 	.ts_name = "klibm0-ut",
@@ -64,7 +64,6 @@ const struct m0_test_suite m0_klibm0_ut = {
 #ifdef ENABLE_FAULT_INJECTION
 		{ "finject",       test_finject       },
 #endif
-		{ "genarray",      test_genarray      },
 		{ "list",          test_list          },
 		{ "lockers",       test_lockers       },
 		{ "tlist",         test_tlist         },
@@ -76,6 +75,7 @@ const struct m0_test_suite m0_klibm0_ut = {
 		{ "time",          m0_ut_time_test    },
 		{ "trace",         test_trace         },
 		{ "uuid",          m0_test_lib_uuid   },
+		{ "varr",          test_varr          },
 		{ "vec",           test_vec           },
 		{ "zerovec",       test_zerovec       },
 		{ NULL,            NULL               }
diff --git a/lib/linux_kernel/varr.c b/lib/linux_kernel/varr.c
new file mode 100644
index 0000000..c89e5dd
--- /dev/null
+++ b/lib/linux_kernel/varr.c
@@ -0,0 +1,419 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Anand Vidwansa <anand_vidwansa@xyratex.com>
+ * Original creation date: 12/17/2012
+ */
+
+#include "lib/linux_kernel/varr.h" /* m0_varr */
+#include "lib/bob.h"	/* m0_bob_type */
+#include "lib/memory.h"
+#include "lib/misc.h"	/* m0_forall */
+#include "lib/errno.h"	/* Includes appropriate errno header. */
+#include "lib/types.h"	/* Includes appropriate types header. */
+#include "lib/trace.h"	/* M0_ENTRY() */
+
+static const struct m0_bob_type varr_bobtype;
+
+M0_BOB_DEFINE(static, &varr_bobtype, m0_varr);
+
+static const struct m0_bob_type varr_bobtype = {
+	.bt_name         = "generic_array_bobtype",
+	.bt_magix_offset = offsetof(struct m0_varr, va_magic),
+	.bt_magix        = M0_LIB_GENARRAY_MAGIC,
+	.bt_check        = NULL,
+};
+
+M0_INTERNAL int level_find(unsigned long pg);
+static bool varr_invariant(const struct m0_varr *arr);
+static int varr_ln_alloc(struct m0_varr *arr,
+			     unsigned long    nr,
+			     int              level);
+static int varr_l0_alloc(struct m0_varr *arr,
+			     unsigned long   *addr);
+static int varr_l1_alloc(struct m0_varr *arr,
+			     unsigned long   *addr,
+			     unsigned long    nr);
+static int varr_l2_alloc(struct m0_varr *arr,
+			     unsigned long   *addr,
+			     unsigned long    nr);
+static void varr_ln_free(struct m0_varr *arr,
+			     unsigned long   *addr,
+			     int              level);
+static unsigned long buff_nr_in_ln(const struct m0_varr *arr,
+				   int                    level);
+static void varr_l0_free(struct m0_varr *arr,
+			 unsigned long   *addr);
+static void varr_l1_free(struct m0_varr *arr,
+			 unsigned long   *addr);
+static void varr_l2_free(struct m0_varr *arr,
+			 unsigned long   *addr);
+M0_INTERNAL void varr_fini(struct m0_varr *arr);
+M0_INTERNAL unsigned long buff_index_in_level_n(unsigned long pg,
+						int           level);
+static unsigned long buff_nr_left_after_level_n(unsigned long pg,
+						int           level);
+
+M0_INTERNAL unsigned long cont_nr_for_objs(unsigned long nr,
+					   unsigned long obj_nr_in_1_cont);
+
+M0_INTERNAL unsigned long varr_obj_nr_in_buff(const struct m0_varr *arr)
+{
+	M0_PRE(arr != NULL);
+	M0_PRE(arr->va_sizeof > 0);
+
+	return PAGE_CACHE_SIZE / arr->va_sizeof;
+}
+
+M0_INTERNAL unsigned long cont_nr_for_objs(unsigned long nr,
+					   unsigned long obj_nr_in_1_cont)
+{
+	M0_PRE(obj_nr_in_1_cont > 0);
+
+	return nr / obj_nr_in_1_cont + (nr % obj_nr_in_1_cont == 0 ? 0 : 1);
+}
+
+static bool varr_invariant(const struct m0_varr *arr)
+{
+	return
+		m0_varr_bob_check(arr) &&
+		arr->va_nr > 0 &&
+		arr->va_alloc > 0 &&
+		arr->va_sizeof > 0 &&
+		M0_0VEC_ALIGN % arr->va_sizeof == 0 &&
+		m0_forall(i, level_find(cont_nr_for_objs(arr->va_nr,
+			  varr_obj_nr_in_buff(arr))),
+			  (unsigned long *)arr->va_levels[i] != NULL);
+}
+
+M0_INTERNAL int varr_init(struct m0_varr *arr,
+			  uint64_t        nr,
+			  size_t          size)
+{
+	int            rc = 0;
+	int            level;
+	unsigned long  buff_nr;
+	int            level_nr;
+
+	M0_PRE(arr != NULL);
+	M0_PRE(nr   > 0);
+	M0_PRE(size > 0);
+	M0_PRE(PAGE_CACHE_SIZE % size == 0);
+
+	/*
+	 * Since two successive buffs are not guaranteed to be contiguous,
+	 * structures bigger than page size can't fit in such array since
+	 * any attempt to dereference structure members can go over a
+	 * page size and can fault the program.
+	 */
+	if (nr > (M0_0VEC_ALIGN / size * PAGE_NR_TILL_LEVEL2) ||
+	    size > M0_0VEC_ALIGN)
+		return -EINVAL;
+
+	arr->va_nr     = nr;
+	arr->va_alloc  = arr->va_dealloc = 0;
+	arr->va_sizeof = size;
+	arr->va_levels[VA_LEVEL0] = arr->va_levels[VA_LEVEL1] =
+		arr->va_levels[VA_LEVEL2] = 0;
+	m0_varr_bob_init(arr);
+
+	buff_nr  = cont_nr_for_objs(nr, varr_obj_nr_in_buff(arr));
+	level_nr = level_find(buff_nr);
+
+	for (level = VA_LEVEL0; level <= level_nr; ++level) {
+		rc = varr_ln_alloc(arr, buff_nr_in_ln(arr, level), level);
+		if (rc != 0)
+			break;
+	}
+
+	if (rc != 0)
+		varr_fini(arr);
+	else
+		M0_POST_EX(varr_invariant(arr));
+	return rc;
+}
+
+M0_INTERNAL void varr_fini(struct m0_varr *arr)
+{
+	int l;
+	int level;
+
+	M0_PRE(arr != NULL);
+	M0_PRE_EX(varr_invariant(arr));
+
+	level = level_find(arr->va_nr / varr_obj_nr_in_buff(arr));
+	for (l = 0; l <= level; ++l)
+		varr_ln_free(arr, &arr->va_levels[l], l);
+
+	M0_POST(arr->va_alloc == arr->va_dealloc);
+	m0_varr_bob_fini(arr);
+	arr->va_nr = 0;
+	arr->va_sizeof = 0;
+	arr->va_alloc = arr->va_dealloc = 0;
+}
+
+M0_INTERNAL unsigned long *varr_buff(const struct m0_varr *arr,
+				     unsigned long         id)
+{
+	int            level;
+	unsigned long  pg;
+	unsigned long *pgptr;
+
+	M0_PRE(arr != NULL);
+	M0_PRE(id  <  arr->va_nr);
+
+	pg    = id / varr_obj_nr_in_buff(arr);
+	level = level_find(pg);
+	pgptr = (unsigned long *)arr->va_levels[level];
+
+	if (level == VA_LEVEL0)
+		return pgptr;
+
+	for (; level > 0; --level) {
+		pgptr += buff_index_in_level_n(pg, level);
+		pg     = buff_nr_left_after_level_n(pg, level);
+		/* Dereferences the buffer pointer at given offset. */
+		M0_ASSERT((unsigned long *)*pgptr != NULL);
+		pgptr  = (unsigned long *)*pgptr;
+	}
+
+	M0_POST_EX(varr_invariant(arr));
+	return pgptr;
+}
+
+static void varr_l0_free(struct m0_varr *arr,
+			     unsigned long   *addr)
+{
+	if (*addr != 0) {
+		free_page(*addr);
+		*addr = 0;
+		++arr->va_dealloc;
+	}
+}
+
+static void varr_l1_free(struct m0_varr *arr,
+			     unsigned long   *addr)
+{
+	unsigned long id;
+	unsigned long *ptr;
+
+	M0_PRE(arr  != NULL);
+	M0_PRE(addr != NULL);
+
+	if (*addr != 0) {
+		for (id = 0; id < M0_0VEC_ALIGN / sizeof id; ++id) {
+			ptr = (unsigned long *)*addr;
+			ptr += id;
+			varr_l0_free(arr, ptr);
+		}
+		varr_l0_free(arr, addr);
+	}
+}
+
+static void varr_l2_free(struct m0_varr *arr,
+			     unsigned long   *addr)
+{
+	unsigned long  id;
+	unsigned long *tier1;
+
+	M0_PRE(arr  != NULL);
+	M0_PRE(addr != NULL);
+
+	if (arr->va_levels[VA_LEVEL2] != 0) {
+		tier1 = (unsigned long *)(arr->va_levels[2]);
+		for (id = 0; id < (M0_0VEC_ALIGN / sizeof id) && *tier1 != 0;
+		     ++id, tier1++)
+			varr_l1_free(arr, tier1);
+		varr_l0_free(arr, &arr->va_levels[VA_LEVEL2]);
+	}
+}
+
+static void varr_ln_free(struct m0_varr *arr,
+			     unsigned long   *addr,
+			     int              level)
+{
+	M0_PRE(arr  != NULL);
+	M0_PRE(addr != NULL);
+	M0_PRE(level >= VA_LEVEL0 && level < VA_LEVEL_NR);
+
+	return
+		level == VA_LEVEL0 ? varr_l0_free(arr, addr) :
+		level == VA_LEVEL1 ? varr_l1_free(arr, addr) :
+		varr_l2_free(arr, addr);
+}
+
+static int varr_l0_alloc(struct m0_varr *arr,
+			     unsigned long   *addr)
+{
+	M0_PRE(arr  != NULL);
+	M0_PRE(addr != NULL);
+
+	*addr = (unsigned long)get_zeroed_page(GFP_KERNEL);
+	if ((unsigned long *)*addr != NULL) {
+		++arr->va_alloc;
+		return 0;
+	}
+	return -ENOMEM;
+}
+
+static int varr_l1_alloc(struct m0_varr *arr,
+			     unsigned long   *addr,
+			     unsigned long    nr)
+{
+	int            rc;
+	unsigned long  id;
+	unsigned long *pg;
+
+	M0_PRE(arr  != NULL);
+	M0_PRE(addr != NULL);
+	M0_PRE(nr    > 0);
+
+	*addr = (unsigned long)get_zeroed_page(GFP_KERNEL);
+	if ((unsigned long *)*addr == NULL)
+		return -ENOMEM;
+	++arr->va_alloc;
+	pg = (unsigned long *)*addr;
+	for (id = 0; id < nr; ++id, ++pg) {
+		rc = varr_l0_alloc(arr, pg);
+		if (rc != 0)
+			break;
+	}
+	return rc;
+}
+
+static int varr_l2_alloc(struct m0_varr *arr,
+			     unsigned long   *addr,
+			     unsigned long    nr)
+{
+	int            rc;
+	unsigned long  n;
+	unsigned long  total;
+	unsigned long *pg;
+
+	M0_PRE(arr  != NULL);
+	M0_PRE(addr != NULL);
+	M0_PRE(nr    > 0);
+
+	*addr = (unsigned long)get_zeroed_page(GFP_KERNEL);
+	if ((unsigned long *)*addr == NULL)
+		return -ENOMEM;
+
+	++arr->va_alloc;
+	pg = (unsigned long *)*addr;
+	for (total = 0; total < nr; total += n, ++pg) {
+		M0_ASSERT((unsigned long *)*pg == NULL);
+		n  = min64u(nr - total, PAGE_NR_IN_LEVEL1);
+		rc = varr_l1_alloc(arr, pg, n);
+		if (rc != 0)
+			break;
+	}
+	return rc;
+}
+
+static int varr_ln_alloc(struct m0_varr *arr,
+			     unsigned long    nr,
+			     int              level)
+{
+	M0_PRE(arr != NULL);
+	M0_PRE(nr   > 0);
+	M0_PRE(level >= VA_LEVEL0 && level <= VA_LEVEL_NR);
+
+	return
+		level == VA_LEVEL0 ?
+			varr_l0_alloc(arr, &arr->va_levels[VA_LEVEL0]) :
+		level == VA_LEVEL1 ?
+			varr_l1_alloc(arr, &arr->va_levels[VA_LEVEL1], nr) :
+		varr_l2_alloc(arr, &arr->va_levels[VA_LEVEL2], nr);
+}
+
+static uint64_t varr_obj_nr_in_l0(const struct m0_varr *arr)
+{
+	return min64u(arr->va_nr, varr_obj_nr_in_buff(arr));
+}
+
+static uint64_t varr_obj_nr_in_l1(const struct m0_varr *arr)
+{
+	return min64u(arr->va_nr - varr_obj_nr_in_l0(arr),
+		      PAGE_NR_IN_LEVEL1 * varr_obj_nr_in_buff(arr));
+}
+
+static uint64_t varr_obj_nr_till_l1(const struct m0_varr *arr)
+{
+	return varr_obj_nr_in_l0(arr) + varr_obj_nr_in_l1(arr);
+}
+
+static uint64_t varr_obj_nr_in_l2(const struct m0_varr *arr)
+{
+	return min64u(arr->va_nr - varr_obj_nr_till_l1(arr),
+		      PAGE_NR_IN_LEVEL2 * varr_obj_nr_in_buff(arr));
+}
+
+M0_INTERNAL uint64_t varr_obj_nr_in_ln(const struct m0_varr *arr,
+					   int                    level)
+{
+	M0_PRE(arr != NULL);
+	M0_PRE(level >= VA_LEVEL0 && level <= VA_LEVEL2);
+
+	return
+		level == 0 ? varr_obj_nr_in_l0(arr) :
+		level == 1 ? varr_obj_nr_in_l1(arr) :
+		varr_obj_nr_in_l2(arr);
+}
+
+static unsigned long buff_nr_in_ln(const struct m0_varr *arr,
+				   int                    level)
+{
+	M0_PRE(arr != NULL);
+	M0_PRE(level >= VA_LEVEL0 && level <= VA_LEVEL_NR);
+
+	return
+		level == VA_LEVEL0 ? PAGE_NR_IN_LEVEL0 :
+		level == VA_LEVEL1 ?
+		min64u(cont_nr_for_objs(varr_obj_nr_in_l1(arr),
+				        varr_obj_nr_in_buff(arr)),
+		       PAGE_NR_IN_LEVEL1) :
+		min64u(cont_nr_for_objs(varr_obj_nr_in_l2(arr),
+				        varr_obj_nr_in_buff(arr)),
+		       PAGE_NR_IN_LEVEL2);
+}
+
+M0_INTERNAL unsigned long buff_index_in_level_n(unsigned long    pg,
+						int              level)
+{
+	M0_PRE(level > 0 && level < VA_LEVEL_NR);
+
+	return
+		level == VA_LEVEL1 ? pg > 0 ? pg - PAGE_NR_IN_LEVEL0 : pg :
+		(pg - PAGE_NR_TILL_LEVEL1) / PAGE_NR_IN_LEVEL1;
+}
+
+static unsigned long buff_nr_left_after_level_n(unsigned long pg,
+						int           level)
+{
+	M0_PRE(level > VA_LEVEL0 && level < VA_LEVEL_NR);
+
+	return level == VA_LEVEL2 ?
+		((pg - PAGE_NR_TILL_LEVEL1) % PAGE_NR_IN_LEVEL1) + 1 : pg;
+}
+
+M0_INTERNAL int level_find(unsigned long pg)
+{
+	M0_PRE(pg < PAGE_NR_TILL_LEVEL2);
+
+	return
+	       pg < PAGE_NR_IN_LEVEL0 ? VA_LEVEL0 :
+	       pg < PAGE_NR_TILL_LEVEL1 ? VA_LEVEL1 : VA_LEVEL2;
+}
diff --git a/lib/linux_kernel/varr.h b/lib/linux_kernel/varr.h
new file mode 100644
index 0000000..a6867ee
--- /dev/null
+++ b/lib/linux_kernel/varr.h
@@ -0,0 +1,292 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Anand Vidwansa <anand_vidwansa@xyratex.com>
+ * Original creation date: 12/17/2012
+ */
+
+#pragma once
+
+#ifndef __MERO_LIB_LINUX_KERNEL_GEN_ARRAY_H__
+#define __MERO_LIB_LINUX_KERNEL_GEN_ARRAY_H__
+
+#include "lib/vec.h"
+
+#include <linux/pagemap.h> /* PAGE_CACHE_SIZE */
+
+/**
+ * Represents a virtual array which is meant to be used in kernel space.
+ * Typically, linux kernel page allocator does not guarantee allocation
+ * of contiguous pages since the address space could be fragmented.
+ *
+ * It is left to applications to work around this problem.
+ * There are 2 possible approaches to resolve this issue.
+ * - use vmalloc() instead of kmalloc() OR
+ * - use a virtual array by  maintaining set of pages
+ *   (contiguous/discontiguous) and doing the indexing manually.
+ *
+ * Often, using vmalloc() is expensive since process page tables have to be
+ * rearranged in order to to make the memory look like it is contiguous
+ * even if it is not.
+ * This can mess with processor TLB (translation lookaside buffer) cache
+ * which maintains the latest mapping of virtual to physical addresses,
+ * which adds to performance degradation.
+ *
+ * The second approach is to use a virtual array with a set of kernel pages
+ * (physical contiguity of pages does not matter) and using manual indexing
+ * to iterate over the set of pages.
+ *
+ * Advantages:
+ * - Fairly inexpensive as compared to vmalloc() since no page tables need
+ *   to be updated.
+ * - An indexing scheme desirable to application can be used.
+ * - Can do boundary checking (due to use of metadata about array)
+ *
+ * Disadvantages:
+ * - Existing code which assumes contiguous allocation can not be used as is.
+ * - New APIs have to be written to read/write from/to array.
+ * - Mimimum one page must be allocated since granularity of allocation is
+ *   a page.
+ *
+ * Here the virtual array approach is adopted since it's lightweight and
+ * flexible.
+ *
+ * The structure of virtual array is kept something similar to a block map
+ * from an on-disk inode which multiple indirections.
+ *
+ * The current implementation uses 2 levels of indirections as follows.
+ * - Maintains array of 3 pages where
+ *   - No indirection: First page is used as is, for memory worth
+ *     PAGE_CACHE_SIZE (total 4K).
+ *
+ *   - First indirection: Second page is used to store addresses of pages,
+ *     each of which will store PAGE_CACHE_SIZE worth of data (total 2M).
+ *
+ *   - Second indirection: Third page is used to store pages, each of which
+ *     can hold data worth first indirection (total 1G).
+ *
+ * In all, this implementation can allocate up to 262657 pages.
+ * For any allocation requests bigger than this number, an error code
+ * is returned.
+ */
+
+struct m0_varr;
+
+enum {
+	VA_LEVEL0 = 0,
+	VA_LEVEL1,
+	VA_LEVEL2,
+	VA_LEVEL_NR,
+	PAGE_NR_IN_LEVEL0   = 1,
+	PAGE_NR_IN_LEVEL1   = PAGE_CACHE_SIZE / sizeof (unsigned long),
+	//PAGE_NR_IN_LEVEL1   = M0_0VEC_ALIGN / sizeof (unsigned long),
+	PAGE_NR_IN_LEVEL2   = PAGE_NR_IN_LEVEL1 * PAGE_NR_IN_LEVEL1,
+
+	/** Number of buffers till end of level 1. */
+	PAGE_NR_TILL_LEVEL1 = PAGE_NR_IN_LEVEL0 + PAGE_NR_IN_LEVEL1,
+
+	/** Number of buffers till end of level 2. */
+	PAGE_NR_TILL_LEVEL2 = PAGE_NR_TILL_LEVEL1 + PAGE_NR_IN_LEVEL2,
+};
+
+struct m0_varr {
+	/** Number of elements in array. */
+	uint64_t      va_nr;
+
+	/** Size of object type stored in m0_varr. */
+	size_t        va_sizeof;
+
+	/**
+	 * Page levels according to size of array.
+	 * Only the levels which fall within size of array are allocated.
+	 */
+	unsigned long va_levels[VA_LEVEL_NR];
+
+	/** Debug field - Number of buffers allocated. */
+	unsigned long va_alloc;
+
+	/** Debug field - Number of buffers deallocated. */
+	unsigned long va_dealloc;
+
+	/** Magic field to cross check sanity of structure. */
+	uint64_t      va_magic;
+};
+
+/**
+ * Initialises a virtual array.
+ * @param nr   Length of array.
+ * @param size Size of object to be stored in array.
+ * @pre   arr != NULL && nr > 0.
+ * @post  varr_invariant(arr) == true.
+ */
+M0_INTERNAL int varr_init(struct m0_varr *arr,
+			  uint64_t        nr,
+			  size_t          size);
+
+/** Returns number of objects that can fit in one buffer. */
+M0_INTERNAL unsigned long varr_obj_nr_in_buff(const struct m0_varr *arr);
+
+/** Returns the level till which objects are accommodated in m0_varr. */
+M0_INTERNAL int level_find(unsigned long pg);
+
+/** Finds out index in given level for given buffer index. */
+M0_INTERNAL unsigned long buff_index_in_level_n(unsigned long    pg,
+						int              level);
+
+/** Returns number of objects contained in given level. */
+M0_INTERNAL uint64_t varr_obj_nr_in_ln(const struct m0_varr *arr,
+					   int                    level);
+
+/**
+ * Returns the buffer in which given object with index id falls.
+ * @pre  arr != NULL && id < arr->va_nr.
+ * @post varr_invariant(arr).
+ */
+M0_INTERNAL unsigned long *varr_buff(const struct m0_varr *arr,
+					 unsigned long          id);
+
+#define varr_ele_get(arr, type, index)				\
+({								\
+	type          *__ptr;					\
+								\
+	__ptr  = (type *)varr_buff(arr, index);			\
+	__ptr += index % varr_obj_nr_in_buff(arr);		\
+	M0_POST(__ptr != NULL);					\
+	__ptr;							\
+})
+
+/**
+ * Returns the number of container buffers needed to accommodate nr
+ * objects from virtual array.
+ * @pre obj_nr_in_1_cont > 0.
+ */
+M0_INTERNAL unsigned long cont_nr_for_objs(unsigned long nr,
+					   unsigned long obj_nr_in_1_cont);
+
+#define varr_buffs_for_obj_n(arr, nr, level)		\
+cont_nr_for_objs(nr, varr_obj_nr_in_ln(arr, level))
+
+#define varr_for_l0(arr, var, addr, nr, ...)				\
+({									\
+	uint64_t    id;							\
+	typeof(var) var;						\
+									\
+	var = (typeof(var))(addr);					\
+	for (id = 0; id < (nr); ++id, ++var) {				\
+		if (!({ __VA_ARGS__ ; }))				\
+			break;						\
+	}								\
+	id == (nr);							\
+})
+
+#define varr_for_l1(arr, var, addr, nr, ...)			\
+({									\
+	uint64_t       l   = 0;						\
+	uint64_t       _t1 = 0;						\
+	uint64_t       _nr = 0;						\
+	unsigned long *_l0 = (unsigned long *)(addr);			\
+	unsigned long *_l1;						\
+									\
+	for (; l < varr_buffs_for_obj_n(arr, nr, VA_LEVEL0); ++l, ++_l0) {	\
+		_nr = min64u(nr - _t1, varr_obj_nr_in_ln(arr, VA_LEVEL0));\
+		_l1 = (unsigned long *)*_l0;\
+		if (!varr_for_l0(arr, var, _l1, _nr, __VA_ARGS__))	\
+			break;						\
+		_t1 += _nr;						\
+	}								\
+	_t1 == (nr);							\
+})
+
+#define varr_for_l2(arr, var, addr, nr, ...)			\
+({									\
+	uint64_t       l   = 0;						\
+	uint64_t       _nr = 0;						\
+	uint64_t       _t2 = 0;						\
+	unsigned long *_l1 = (unsigned long *)(addr);			\
+	unsigned long *_l2;						\
+									\
+	for (; l < varr_buffs_for_obj_n(arr, nr, VA_LEVEL1); ++l, ++_l1) {\
+		_nr = min64u(nr - _t2, varr_obj_nr_in_ln(arr, VA_LEVEL1));\
+		_l2 = (unsigned long *)*_l1;				\
+		if (!varr_for_l1(arr, var, _l2, _nr, __VA_ARGS__))	\
+			break;						\
+		_t2 += _nr;						\
+	}								\
+	_t2 == (nr);							\
+})
+
+/**
+ * Iterates over all objects stored in m0_varr performing same
+ * operations for every object.
+ * This can be used in invariant checking.
+ */
+#define varr_forall(arr, var, type, ...)				\
+({									\
+	bool           cond;						\
+	uint64_t       nr;						\
+	uint64_t       total = 0;					\
+	unsigned long  lev;						\
+	unsigned long *addr;						\
+	type          *var;						\
+	struct m0_varr *a = (arr);					\
+									\
+	lev  = level_find(a->va_nr / varr_obj_nr_in_buff(a));	\
+	addr = (unsigned long *)a->va_levels[VA_LEVEL0];		\
+	nr   = varr_obj_nr_in_ln(a, VA_LEVEL0);			\
+	if (VA_LEVEL0 <= lev) {						\
+		cond = varr_for_l0(a, var, addr, nr,		\
+				       ({ __VA_ARGS__; }));		\
+		if (cond)						\
+			total += nr;					\
+	}								\
+									\
+	addr = (unsigned long *)a->va_levels[VA_LEVEL1];		\
+	nr   = varr_obj_nr_in_ln(a, VA_LEVEL1);			\
+	if (cond && VA_LEVEL1 <= lev) {					\
+		cond = varr_for_l1(a, var, addr, nr,		\
+				       ({ __VA_ARGS__; }));		\
+		if (cond)						\
+			total += nr;					\
+	}								\
+									\
+	addr = (unsigned long *)a->va_levels[VA_LEVEL2];		\
+	nr   = varr_obj_nr_in_ln(a, VA_LEVEL2);			\
+	if (cond && VA_LEVEL2 <= lev) {					\
+		cond = varr_for_l2(a, var, addr, nr,		\
+				       ({ __VA_ARGS__; }));		\
+		if (cond)						\
+			total += nr;					\
+	}								\
+	total == a->va_nr;						\
+})
+
+/**
+ * Finalises a virtual array.
+ * @pre varr_invariant(arr) == true
+ */
+M0_INTERNAL void varr_fini(struct m0_varr *arr);
+
+#endif /* __MERO_LIB_LINUX_KERNEL_GEN_ARRAY_H__ */
+
+/*
+ *  Local variables:
+ *  c-indentation-style: "K&R"
+ *  c-basic-offset: 8
+ *  tab-width: 8
+ *  fill-column: 80
+ *  scroll-step: 1
+ *  End:
+ */
diff --git a/lib/ut/Kbuild.sub b/lib/ut/Kbuild.sub
index 10ac11f..e424a9a 100644
--- a/lib/ut/Kbuild.sub
+++ b/lib/ut/Kbuild.sub
@@ -4,7 +4,6 @@ m0ut_objects += lib/ut/bitmap.o \
                 lib/ut/chan.o \
                 lib/ut/cookie.o \
                 lib/ut/finject.o \
-                lib/ut/genarray.o \
                 lib/ut/list.o \
                 lib/ut/lockers.o \
                 lib/ut/memory.o \
@@ -19,6 +18,7 @@ m0ut_objects += lib/ut/bitmap.o \
                 lib/ut/tlist.o \
                 lib/ut/trace.o \
                 lib/ut/uuid.o \
+                lib/ut/varr.o \
                 lib/ut/vec.o \
                 lib/ut/zerovec.o
 
diff --git a/lib/ut/genarray.c b/lib/ut/genarray.c
deleted file mode 100644
index 1d29672..0000000
--- a/lib/ut/genarray.c
+++ /dev/null
@@ -1,199 +0,0 @@
-/* -*- C -*- */
-/*
- * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
- *
- * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
- * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
- * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
- * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
- * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
- * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
- * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
- *
- * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
- * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
- * http://www.xyratex.com/contact
- *
- * Original author: Anand Vidwansa <anand_vidwansa@xyratex.com>
- * Original creation date: 01/07/2013
- */
-
-#include "lib/linux_kernel/genarray.h"
-#include "lib/vec.h"
-#include "lib/memory.h"
-#include "ut/ut.h"
-
-static unsigned long ELEMENT_NR = 1234567;
-static unsigned long struct_nr  = 123456;
-static uint64_t FOO_MAGIC = 0x1234567890abcde;
-
-struct bar {
-	uint64_t b_8b;
-	uint64_t b_81b;
-	uint64_t b_82b;
-};
-
-/* 64 bytes long. */
-struct foo {
-	uint64_t       f_8b;
-	uint64_t       f_81b;
-	uint64_t       f_magic;
-	char          *f_ptr;
-	unsigned long *f_lptr;
-	struct bar     f_bar;
-};
-
-static struct foo **address_tracker;
-
-static void foo_init(struct foo *f, unsigned long id)
-{
-	f->f_8b   = (uint64_t)id;
-	f->f_81b  = (uint64_t)id;
-	f->f_magic = FOO_MAGIC;
-	f->f_ptr  = (char *)id;
-	f->f_lptr = (unsigned long *)id;
-	f->f_bar.b_8b  = (uint64_t)id;
-	f->f_bar.b_81b = (uint64_t)id;
-	f->f_bar.b_82b = (uint64_t)id;
-}
-
-static bool foo_check(struct foo *f, unsigned long id)
-{
-	return
-		f->f_8b  == (uint64_t)id &&
-		f->f_81b == (uint64_t)id &&
-		f->f_magic == FOO_MAGIC &&
-		f->f_ptr == (char *)id &&
-		f->f_lptr == (unsigned long *)id &&
-		f->f_bar.b_8b == (uint64_t)id &&
-		f->f_bar.b_81b == (uint64_t)id &&
-		f->f_bar.b_82b == (uint64_t)id;
-}
-
-void test_genarray(void)
-{
-	int                  rc;
-	unsigned long        id;
-	unsigned long        t2;
-	unsigned long        page_nr;
-	unsigned long        ele_nr_in_page;
-	unsigned long        page_id_in_l2;
-	unsigned long       *tier1;
-	unsigned long       *tier2;
-	unsigned long       *addr;
-	unsigned long       *val;
-	unsigned long        cnt;
-	struct foo          *f;
-	struct genarray      arr;
-
-	/* genarray used to store ELEMENT_NR, 8 byte long objects. */
-	rc = genarray_init(&arr, ELEMENT_NR, sizeof(unsigned long));
-
-	M0_UT_ASSERT(rc == 0);
-	M0_UT_ASSERT(arr.ga_magic    == M0_LIB_GENARRAY_MAGIC);
-	M0_UT_ASSERT(arr.ga_len      == ELEMENT_NR);
-	M0_UT_ASSERT(arr.ga_typwidth == sizeof(unsigned long));
-
-	M0_UT_ASSERT(arr.ga_levels[GA_LEVEL0] != 0);
-	M0_UT_ASSERT(arr.ga_levels[GA_LEVEL1] != 0);
-
-	ele_nr_in_page = M0_0VEC_ALIGN / sizeof(unsigned long);
-	for (id = 0; id < ele_nr_in_page; ++id) {
-		tier1 = (unsigned long *)arr.ga_levels[GA_LEVEL1] + id;
-		M0_UT_ASSERT(*tier1 != 0);
-	}
-
-	M0_UT_ASSERT(arr.ga_levels[GA_LEVEL2] != 0);
-
-	page_nr        = ELEMENT_NR / ele_nr_in_page;
-	ELEMENT_NR % ele_nr_in_page != 0 ?: ++page_nr;
-	page_id_in_l2  = (page_nr - PAGE_NR_TILL_LEVEL1) / PAGE_NR_IN_LEVEL1;
-
-	for (id = 0; id <= page_id_in_l2; ++id) {
-		tier1  = (unsigned long *)arr.ga_levels[GA_LEVEL2];
-		tier1 += id;
-		M0_UT_ASSERT(*tier1 != 0);
-		for (t2 = 0; t2 < ele_nr_in_page; ++t2) {
-			tier2  = (unsigned long *)*tier1;
-			tier2 += t2;
-			if (PAGE_NR_TILL_LEVEL1 + id * PAGE_NR_IN_LEVEL1 +
-			    t2 <= page_nr)
-				M0_UT_ASSERT(*tier2 != 0);
-			else
-				M0_UT_ASSERT(*tier2 == 0);
-		}
-	}
-
-	for (id = page_id_in_l2 + 1; id < ele_nr_in_page; ++id) {
-		tier1  = (unsigned long *)arr.ga_levels[GA_LEVEL2];
-		tier1 += id;
-		M0_UT_ASSERT(*tier1 == 0);
-	}
-
-	for (id = 0; id < ELEMENT_NR; ++id) {
-		val = genarray_ele_get(&arr, unsigned long, id);
-		*val = id;
-	}
-
-	for (id = ELEMENT_NR - 1; id != 0; --id) {
-		val = genarray_ele_get(&arr, unsigned long, id);
-		M0_UT_ASSERT(*val == id);
-	}
-
-	tier1  = (unsigned long *)arr.ga_levels[GA_LEVEL2];
-	tier1 += page_index_in_level_n(page_nr, GA_LEVEL2);
-	tier2  = (unsigned long *)*tier1;
-	tier2 += (page_nr - PAGE_NR_TILL_LEVEL1) % PAGE_NR_IN_LEVEL1;
-	addr   = (unsigned long *)(*tier2 + (sizeof(unsigned long) *
-		 (ELEMENT_NR % genarray_obj_nr_in_page(&arr))));
-	M0_UT_ASSERT(*addr == 0);
-	genarray_fini(&arr);
-
-	/* Genarray used to store array of structures. */
-	rc = genarray_init(&arr, struct_nr, sizeof *f);
-
-	/*
-	 * Total size to accommodate array of struct foo worth 64 bytes
-	 * each = 64 * 123456 = 7901184.
-	 * Total number of pages to be allocated to accommodate array
-	 * worth 7901184 bytes = 7901184 / 4096 = 1929.
-	 * Pages till level 0 = 1.
-	 * Pages till level 1 = 513.
-	 * Pages till level 2, sublevel (0 + 1 + 2) = 1929.
-	 * Number of meta pages allocated = 5.
-	 */
-	M0_UT_ASSERT(rc == 0);
-	M0_UT_ASSERT(arr.ga_len == struct_nr);
-	M0_UT_ASSERT(arr.ga_typwidth == sizeof *f);
-	M0_UT_ASSERT((unsigned long *)arr.ga_levels[0] != NULL);
-	M0_UT_ASSERT((unsigned long *)arr.ga_levels[1] != NULL);
-	M0_UT_ASSERT((unsigned long *)arr.ga_levels[2] != NULL);
-	M0_UT_ASSERT(arr.ga_alloc == 1929 + 5);
-
-	M0_ALLOC_ARR(address_tracker, struct_nr);
-	M0_UT_ASSERT(address_tracker != NULL);
-
-	for (cnt = 0, id = 0; id < struct_nr; ++id, ++cnt) {
-		M0_UT_ASSERT(cnt == id);
-		f = genarray_ele_get(&arr, struct foo, id);
-		foo_init(f, id);
-		address_tracker[id] = f;
-	}
-
-	M0_UT_ASSERT(!genarray_forall(&arr, fint, struct foo,
-				      fint->f_8b == 12345));
-
-	for (id = 0; id < struct_nr; ++id)
-		M0_UT_ASSERT(address_tracker[id]->f_magic == FOO_MAGIC);
-
-	M0_UT_ASSERT(genarray_forall(&arr, fint, struct foo,
-				     fint->f_magic == FOO_MAGIC));
-
-	for (id = struct_nr - 1; id != 0; --id) {
-		f = genarray_ele_get(&arr, struct foo, id);
-		M0_UT_ASSERT(f == address_tracker[id]);
-		M0_UT_ASSERT(foo_check(f, id));
-	}
-	m0_free(address_tracker);
-	genarray_fini(&arr);
-}
diff --git a/lib/ut/main.c b/lib/ut/main.c
index fc6a22d..963c7e1 100644
--- a/lib/ut/main.c
+++ b/lib/ut/main.c
@@ -47,7 +47,6 @@ extern void test_tlist(void);
 extern void test_trace(void);
 extern void test_vec(void);
 extern void test_zerovec(void);
-extern void test_genarray(void);
 
 const struct m0_test_suite libm0_ut = {
 	.ts_name = "libm0-ut",
diff --git a/lib/ut/varr.c b/lib/ut/varr.c
new file mode 100644
index 0000000..6df1922
--- /dev/null
+++ b/lib/ut/varr.c
@@ -0,0 +1,199 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Anand Vidwansa <anand_vidwansa@xyratex.com>
+ * Original creation date: 01/07/2013
+ */
+
+#include "lib/linux_kernel/varr.h"
+#include "lib/vec.h"
+#include "lib/memory.h"
+#include "ut/ut.h"
+
+static unsigned long ELEMENT_NR = 1234567;
+static unsigned long struct_nr  = 123456;
+static uint64_t FOO_MAGIC = 0x1234567890abcde;
+
+struct bar {
+	uint64_t b_8b;
+	uint64_t b_81b;
+	uint64_t b_82b;
+};
+
+/* 64 bytes long. */
+struct foo {
+	uint64_t       f_8b;
+	uint64_t       f_81b;
+	uint64_t       f_magic;
+	char          *f_ptr;
+	unsigned long *f_lptr;
+	struct bar     f_bar;
+};
+
+static struct foo **address_tracker;
+
+static void foo_init(struct foo *f, unsigned long id)
+{
+	f->f_8b   = (uint64_t)id;
+	f->f_81b  = (uint64_t)id;
+	f->f_magic = FOO_MAGIC;
+	f->f_ptr  = (char *)id;
+	f->f_lptr = (unsigned long *)id;
+	f->f_bar.b_8b  = (uint64_t)id;
+	f->f_bar.b_81b = (uint64_t)id;
+	f->f_bar.b_82b = (uint64_t)id;
+}
+
+static bool foo_check(struct foo *f, unsigned long id)
+{
+	return
+		f->f_8b  == (uint64_t)id &&
+		f->f_81b == (uint64_t)id &&
+		f->f_magic == FOO_MAGIC &&
+		f->f_ptr == (char *)id &&
+		f->f_lptr == (unsigned long *)id &&
+		f->f_bar.b_8b == (uint64_t)id &&
+		f->f_bar.b_81b == (uint64_t)id &&
+		f->f_bar.b_82b == (uint64_t)id;
+}
+
+void test_varr(void)
+{
+	int                  rc;
+	unsigned long        id;
+	unsigned long        t2;
+	unsigned long        buff_nr;
+	unsigned long        ele_nr_in_buff;
+	unsigned long        buff_id_in_l2;
+	unsigned long       *tier1;
+	unsigned long       *tier2;
+	unsigned long       *addr;
+	unsigned long       *val;
+	unsigned long        cnt;
+	struct foo          *f;
+	struct m0_varr       arr;
+
+	/* varr used to store ELEMENT_NR, 8 byte long objects. */
+	rc = varr_init(&arr, ELEMENT_NR, sizeof(unsigned long));
+
+	M0_UT_ASSERT(rc == 0);
+	M0_UT_ASSERT(arr.va_magic  == M0_LIB_GENARRAY_MAGIC);
+	M0_UT_ASSERT(arr.va_nr     == ELEMENT_NR);
+	M0_UT_ASSERT(arr.va_sizeof == sizeof(unsigned long));
+
+	M0_UT_ASSERT(arr.va_levels[VA_LEVEL0] != 0);
+	M0_UT_ASSERT(arr.va_levels[VA_LEVEL1] != 0);
+
+	ele_nr_in_buff = M0_0VEC_ALIGN / sizeof(unsigned long);
+	for (id = 0; id < ele_nr_in_buff; ++id) {
+		tier1 = (unsigned long *)arr.va_levels[VA_LEVEL1] + id;
+		M0_UT_ASSERT(*tier1 != 0);
+	}
+
+	M0_UT_ASSERT(arr.va_levels[VA_LEVEL2] != 0);
+
+	buff_nr        = ELEMENT_NR / ele_nr_in_buff;
+	ELEMENT_NR % ele_nr_in_buff != 0 ?: ++buff_nr;
+	buff_id_in_l2  = (buff_nr - PAGE_NR_TILL_LEVEL1) / PAGE_NR_IN_LEVEL1;
+
+	for (id = 0; id <= buff_id_in_l2; ++id) {
+		tier1  = (unsigned long *)arr.va_levels[VA_LEVEL2];
+		tier1 += id;
+		M0_UT_ASSERT(*tier1 != 0);
+		for (t2 = 0; t2 < ele_nr_in_buff; ++t2) {
+			tier2  = (unsigned long *)*tier1;
+			tier2 += t2;
+			if (PAGE_NR_TILL_LEVEL1 + id * PAGE_NR_IN_LEVEL1 +
+			    t2 <= buff_nr)
+				M0_UT_ASSERT(*tier2 != 0);
+			else
+				M0_UT_ASSERT(*tier2 == 0);
+		}
+	}
+
+	for (id = buff_id_in_l2 + 1; id < ele_nr_in_buff; ++id) {
+		tier1  = (unsigned long *)arr.va_levels[VA_LEVEL2];
+		tier1 += id;
+		M0_UT_ASSERT(*tier1 == 0);
+	}
+
+	for (id = 0; id < ELEMENT_NR; ++id) {
+		val = varr_ele_get(&arr, unsigned long, id);
+		*val = id;
+	}
+
+	for (id = ELEMENT_NR - 1; id != 0; --id) {
+		val = varr_ele_get(&arr, unsigned long, id);
+		M0_UT_ASSERT(*val == id);
+	}
+
+	tier1  = (unsigned long *)arr.va_levels[VA_LEVEL2];
+	tier1 += buff_index_in_level_n(buff_nr, VA_LEVEL2);
+	tier2  = (unsigned long *)*tier1;
+	tier2 += (buff_nr - PAGE_NR_TILL_LEVEL1) % PAGE_NR_IN_LEVEL1;
+	addr   = (unsigned long *)(*tier2 + (sizeof(unsigned long) *
+		 (ELEMENT_NR % varr_obj_nr_in_buff(&arr))));
+	M0_UT_ASSERT(*addr == 0);
+	varr_fini(&arr);
+
+	/* Genarray used to store array of structures. */
+	rc = varr_init(&arr, struct_nr, sizeof *f);
+
+	/*
+	 * Total size to accommodate array of struct foo worth 64 bytes
+	 * each = 64 * 123456 = 7901184.
+	 * Total number of buffers to be allocated to accommodate array
+	 * worth 7901184 bytes = 7901184 / 4096 = 1929.
+	 * Pages till level 0 = 1.
+	 * Pages till level 1 = 513.
+	 * Pages till level 2, sublevel (0 + 1 + 2) = 1929.
+	 * Number of meta buffers allocated = 5.
+	 */
+	M0_UT_ASSERT(rc == 0);
+	M0_UT_ASSERT(arr.va_nr == struct_nr);
+	M0_UT_ASSERT(arr.va_sizeof == sizeof *f);
+	M0_UT_ASSERT((unsigned long *)arr.va_levels[0] != NULL);
+	M0_UT_ASSERT((unsigned long *)arr.va_levels[1] != NULL);
+	M0_UT_ASSERT((unsigned long *)arr.va_levels[2] != NULL);
+	M0_UT_ASSERT(arr.va_alloc == 1929 + 5);
+
+	M0_ALLOC_ARR(address_tracker, struct_nr);
+	M0_UT_ASSERT(address_tracker != NULL);
+
+	for (cnt = 0, id = 0; id < struct_nr; ++id, ++cnt) {
+		M0_UT_ASSERT(cnt == id);
+		f = varr_ele_get(&arr, struct foo, id);
+		foo_init(f, id);
+		address_tracker[id] = f;
+	}
+
+	M0_UT_ASSERT(!varr_forall(&arr, fint, struct foo,
+				      fint->f_8b == 12345));
+
+	for (id = 0; id < struct_nr; ++id)
+		M0_UT_ASSERT(address_tracker[id]->f_magic == FOO_MAGIC);
+
+	M0_UT_ASSERT(varr_forall(&arr, fint, struct foo,
+				     fint->f_magic == FOO_MAGIC));
+
+	for (id = struct_nr - 1; id != 0; --id) {
+		f = varr_ele_get(&arr, struct foo, id);
+		M0_UT_ASSERT(f == address_tracker[id]);
+		M0_UT_ASSERT(foo_check(f, id));
+	}
+	m0_free(address_tracker);
+	varr_fini(&arr);
+}
-- 
1.8.3.2

