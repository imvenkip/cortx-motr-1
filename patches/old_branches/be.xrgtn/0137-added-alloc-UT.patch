From fbfef6169381aea60c423a269591eb7e15cf81c7 Mon Sep 17 00:00:00 2001
From: Maxim Medved <Max_Medved@xyratex.com>
Date: Tue, 11 Jun 2013 16:46:01 +0300
Subject: [PATCH 137/228] added alloc UT

multiple fixes in be/alloc;
added UT (including multithreaded UT) for be/alloc;
small fix for seg_header_create().
---
 be/alloc.c          | 331 +++++++++++++++++++++++++++++++++++++---------------
 be/alloc.h          |   2 +-
 be/alloc_internal.h |   3 +-
 be/seg.c            |   5 +
 be/ut/alloc.c       | 140 +++++++++++++++++++++-
 be/ut/helper.c      |   2 +-
 be/ut/helper.h      |   1 +
 be/ut/main.c        |  14 ++-
 8 files changed, 391 insertions(+), 107 deletions(-)

diff --git a/be/alloc.c b/be/alloc.c
index 02d3cfc..7b90bbc 100644
--- a/be/alloc.c
+++ b/be/alloc.c
@@ -54,15 +54,47 @@ M0_TL_DESCR_DEFINE(chunks_free, "list of free chunks in m0_be_allocator",
 		   M0_BE_ALLOC_FREE_LINK_MAGIC, M0_BE_ALLOC_FREE_MAGIC);
 M0_TL_DEFINE(chunks_free, static, struct be_alloc_chunk);
 
-/** O(1) time complexity */
-static bool be_alloc_chunk_invariant(const struct be_alloc_chunk *c)
+static bool be_alloc_chunk_is_not_overlapping(const struct be_alloc_chunk *a,
+					      const struct be_alloc_chunk *b)
 {
+	return a == NULL || b == NULL ||
+	       ((char *) a < (char *) b &&
+		(char *) &a->bac_mem[a->bac_size] <= (char *) b);
+}
+
+static bool be_alloc_chunk_invariant(struct m0_be_allocator *a,
+				     const struct be_alloc_chunk *c)
+{
+	struct be_alloc_chunk *cprev;
+	struct be_alloc_chunk *cnext;
+	struct be_alloc_chunk *fprev;
+	struct be_alloc_chunk *fnext;
+
+	cprev = chunks_all_tlist_prev(&a->ba_h->bah_chunks.bl_list, c);
+	cnext = chunks_all_tlist_next(&a->ba_h->bah_chunks.bl_list, c);
+	if (c->bac_free) {
+		fprev = chunks_free_tlist_prev(&a->ba_h->bah_free.bl_list, c);
+		fnext = chunks_free_tlist_next(&a->ba_h->bah_free.bl_list, c);
+	} else {
+		fprev = NULL;
+		fnext = NULL;
+	}
+
 	return c != NULL &&
 	       c->bac_magic0 == M0_BE_ALLOC_MAGIC0 &&
-	       c->bac_magic1 == M0_BE_ALLOC_MAGIC1;
+	       c->bac_magic1 == M0_BE_ALLOC_MAGIC1 &&
+	       be_alloc_chunk_is_not_overlapping(cprev, c) &&
+	       be_alloc_chunk_is_not_overlapping(c, cnext) &&
+	       be_alloc_chunk_is_not_overlapping(fprev, c) &&
+	       be_alloc_chunk_is_not_overlapping(c, fnext) &&
+	       ergo(fprev != cprev,
+		    be_alloc_chunk_is_not_overlapping(fprev, cprev)) &&
+	       ergo(cnext != fnext,
+		    be_alloc_chunk_is_not_overlapping(cnext, fnext));
 }
 
-static void be_alloc_chunk_init(struct be_alloc_chunk *c,
+static void be_alloc_chunk_init(struct m0_be_allocator *a,
+				struct be_alloc_chunk *c,
 				m0_bcount_t size, bool free)
 {
 	*c = (struct be_alloc_chunk) {
@@ -73,13 +105,14 @@ static void be_alloc_chunk_init(struct be_alloc_chunk *c,
 	};
 	chunks_all_tlink_init(c);
 	chunks_free_tlink_init(c);
-	M0_POST(be_alloc_chunk_invariant(c));
 }
 
-static void be_alloc_chunk_del_fini(struct be_alloc_chunk *c)
+static void be_alloc_chunk_del_fini(struct m0_be_allocator *a,
+				    struct be_alloc_chunk *c)
 {
-	M0_PRE(be_alloc_chunk_invariant(c));
-	chunks_free_tlist_del(c);
+	M0_PRE(be_alloc_chunk_invariant(a, c));
+	if (c->bac_free)
+		chunks_free_tlist_del(c);
 	chunks_all_tlist_del(c);
 	chunks_free_tlink_fini(c);
 	chunks_all_tlink_fini(c);
@@ -93,90 +126,167 @@ static struct be_alloc_chunk *be_alloc_chunk_addr(void *ptr)
 static struct be_alloc_chunk *be_alloc_chunk_prev(struct m0_be_allocator *a,
 						  struct be_alloc_chunk *c)
 {
-	return chunks_all_tlist_prev(&a->ba_h->bah_free.bl_list, c);
+	struct be_alloc_chunk *r;
+
+	r = chunks_all_tlist_prev(&a->ba_h->bah_chunks.bl_list, c);
+	M0_ASSERT(ergo(r != NULL, be_alloc_chunk_invariant(a, r)));
+	return r;
 }
 
 static struct be_alloc_chunk *be_alloc_chunk_next(struct m0_be_allocator *a,
 						  struct be_alloc_chunk *c)
 {
-	return chunks_all_tlist_next(&a->ba_h->bah_free.bl_list, c);
+	struct be_alloc_chunk *r;
+
+	r = chunks_all_tlist_next(&a->ba_h->bah_chunks.bl_list, c);
+	M0_ASSERT(ergo(r != NULL, be_alloc_chunk_invariant(a, r)));
+	return r;
+}
+
+void be_alloc_chunk_mark_free(struct m0_be_allocator *a,
+			      struct be_alloc_chunk *c)
+{
+	struct be_alloc_chunk *next;
+
+	M0_PRE(be_alloc_chunk_invariant(a, c));
+	M0_PRE(!c->bac_free);
+	/* scan forward until free chunk found */
+	for (next = c; next != NULL; next = be_alloc_chunk_next(a, next)) {
+		if (next->bac_free)
+			break;
+	}
+	c->bac_free = true;
+	if (next == NULL)
+		chunks_free_tlist_add_tail(&a->ba_h->bah_chunks.bl_list, c);
+	else
+		chunks_free_tlist_add_before(next, c);
+	M0_POST(c->bac_free);
+	M0_POST(be_alloc_chunk_invariant(a, c));
+}
+
+static uintptr_t be_alloc_chunk_after(struct m0_be_allocator *a,
+				      struct be_alloc_chunk *c)
+{
+	return c == NULL ? (uintptr_t) a->ba_h->bah_addr :
+			   (uintptr_t) &c->bac_mem[c->bac_size];
 }
 
-/** try to add free chunk after c */
+/** try to add a free chunk after the c */
 static struct be_alloc_chunk *
-be_alloc_chunk_tryadd_after(struct m0_be_allocator *a,
-			    struct be_alloc_chunk *c,
-			    struct be_alloc_chunk *f,
-			    m0_bcount_t size_total, bool free)
+be_alloc_chunk_add_after(struct m0_be_allocator *a,
+			 struct be_alloc_chunk *c,
+			 struct be_alloc_chunk *f,
+			 uintptr_t offset,
+			 m0_bcount_t size_total, bool free)
 {
 	struct be_alloc_chunk *new;
 
-	M0_PRE(be_alloc_chunk_invariant(c));
-	M0_PRE(ergo(free, be_alloc_chunk_invariant(f)));
-	if (size_total < sizeof *c + 1) {
-		/* increase size of chunk c */
-		c->bac_size += size_total;
-		new = NULL;
-	} else {
-		/* add a new chunk */
-		new = (struct be_alloc_chunk *)
-		      (((uintptr_t) c) + sizeof(*c) + c->bac_size);
-		be_alloc_chunk_init(new, size_total - sizeof(*new), free);
+	M0_PRE(ergo(c != NULL, be_alloc_chunk_invariant(a, c)));
+	M0_PRE(ergo(free && f != NULL, be_alloc_chunk_invariant(a, f)));
+	M0_PRE(size_total > sizeof *new);
+
+	new = c == NULL ? (struct be_alloc_chunk *)
+			  ((uintptr_t) a->ba_h->bah_addr + offset) :
+			  (struct be_alloc_chunk *) be_alloc_chunk_after(a, c);
+	be_alloc_chunk_init(a, new, size_total - sizeof(*new), free);
+
+	/** add chunk to m0_be_allocator_header.bac_chunks list */
+	if (c != NULL)
 		chunks_all_tlist_add_after(c, new);
-		if (free)
+	else
+		chunks_all_tlist_add(&a->ba_h->bah_chunks.bl_list, new);
+	if (free) {
+		/** add chunk to m0_be_allocator_header.bac_free list */
+		if (f != NULL)
 			chunks_free_tlist_add_after(f, new);
+		else
+			chunks_free_tlist_add(&a->ba_h->bah_free.bl_list, new);
 	}
-	M0_POST(ergo(new != NULL, be_alloc_chunk_invariant(new)));
-	M0_POST(ergo(free, be_alloc_chunk_invariant(f)));
-	M0_POST(be_alloc_chunk_invariant(c));
+	M0_POST(be_alloc_chunk_invariant(a, new));
+	M0_POST(ergo(free && f != NULL, be_alloc_chunk_invariant(a, f)));
+	M0_PRE(ergo(c != NULL, be_alloc_chunk_invariant(a, c)));
 	return new;
 }
 
+/*
+ * +---------------+	+----------+ +--------+ |	 |
+ * |	prev	   |	|  prev	   | |	      | |	 |
+ * +---------------+	+----------+ |  prev  | |	 | < start0
+ * |		   |	|  chunk0  | |	      | |	 |
+ * |		   |	+----------+ +--------+ +--------+ < start_new
+ * |    c	   |	|	   | |	      | |	 |
+ * |		   |	|  new	   | |  new   | |  new	 |
+ * |		   |	|	   | |	      | |	 |
+ * |		   |	+----------+ +--------+ |	 | < start1
+ * |		   |	|  chunk1  | |	      | |	 |
+ * +---------------+	+----------+ |	      | +--------+ < start_next
+ * |	next	   |	|  next	   | |	      | |  next	 |
+ * +-------------- +	+----------+ |	      | +--------+
+ *
+ * initial position	after split  no space	 no space
+ *				     for chunk0  for chunk1
+ */
 static struct be_alloc_chunk *
 be_alloc_chunk_split(struct m0_be_allocator *a, struct be_alloc_chunk *c,
-		     uintptr_t addr_start, m0_bcount_t size)
+		     uintptr_t start_new, m0_bcount_t size)
 {
 	struct be_alloc_chunk *prev;
-	struct be_alloc_chunk *next;
 	struct be_alloc_chunk *prev_free;
-	struct be_alloc_chunk *f;
-	uintptr_t	       addr_end;
-	uintptr_t	       addr_prev_end;
-	uintptr_t	       addr_next_start;
-	const uintptr_t	       chunk_size = sizeof *c;
-
-	M0_PRE(be_alloc_chunk_invariant(c));
+	struct be_alloc_chunk *new;
+	const m0_bcount_t      chunk_size = sizeof *c;
+	uintptr_t	       start0;
+	uintptr_t	       start1;
+	uintptr_t	       start_next;
+	m0_bcount_t	       chunk0_size;
+	m0_bcount_t	       chunk1_size;
+
+	M0_PRE(be_alloc_chunk_invariant(a, c));
 	M0_PRE(c->bac_free);
 
-	prev = be_alloc_chunk_prev(a, c);
-	next = be_alloc_chunk_next(a, c);
-	addr_prev_end	= (uintptr_t) prev + chunk_size + prev->bac_size;
-	addr_next_start = (uintptr_t) next;
+	prev	  = be_alloc_chunk_prev(a, c);
 	prev_free = chunks_free_tlist_prev(&a->ba_h->bah_free.bl_list, c);
 
-	be_alloc_chunk_del_fini(c);
-	/* c is not valid chunk now */
-
-	addr_end = addr_start + chunk_size + size;
-	M0_ASSERT(addr_prev_end <= addr_start);
-	M0_ASSERT(addr_end	<= addr_next_start);
+	start0	    = be_alloc_chunk_after(a, prev);
+	start1	    = start_new + chunk_size + size;
+	start_next  = be_alloc_chunk_after(a, c);
+	chunk0_size = start_new - start0;
+	chunk1_size = start_next - start1;
+	M0_ASSERT(start0    <= start_new);
+	M0_ASSERT(start_new <= start1);
+	M0_ASSERT(start1    <= start_next);
+
+	be_alloc_chunk_del_fini(a, c);
+	/* c is not a valid chunk now */
+
+	if (chunk0_size <= chunk_size) {
+		/* no space for chunk0 */
+		if (prev != NULL)
+			prev->bac_size += chunk0_size;
+		else
+			; /* space before the first chunk is temporary lost */
+	} else {
+		prev_free = be_alloc_chunk_add_after(a, prev, prev_free,
+						     0, chunk0_size, true);
+		prev = prev_free;
+	}
 
-	/* handle space before new chunk */
-	c = be_alloc_chunk_tryadd_after(a, prev, prev_free,
-					addr_start - addr_prev_end, true);
-	f = c == NULL ? prev_free : c;
-	c = c == NULL ? prev : c;
 	/* add the new chunk */
-	c = be_alloc_chunk_tryadd_after(a, c, NULL, chunk_size + size, false);
-	M0_ASSERT(c != NULL);
-	c->bac_free = false;
-	/* handle space after new chunk */
-	be_alloc_chunk_tryadd_after(a, c, f, addr_next_start - addr_end, true);
-
-	M0_POST(!c->bac_free);
-	M0_POST(c->bac_size >= size);
-	M0_POST(be_alloc_chunk_invariant(c));
-	return c;
+	new = be_alloc_chunk_add_after(a, prev, NULL,
+				       prev == NULL ? chunk0_size : 0,
+				       chunk_size + size, false);
+	M0_ASSERT(new != NULL);
+
+	if (chunk1_size <= chunk_size) {
+		/* no space for chunk1 */
+		new->bac_size += chunk1_size;
+	} else {
+		be_alloc_chunk_add_after(a, new, prev_free,
+					 0, chunk1_size, true);
+	}
+	M0_POST(!new->bac_free);
+	M0_POST(new->bac_size >= size);
+	M0_POST(be_alloc_chunk_invariant(a, new));
+	return new;
 }
 
 static struct be_alloc_chunk *
@@ -190,7 +300,7 @@ be_alloc_chunk_trysplit(struct m0_be_allocator *a, struct be_alloc_chunk *c,
 	uintptr_t	       addr_end;
 	const uintptr_t	       chunk_size = sizeof *c;
 
-	M0_PRE(be_alloc_chunk_invariant(c));
+	M0_PRE(be_alloc_chunk_invariant(a, c));
 	M0_PRE(alignment != 0);
 	if (c->bac_free) {
 		addr_start = (uintptr_t) c;
@@ -203,31 +313,37 @@ be_alloc_chunk_trysplit(struct m0_be_allocator *a, struct be_alloc_chunk *c,
 			 be_alloc_chunk_split(a, c, addr_mem - chunk_size,
 					      size) : NULL;
 	}
-	M0_POST(be_alloc_chunk_invariant(c));
+	M0_POST(ergo(result != NULL, be_alloc_chunk_invariant(a, result)));
 	return result;
 }
 
-static bool
-be_alloc_chunk_trymerge(struct be_alloc_chunk *a, struct be_alloc_chunk *b)
+static bool be_alloc_chunk_trymerge(struct m0_be_allocator *al,
+				    struct be_alloc_chunk *a,
+				    struct be_alloc_chunk *b)
 {
-	bool chunks_were_merged = false;
-
-	M0_PRE(be_alloc_chunk_invariant(a));
-	M0_PRE(be_alloc_chunk_invariant(b));
-	M0_PRE((char *) a < (char *) b);
-	if (a != NULL && b != NULL &&
-	    a->bac_free && b->bac_free) {
-		a->bac_size += sizeof(*b) + b->bac_size;
-		be_alloc_chunk_del_fini(b);
+	m0_bcount_t b_size_total;
+	bool	    chunks_were_merged = false;
+
+	M0_PRE(ergo(a != NULL, be_alloc_chunk_invariant(al, a)));
+	M0_PRE(ergo(b != NULL, be_alloc_chunk_invariant(al, b)));
+	M0_PRE(ergo(a != NULL && b != NULL, (char *) a < (char *) b));
+	M0_PRE(ergo(a != NULL, chunks_free_tlink_is_in(a)) ||
+	       ergo(b != NULL, chunks_free_tlink_is_in(b)));
+	if (a != NULL && b != NULL && a->bac_free && b->bac_free) {
+		b_size_total = sizeof(*b) + b->bac_size;
+		be_alloc_chunk_del_fini(al, b);
+		a->bac_size += b_size_total;
 		chunks_were_merged = true;
 	}
-	M0_POST(be_alloc_chunk_invariant(a));
+	M0_POST(ergo(a != NULL, be_alloc_chunk_invariant(al, a)));
+	M0_POST(ergo(b != NULL && !chunks_were_merged,
+		     be_alloc_chunk_invariant(al, b)));
 	return chunks_were_merged;
 }
 
 
-M0_INTERNAL int
-m0_be_allocator_init(struct m0_be_allocator *a, struct m0_be_seg *seg)
+M0_INTERNAL int m0_be_allocator_init(struct m0_be_allocator *a,
+				     struct m0_be_seg *seg)
 {
 	M0_PRE(m0_be_seg__invariant(seg));
 
@@ -247,7 +363,27 @@ M0_INTERNAL void m0_be_allocator_fini(struct m0_be_allocator *a)
 
 M0_INTERNAL bool m0_be_allocator__invariant(struct m0_be_allocator *a)
 {
-	return true;
+	struct be_alloc_chunk *iter;
+	bool		       success = true;
+
+	m0_mutex_lock(&a->ba_lock);
+
+	m0_tl_for(chunks_all, &a->ba_h->bah_chunks.bl_list, iter) {
+		if (!be_alloc_chunk_invariant(a, iter)) {
+			success = false;
+			break;
+		}
+	} m0_tl_endfor;
+	m0_tl_for(chunks_free, &a->ba_h->bah_free.bl_list, iter) {
+		if (!be_alloc_chunk_invariant(a, iter) && !success) {
+			success = false;
+			break;
+		}
+	} m0_tl_endfor;
+
+	m0_mutex_unlock(&a->ba_lock);
+
+	return success;
 }
 
 M0_INTERNAL int m0_be_allocator_create(struct m0_be_allocator *a)
@@ -257,11 +393,8 @@ M0_INTERNAL int m0_be_allocator_create(struct m0_be_allocator *a)
 	m0_bcount_t		       overhead;
 	m0_bcount_t		       free_space;
 
-	M0_PRE(m0_be_allocator__invariant(a));
-
 	h = a->ba_h;
 	/** @todo GET_PTR h */
-	c = &h->bah_main;
 	overhead   = sizeof(struct m0_be_seg_hdr);
 	free_space = a->ba_seg->bs_size - overhead;
 
@@ -271,6 +404,9 @@ M0_INTERNAL int m0_be_allocator_create(struct m0_be_allocator *a)
 
 	m0_mutex_lock(&a->ba_lock);
 
+	h->bah_size = free_space;
+	h->bah_addr = (void *) ((uintptr_t) a->ba_seg->bs_addr + overhead);
+
 	m0_be_list_init(&h->bah_chunks, a->ba_seg);
 	chunks_all_tlist_init(&h->bah_chunks.bl_list);
 	m0_be_list_init(&h->bah_free, a->ba_seg);
@@ -281,10 +417,8 @@ M0_INTERNAL int m0_be_allocator_create(struct m0_be_allocator *a)
 	};
 
 	/* init main chunk */
-	c = &h->bah_main;
-	be_alloc_chunk_init(c, free_space, true);
-	chunks_all_tlist_add_tail(&h->bah_chunks.bl_list, c);
-	chunks_free_tlist_add_tail(&h->bah_free.bl_list, c);
+	c = be_alloc_chunk_add_after(a, NULL, NULL, 0, free_space, true);
+	M0_ASSERT(c != NULL);
 
 	m0_mutex_unlock(&a->ba_lock);
 
@@ -302,11 +436,11 @@ M0_INTERNAL int m0_be_allocator_destroy(struct m0_be_allocator *a)
 	M0_PRE(m0_be_allocator__invariant(a));
 
 	h = a->ba_h;
-	c = &h->bah_main;
+	c = chunks_all_tlist_head(&h->bah_chunks.bl_list);
 	/** @todo GET_PTR h */
 	m0_mutex_lock(&a->ba_lock);
 
-	be_alloc_chunk_del_fini(c);
+	be_alloc_chunk_del_fini(a, c);
 
 	chunks_free_tlist_fini(&h->bah_free.bl_list);
 	m0_be_list_fini(&h->bah_free);
@@ -335,11 +469,13 @@ M0_INTERNAL void *m0_be_alloc(struct m0_be_allocator *a,
 
 	M0_PRE(m0_be_allocator__invariant(a));
 	m0_mutex_lock(&a->ba_lock);
+	/* algorithm starts here */
 	m0_tl_for(chunks_free, &a->ba_h->bah_free.bl_list, iter) {
 		c = be_alloc_chunk_trysplit(a, iter, size, shift);
 		if (c != NULL)
 			break;
 	} m0_tl_endfor;
+	/* and ends here */
 	m0_mutex_unlock(&a->ba_lock);
 	M0_POST(m0_be_allocator__invariant(a));
 
@@ -357,24 +493,27 @@ M0_INTERNAL void m0_be_free(struct m0_be_allocator *a,
 	struct be_alloc_chunk *next;
 	bool		       chunks_were_merged;
 
+	if (ptr == NULL)
+		return;
+
 	M0_PRE(m0_be_allocator__invariant(a));
 	m0_mutex_lock(&a->ba_lock);
 	if (ptr != NULL) {
 		c = be_alloc_chunk_addr(ptr);
-		M0_PRE(be_alloc_chunk_invariant(c));
+		M0_PRE(be_alloc_chunk_invariant(a, c));
 		M0_PRE(!c->bac_free);
-		/* actual algorithm starts here */
-		c->bac_free = true;
+		/* algorithm starts here */
+		be_alloc_chunk_mark_free(a, c);
 		prev = be_alloc_chunk_prev(a, c);
 		next = be_alloc_chunk_next(a, c);
-		chunks_were_merged = be_alloc_chunk_trymerge(prev, c);
+		chunks_were_merged = be_alloc_chunk_trymerge(a, prev, c);
 		if (chunks_were_merged)
 			c = prev;
-		be_alloc_chunk_trymerge(c, next);
+		be_alloc_chunk_trymerge(a, c, next);
 		/* and ends here */
 		M0_POST(c->bac_free);
 		M0_POST(c->bac_size > 0);
-		M0_POST(be_alloc_chunk_invariant(c));
+		M0_POST(be_alloc_chunk_invariant(a, c));
 	}
 	m0_mutex_unlock(&a->ba_lock);
 	M0_POST(m0_be_allocator__invariant(a));
diff --git a/be/alloc.h b/be/alloc.h
index 4914f1f..5dc5b0a 100644
--- a/be/alloc.h
+++ b/be/alloc.h
@@ -82,7 +82,7 @@ M0_INTERNAL void m0_be_alloc_stats(struct m0_be_allocator *a,
 				   struct m0_be_allocator_stats *out);
 
 #define M0_BE_ALLOC_ARR(seg, tx, op, shift, arr, nr)			\
-	((arr) = m0_be_alloc(&(seg)->bs_allocator, (tx), (op), \
+	((arr) = m0_be_alloc(&(seg)->bs_allocator, (tx), (op),		\
 			     (nr) * sizeof ((arr)[0])), (shift))
 
 #define M0_BE_ALLOC_PTR(seg, tx, op, shift, ptr)			\
diff --git a/be/alloc_internal.h b/be/alloc_internal.h
index b43840c..35dde07 100644
--- a/be/alloc_internal.h
+++ b/be/alloc_internal.h
@@ -66,7 +66,8 @@ struct m0_be_allocator_header {
 	struct m0_be_list	      bah_chunks;	/**< all chunks */
 	struct m0_be_list	      bah_free;		/**< free chunks */
 	struct m0_be_allocator_stats  bah_stats;
-	struct be_alloc_chunk	      bah_main;		/**< main chunk */
+	m0_bcount_t		      bah_size;		/**< memory size */
+	void			     *bah_addr;		/**< memory address */
 };
 
 /** @} end of be group */
diff --git a/be/seg.c b/be/seg.c
index b6a36e3..0d1b947 100644
--- a/be/seg.c
+++ b/be/seg.c
@@ -110,6 +110,11 @@ seg_header_create(struct m0_be_seg *seg, void *addr, m0_bcount_t size)
 				  BE_SEG_HEADER_OFFSET, st_block_shift);
 	m0_free(hdrbuf);
 
+	if (rc == 0) {
+		seg->bs_addr = addr;
+		seg->bs_size = size;
+	}
+
 	return rc;
 }
 
diff --git a/be/ut/alloc.c b/be/ut/alloc.c
index 1cb0071..c2b0c7f 100644
--- a/be/ut/alloc.c
+++ b/be/ut/alloc.c
@@ -20,16 +20,148 @@
 
 #include "be/alloc.h"
 
+#include "lib/memory.h"		/* m0_addr_is_aligned */
+#include "lib/misc.h"		/* M0_SET_ARR0 */
+#include "lib/thread.h"		/* m0_thread */
 #include "ut/ut.h"		/* M0_UT_ASSERT */
 #include "be/ut/helper.h"	/* m0_be_ut_seg_helper */
 
-static struct m0_be_ut_seg_helper be_ut_seg_helper;
-static struct m0_be_seg		  be_ut_seg;
+#include <stdlib.h>		/* rand_r */
+#include <string.h>		/* memset */
+
+enum {
+	BE_UT_ALLOC_SIZE   = 0x100,
+	BE_UT_ALLOC_SHIFT  = 13,
+	BE_UT_ALLOC_PTR_NR = 0x100,
+	BE_UT_ALLOC_NR	   = 0x1000,
+	BE_UT_ALLOC_MT_NR  = 0x100,
+	BE_UT_ALLOC_THR_NR = 0x10,
+};
+
+struct be_ut_alloc_thread_state {
+	struct m0_thread ats_thread;
+	/** pointers array for this thread */
+	void		*ats_ptr[BE_UT_ALLOC_PTR_NR];
+	/** number of interations for this thread */
+	int		 ats_nr;
+};
+
+static struct m0_be_ut_seg_helper      be_ut_alloc_seg_helper;
+static struct m0_be_seg		       be_ut_alloc_seg;
+static struct m0_be_allocator	       be_ut_allocator;
+static struct be_ut_alloc_thread_state be_ut_ts[BE_UT_ALLOC_THR_NR];
+
+static void be_ut_alloc_init(void)
+{
+	int rc;
+
+	m0_be_ut_seg_create_open(&be_ut_alloc_seg_helper, &be_ut_alloc_seg);
+	rc = m0_be_allocator_init(&be_ut_allocator, &be_ut_alloc_seg);
+	M0_UT_ASSERT(rc == 0);
+}
+
+static void be_ut_alloc_fini(void)
+{
+	m0_be_allocator_fini(&be_ut_allocator);
+	m0_be_ut_seg_close_destroy(&be_ut_alloc_seg_helper, &be_ut_alloc_seg);
+}
+
+static void be_ut_alloc_create(void)
+{
+	int rc;
+
+	be_ut_alloc_init();
+	rc = m0_be_allocator_create(&be_ut_allocator);
+	M0_UT_ASSERT(rc == 0);
+}
+
+static void be_ut_alloc_destroy()
+{
+	int rc;
+
+	rc = m0_be_allocator_destroy(&be_ut_allocator);
+	M0_UT_ASSERT(rc == 0);
+	be_ut_alloc_fini();
+}
 
 M0_INTERNAL void m0_be_ut_alloc_init_fini(void)
 {
-	m0_be_ut_seg_create(&be_ut_seg_helper, &be_ut_seg);
-	m0_be_ut_seg_destroy(&be_ut_seg_helper, &be_ut_seg);
+	be_ut_alloc_init();
+	be_ut_alloc_fini();
+}
+
+M0_INTERNAL void m0_be_ut_alloc_create_destroy(void)
+{
+	be_ut_alloc_create();
+	be_ut_alloc_destroy();
+}
+
+static void be_ut_alloc_thread(int index)
+{
+	struct be_ut_alloc_thread_state *ts = &be_ut_ts[index];
+	unsigned int			 seed = index;
+	m0_bcount_t			 size;
+	unsigned			 shift;
+	int				 i;
+	int				 j;
+	void				*p;
+
+	memset(&ts->ats_ptr, 0, sizeof(ts->ats_ptr));
+	for (j = 0; j < ts->ats_nr; ++j) {
+		i = rand_r(&seed) % BE_UT_ALLOC_PTR_NR;
+		p = ts->ats_ptr[i];
+		if (p == NULL) {
+			size = (rand_r(&seed) % BE_UT_ALLOC_SIZE) + 1;
+			shift = rand_r(&seed) % BE_UT_ALLOC_SHIFT;
+			p = m0_be_alloc(&be_ut_allocator, NULL, NULL, /* XXX */
+					size, shift);
+			M0_UT_ASSERT(p != NULL);
+			M0_UT_ASSERT(m0_addr_is_aligned(p, shift));
+			if (p != NULL)
+				memset(p, 0xFF, size);
+		} else {
+			m0_be_free(&be_ut_allocator, NULL, NULL, /* XXX */ p);
+			p = NULL;
+		}
+		ts->ats_ptr[i] = p;
+	}
+	for (i = 0; i < BE_UT_ALLOC_PTR_NR; ++i)
+		m0_be_free(&be_ut_allocator, NULL, NULL, /* XXX */
+			   ts->ats_ptr[i]);
+}
+
+static void be_ut_alloc_mt(int nr)
+{
+	int rc;
+	int i;
+
+	M0_SET_ARR0(be_ut_ts);
+	for (i = 0; i < nr; ++i) {
+		be_ut_ts[i].ats_nr = nr == 1 ? BE_UT_ALLOC_NR :
+					       BE_UT_ALLOC_MT_NR;
+	}
+	be_ut_alloc_create();
+	for (i = 0; i < nr; ++i) {
+		rc = M0_THREAD_INIT(&be_ut_ts[i].ats_thread, int, NULL,
+				    &be_ut_alloc_thread, i,
+				    "#%dbe_ut_alloc", i);
+		M0_UT_ASSERT(rc == 0);
+	}
+	for (i = 0; i < nr; ++i) {
+		m0_thread_join(&be_ut_ts[i].ats_thread);
+		m0_thread_fini(&be_ut_ts[i].ats_thread);
+	}
+	be_ut_alloc_destroy();
+}
+
+M0_INTERNAL void m0_be_ut_alloc_multiple(void)
+{
+	be_ut_alloc_mt(1);
+}
+
+M0_INTERNAL void m0_be_ut_alloc_mt(void)
+{
+	be_ut_alloc_mt(BE_UT_ALLOC_THR_NR);
 }
 
 /*
diff --git a/be/ut/helper.c b/be/ut/helper.c
index e8ab6f0..4d23c98 100644
--- a/be/ut/helper.c
+++ b/be/ut/helper.c
@@ -33,7 +33,7 @@
 enum {
 	BE_SEG_UT_DOM_ID   = 42,
 	BE_SEG_UT_STOB_ID  = 42,
-	BE_SEG_UT_SEG_SIZE = 0x10000,
+	BE_SEG_UT_SEG_SIZE = 0x1000000,	/**< 16MiB */
 };
 
 const char *seg_ut_storage_dir = "./__seg_ut_stob";
diff --git a/be/ut/helper.h b/be/ut/helper.h
index c88a5a8..b66a828 100644
--- a/be/ut/helper.h
+++ b/be/ut/helper.h
@@ -28,6 +28,7 @@
 #include "be/be.h"		/* m0_be */
 #include "dtm/dtm.h"		/* m0_dtx */
 
+/** Helper structure for easy segment preparing for UT */
 struct m0_be_ut_seg_helper {
 	struct m0_stob_domain *bus_dom;
 	struct m0_dtx	       bus_dtx;
diff --git a/be/ut/main.c b/be/ut/main.c
index ba43a0a..b78dbf2 100644
--- a/be/ut/main.c
+++ b/be/ut/main.c
@@ -25,14 +25,20 @@ extern void m0_be_ut_seg_create_destroy(void);
 extern void m0_be_ut_seg_open_close(void);
 
 extern void m0_be_ut_alloc_init_fini(void);
+extern void m0_be_ut_alloc_create_destroy(void);
+extern void m0_be_ut_alloc_multiple(void);
+extern void m0_be_ut_alloc_mt(void);
 
 const struct m0_test_suite m0_be_ut = {
 	.ts_name = "be-ut",
 	.ts_tests = {
-		{ "seg-init",   m0_be_ut_seg_init_fini		},
-		{ "seg-create", m0_be_ut_seg_create_destroy	},
-		{ "seg-open",   m0_be_ut_seg_open_close		},
-		{ "alloc-init", m0_be_ut_alloc_init_fini	},
+		{ "seg-init",       m0_be_ut_seg_init_fini	  },
+		{ "seg-create",     m0_be_ut_seg_create_destroy	  },
+		{ "seg-open",       m0_be_ut_seg_open_close	  },
+		{ "alloc-init",	    m0_be_ut_alloc_init_fini	  },
+		{ "alloc-create",   m0_be_ut_alloc_create_destroy },
+		{ "alloc-multiple", m0_be_ut_alloc_multiple	  },
+		{ "alloc-mt",	    m0_be_ut_alloc_mt		  },
 		{ NULL, NULL }
 	}
 };
-- 
1.8.3.2

