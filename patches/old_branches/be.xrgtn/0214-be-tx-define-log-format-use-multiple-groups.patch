From 199e89e7a99f3e5498345414fd21ff81dd54e5bf Mon Sep 17 00:00:00 2001
From: Alexander Gattin <alexander_gattin@xyratex.com>
Date: Fri, 28 Jun 2013 13:47:10 +0300
Subject: [PATCH 214/228] be/tx: define log format, use multiple groups.

* remove tx_fom.c and tx_fom.h, embed fom directly into tx instead of sm,
  don't use separate set of state names, old M0_BTS_* ones are just fine
* rename M0_BTS_SUBMITTED to M0_BTS_LOG, add M0_BTS_PLACE (use "do" -> "done"
  semantics)
* move remains of Anatoliy's fom implementation from tx_fom.c to tx.c
* add per-state list of tx groups to tx engine
* add reqh parameter to m0_be_tx_init
* add payload_size parameter to m0_be_tx_prep
* assume that tx engine always has at least as much empty (pre-allocated)
  tx groups, as transactions in ACTIVE plus OPENING state (reaionale being that
  in worst case scenario we will assign one tx per group when these tx's
  close - we cannot fail with -ENOMEM during m0_be_tx_close(), but we can
  during m0_be_tx_open()):
  - pre-allocate tx group during m0_be_tx_open(). If there's not enough
    memory for tx group and its buffers, fail the transaction
  - pick up pre-allocated tx group during m0_be_tx_close()
* mark deleted regions via rd_skip flag, not by M0_SET0(reg_d)
* calculate tx size in log using t_pos, not t_used (we will write deleted
  regions (holes) into log)
* simplify tx_engine_free_space()
* rewrite tx_log_size()/tx_log_pre_size() based on new log format
* rewrite tx_engine_got_closed() using new pool of ACTIVE group plus
  EMPTY groups
* remove te_inmem, te_placed and other unnecessary pointers from tx engine
* add description of on-disk log format
* merge vvv's commit removing datum parameter from filler callback
* implement tx_group_alloc(): preallocate STOB i/o indexvec/bufvec and v_count
  arrays for maximal number of transactions per group
---
 be/Makefile.sub |   3 +-
 be/tx.c         | 365 +++++++++++++++++++++++++++++++++++++++-----------------
 be/tx.h         | 154 +++++++-----------------
 be/tx_fom.c     |  79 ------------
 be/tx_fom.h     |  52 --------
 be/tx_group.c   | 135 ++++++++++++++++++---
 be/tx_group.h   | 115 +++++++++++++-----
 be/tx_log.c     |  32 +----
 be/tx_log.h     |  17 ++-
 be/tx_regmap.h  |   1 +
 be/tx_state.h   |  79 ++++++++++++
 be/ut/tx.c      |   1 +
 mero/magic.h    |   4 +
 13 files changed, 599 insertions(+), 438 deletions(-)
 delete mode 100644 be/tx_fom.h
 create mode 100644 be/tx_state.h

diff --git a/be/Makefile.sub b/be/Makefile.sub
index d4032d0..a3238bb 100644
--- a/be/Makefile.sub
+++ b/be/Makefile.sub
@@ -3,10 +3,10 @@ nobase_mero_include_HEADERS += be/alloc.h           \
                                be/list.h            \
                                be/seg.h             \
                                be/tx_credit.h       \
-                               be/tx_fom.h          \
                                be/tx_group.c        \
                                be/tx_log.c          \
                                be/tx_regmap.c       \
+                               be/tx_state.h        \
                                be/tx_service.h
 
 mero_libmero_la_SOURCES += be/alloc.c     \
@@ -17,7 +17,6 @@ mero_libmero_la_SOURCES += be/alloc.c     \
                            be/seg.c       \
                            be/tx.c        \
                            be/tx_credit.c \
-                           be/tx_fom.c    \
                            be/tx_group.c  \
                            be/tx_log.c    \
                            be/tx_regmap.c \
diff --git a/be/tx.c b/be/tx.c
index 21a5591..7b38c62 100644
--- a/be/tx.c
+++ b/be/tx.c
@@ -23,6 +23,7 @@
 
 #include <search.h>            /* tsearch */
 
+#include "fop/fom.h"
 #include "lib/errno.h"
 #include "lib/misc.h"          /* m0_forall */
 #include "lib/cdefs.h"         /* ARRAY_SIZE */
@@ -32,7 +33,7 @@
 
 #include "be/be.h"
 #include "be/tx.h"
-#include "fop/fom.h"
+#include "be/tx_service.h"     /* m0_be_txs_stype */
 
 /**
  * @addtogroup be
@@ -89,19 +90,19 @@ static struct m0_sm_state_descr tx_states[M0_BTS_NR] = {
 		.sd_in        = NULL,
 		.sd_ex        = NULL,
 		.sd_invariant = tx_invariant,
-		.sd_allowed   = M0_BITS(M0_BTS_SUBMITTED),
+		.sd_allowed   = M0_BITS(M0_BTS_LOG),
 	},
-	[M0_BTS_SUBMITTED] = {
+	[M0_BTS_LOG] = {
 		.sd_flags     = 0,
-		.sd_name      = "M0_BTS_SUBMITTED",
+		.sd_name      = "M0_BTS_LOG",
 		.sd_in        = NULL,
 		.sd_ex        = NULL,
 		.sd_invariant = tx_invariant,
-		.sd_allowed   = M0_BITS(M0_BTS_LOGGED),
+		.sd_allowed   = M0_BITS(M0_BTS_PLACE),
 	},
-	[M0_BTS_LOGGED] = {
+	[M0_BTS_PLACE] = {
 		.sd_flags     = 0,
-		.sd_name      = "M0_BTS_LOGGED",
+		.sd_name      = "M0_BTS_PLACE",
 		.sd_in        = NULL,
 		.sd_ex        = NULL,
 		.sd_invariant = tx_invariant,
@@ -133,13 +134,111 @@ static struct m0_sm_state_descr tx_states[M0_BTS_NR] = {
 	}
 };
 
+static void tx_fom_fini(struct m0_fom *fom)
+{
+	M0_ENTRY();
+	m0_fom_fini(fom);
+	M0_LEAVE();
+}
+
+static size_t tx_fom_home_locality(const struct m0_fom *fom)
+{
+	struct m0_be_tx *tx = container_of(fom, struct m0_be_tx, t_fom);
+	return tx->t_hdr.th_id;
+}
+
+static int tx_fom_tick(struct m0_fom *fom)
+{
+	struct m0_be_tx        *tx = container_of(fom, struct m0_be_tx, t_fom);
+	int                     rc;
+
+	M0_LOG(M0_DEBUG, "phase = %d", m0_fom_phase(fom));
+
+	switch (m0_fom_phase(fom)) {
+	case M0_BTS_INIT:
+	case M0_BTS_OPENING:
+	case M0_BTS_ACTIVE:
+	case M0_BTS_CLOSED:
+	case M0_BTS_GROUPED:
+		/* noop */
+		return M0_FSO_WAIT;
+
+	case M0_BTS_LOG:
+		/* noop, group switches all its transactions to LOG state
+		 * and after log i/o completes, switches them to LOGGED one
+		 * by one (serially), so that each transaction comes full
+		 * cycle from LOGGED to PLACED state before next one is
+		 * switched to LOGGED. */
+		return M0_FSO_WAIT;
+
+	case M0_BTS_LOGGED:
+		/* when tx is awoken in LOGGED state, it starts SEG i/o. */
+		/* chan_lock &tx->t_stobio.si_wait */
+		m0_mutex_lock(tx->t_stobio.si_wait.ch_guard);
+		m0_fom_wait_on(fom, &tx->t_stobio.si_wait, &fom->fo_cb);
+		M0_LOG(M0_DEBUG, "set up wait on chan %p",
+		       &tx->t_stobio.si_wait);
+		/* chan_unlock &tx->t_stobio.si_wait */
+		rc = m0_be_launch_seg_write(tx);
+		m0_mutex_unlock(tx->t_stobio.si_wait.ch_guard);
+		if (rc == 0) {
+			M0_LOG(M0_DEBUG, "launched tx%p i/o", tx);
+			tx_state_set(tx, M0_BTS_PLACE);
+		} else
+			tx_state_move(tx, rc, M0_BTS_FAILED);
+		return M0_FSO_WAIT;
+
+	case M0_BTS_PLACE:
+		/* when tx is awoken in PLACE state, SEG i/o is complete. */
+		m0_be_tx_free(tx);  /* free region and i/o buffers */
+		rc = tx->t_stobio.si_rc;
+		if (rc == 0)
+			tx_state_set(tx, M0_BTS_PLACED);
+		else
+			tx_state_move(tx, rc, M0_BTS_FAILED);
+		return M0_FSO_AGAIN;
+
+	case M0_BTS_PLACED:
+		tx_state_set(tx, M0_BTS_STABLE);
+		gr_tlist_del(tx);
+		tx_tlist_del(tx);
+
+		m0_fom_phase_set(fom, M0_FOM_PHASE_FINISH);
+		return M0_FSO_WAIT;
+
+	case M0_BTS_STABLE:
+	case M0_BTS_FAILED:
+	default:
+		M0_IMPOSSIBLE("XXX Just for now it's not possible...");
+	}
+}
+
 static const struct m0_sm_conf tx_sm_conf = {
-	.scf_name      = "m0_be_tx::bo_sm",
+	.scf_name      = "m0_be_tx::bo_fom",
 	.scf_nr_states = M0_BTS_NR,
 	.scf_state     = tx_states
 };
 
-static enum m0_be_tx_state tx_state    (const struct m0_be_tx *tx);
+static const struct m0_fom_ops tx_fom_ops = {
+	.fo_fini          = tx_fom_fini,
+	.fo_tick          = tx_fom_tick,
+	.fo_home_locality = tx_fom_home_locality,
+	.fo_addb_init     = NULL
+};
+
+static const struct m0_fom_type_ops tx_fom_type_ops = {
+	.fto_create = NULL
+};
+
+static struct m0_fom_type tx_fom_type;
+
+M0_INTERNAL void m0_be_tx_fom_type_init(void)
+{
+	/* XXX: why is conf passed as non-const to fom init()? */
+	m0_fom_type_init(&tx_fom_type, &tx_fom_type_ops, &m0_be_txs_stype,
+			 (struct m0_sm_conf*)&tx_sm_conf);
+}
+
 static struct m0_be_tx_engine *tx_engine(const struct m0_be_tx *tx);
 
 static void        tx_open_tail        (struct m0_be_tx *tx);
@@ -156,8 +255,9 @@ M0_INTERNAL void m0_be_tx_engine_init(struct m0_be_tx_engine *engine)
 {
 	m0_forall(i, ARRAY_SIZE(engine->te_txs),
 		  (tx_tlist_init(&engine->te_txs[i]), true));
+	m0_forall(i, ARRAY_SIZE(engine->te_tgs),
+		  (tx_tlist_init(&engine->te_tgs[i]), true));
 	m0_rwlock_init(&engine->te_lock);
-	tx_group_init(&engine->te_group);
 	log_init(&engine->te_log);
 
 	M0_POST(m0_be__tx_engine_invariant(engine));
@@ -167,35 +267,44 @@ M0_INTERNAL void m0_be_tx_engine_fini(struct m0_be_tx_engine *engine)
 {
 	M0_PRE(m0_be__tx_engine_invariant(engine));
 
-	tx_group_fini(&engine->te_group);
 	m0_rwlock_fini(&engine->te_lock);
+	m0_forall(i, ARRAY_SIZE(engine->te_tgs),
+		  (tx_tlist_fini(&engine->te_tgs[i]), true));
 	m0_forall(i, ARRAY_SIZE(engine->te_txs),
 		  (tx_tlist_fini(&engine->te_txs[i]), true));
 }
 
 M0_INTERNAL void m0_be_tx_init(struct m0_be_tx *tx, uint64_t tid,
 			       struct m0_be *be, struct m0_sm_group *tx_grp,
+			       struct m0_reqh *reqh,
 			       m0_be_tx_cb_t persistent,
 			       m0_be_tx_cb_t discarded,
 			       void (*filler)(struct m0_be_tx *tx,
-					      void *payload, void *datum),
+					      void *payload),
 			       void *datum)
 {
-	m0_sm_init(&tx->t_sm, &tx_sm_conf, M0_BTS_INIT, tx_grp);
+	m0_fom_init(&tx->t_fom, &tx_fom_type, &tx_fom_ops, NULL, NULL, reqh,
+		    &m0_be_txs_stype);
 	m0_stob_io_init(&tx->t_stobio);
-	tx->t_root       = NULL;
-	tx->t_id         = tid;
-	tx->t_be         = be;
-	tx->t_persistent = persistent;
-	tx->t_discarded  = discarded;
-	tx->t_filler     = filler;
-	tx->t_datum      = datum;
+	tx->t_root                = NULL;
+	tx->t_hdr.th_id           = tid;
+	tx->t_be                  = be;
+	tx->t_persistent          = persistent;
+	tx->t_discarded           = discarded;
+	tx->t_filler              = filler;
+	tx->t_hdr.th_payload_size = 0;
+	tx->t_datum               = datum;
 	m0_be_tx_credit_init(&tx->t_prepared);
 	m0_be_tx_credit_init(&tx->t_captured);
 	m0_be_tx_credit_init(&tx->t_used);
 	m0_be_tx_credit_init(&tx->t_pos);
-	tx_tlink_init_at(tx, &tx_engine(tx)->te_txs[M0_BTS_INIT]);
+
 	gr_tlink_init(tx);
+	tx_engine_lock(tx_engine(tx));
+	M0_PRE(m0_be__tx_engine_invariant(tx_engine(tx)));
+	m0_fom_queue(&tx->t_fom, reqh);  /* init state machine */
+	tx_tlink_init_at(tx, &tx_engine(tx)->te_txs[M0_BTS_INIT]);
+	tx_engine_unlock(tx_engine(tx));
 
 	M0_POST(m0_be__tx_invariant(tx));
 }
@@ -205,7 +314,7 @@ M0_INTERNAL void m0_be_tx_fini(struct m0_be_tx *tx)
 	M0_PRE(m0_be__tx_invariant(tx));
 
 	tx_tlink_del_fini(tx);
-	m0_sm_fini(&tx->t_sm);
+	m0_fom_fini(&tx->t_fom);
 }
 
 M0_INTERNAL void m0_be_tx_free(struct m0_be_tx *tx)
@@ -239,16 +348,15 @@ M0_INTERNAL void m0_be_tx_free(struct m0_be_tx *tx)
 	M0_LEAVE();
 }
 
-M0_INTERNAL void
-m0_be_tx_prep(struct m0_be_tx *tx, const struct m0_be_tx_credit *credit)
+M0_INTERNAL void m0_be_tx_prep(struct m0_be_tx *tx,
+			       const struct m0_be_tx_credit *credit,
+			       m0_bcount_t payload_size)
 {
 	M0_PRE(m0_be__tx_invariant(tx));
 	M0_PRE(tx_state(tx) == M0_BTS_INIT);
 
 	m0_be_tx_credit_add(&tx->t_prepared, credit);
-#if 1  /* added XXX */
-	tx->t_payload_size = tx->t_prepared.tc_reg_size;
-#endif
+	tx->t_hdr.th_payload_size += payload_size;
 	tx_state_set(tx, M0_BTS_PREPARE);
 
 	M0_POST(m0_be__tx_invariant(tx));
@@ -260,35 +368,48 @@ M0_INTERNAL void m0_be_tx_open(struct m0_be_tx *tx)
 	struct m0_be_tx_credit *prepared = &tx->t_prepared;
 	struct m0_bufvec       *bv;
 	struct m0_indexvec     *iv;
-	m0_bcount_t             log_size = tx_prepared_log_size(tx);
+	m0_bcount_t             log_size = tx_log_pre_size(tx);
 
 	M0_PRE(m0_be__tx_invariant(tx));
 	M0_PRE(tx_state(tx) == M0_BTS_PREPARE);
+	/* Must have more or the same number of empty groups as open
+	 * transactions.*/
+	M0_PRE(tg_tlist_length(&eng->te_tgs[M0_BGS_EMPTY]) >=
+	       tx_tlist_length(&eng->te_txs[M0_BTS_ACTIVE])
+	       tx_tlist_length(&eng->te_txs[M0_BTS_OPENING]));
 
-	if (log_size <= min_check(eng->te_log.lg_size,
-				  eng->te_log.lg_gr_size_max)) {
-		M0_ALLOC_ARR(tx->t_reg_d_area, prepared->tc_reg_nr);
-		M0_ALLOC_ARR(tx->t_reg_area, prepared->tc_reg_size);
-		iv = &tx->t_stobio.si_stob;
-		bv = &tx->t_stobio.si_user;
-		M0_ALLOC_ARR(bv->ov_vec.v_count, prepared->tc_reg_nr);
-		iv->iv_vec.v_count = bv->ov_vec.v_count;
-		M0_ALLOC_ARR(bv->ov_buf, prepared->tc_reg_nr);
-		M0_ALLOC_ARR(iv->iv_index, prepared->tc_reg_nr);
-		if (tx->t_reg_d_area != NULL && tx->t_reg_area != NULL &&
-		    bv->ov_vec.v_count != NULL && bv->ov_buf != NULL &&
-		    iv->iv_index != NULL) {
-			tx_engine_lock(eng);
-			if (tx_log_free_space(eng) >= log_size)
-				tx_open_tail(tx);
-			else
-				tx_state_set(tx, M0_BTS_OPENING);
-			tx_engine_unlock(eng);
-		} else {
+	tx_engine_lock(eng);
+	if (log_size <= eng->te_log.lg_size) {
+		/* If number of empty groups is the same as transactions,
+		 * we need to allocate one more group. */
+		if (tg_tlist_length(&eng->te_tgs[M0_BGS_EMPTY]) ==
+		    tx_tlist_length(&eng->te_txs[M0_BTS_ACTIVE])
+		    tx_tlist_length(&eng->te_txs[M0_BTS_OPENING]) &&
+		    tx_group_alloc(eng) == NULL) {
 			tx_fail(tx, -ENOMEM);
+		} else {
+			M0_ALLOC_ARR(tx->t_reg_d_area, prepared->tc_reg_nr);
+			M0_ALLOC_ARR(tx->t_reg_area, prepared->tc_reg_size);
+			iv = &tx->t_stobio.si_stob;
+			bv = &tx->t_stobio.si_user;
+			M0_ALLOC_ARR(bv->ov_vec.v_count, prepared->tc_reg_nr);
+			iv->iv_vec.v_count = bv->ov_vec.v_count;
+			M0_ALLOC_ARR(bv->ov_buf, prepared->tc_reg_nr);
+			M0_ALLOC_ARR(iv->iv_index, prepared->tc_reg_nr);
+			if (tx->t_reg_d_area != NULL && tx->t_reg_area != NULL
+			    && bv->ov_vec.v_count != NULL && bv->ov_buf != NULL
+			    && iv->iv_index != NULL) {
+				if (tx_engine_free_space(eng) >= log_size)
+					tx_open_tail(tx);
+				else
+					tx_state_set(tx, M0_BTS_OPENING);
+			} else {
+				tx_fail(tx, -ENOMEM);
+			}
 		}
 	} else
 		tx_fail(tx, -EFBIG);
+	tx_engine_unlock(eng);
 
 	M0_LOG(M0_DEBUG, "tx%p", tx);
 	M0_POST(m0_be__tx_invariant(tx));
@@ -310,6 +431,7 @@ m0_be_tx_capture(struct m0_be_tx *tx, const struct m0_be_reg *reg)
 	new->rd_idx = idx;
 	new->rd_buf = tx->t_reg_area + pos->tc_reg_size;
 	new->rd_reg = *reg;
+	new->rd_skip = false;
 
 	M0_LOG(M0_DEBUG, "tx%p capture %p: seg%p[%p, %p) -> [%p,%p)",
 	       tx, new, reg->br_seg, new->rd_reg.br_addr,
@@ -356,7 +478,7 @@ m0_be_tx_capture(struct m0_be_tx *tx, const struct m0_be_reg *reg)
 			/* new completely covers old. */
 			credit_mod(&tx->t_used, old, -1);
 			tdelete(old, &tx->t_root, &tx_reg_cmp);
-			M0_SET0(old);
+			old->rd_skip = true;
 		} else {
 			/*
 			 * New and old regions partially overlap.
@@ -435,18 +557,19 @@ M0_INTERNAL void m0_be_tx_close(struct m0_be_tx *tx)
 	tx_engine_lock(eng);
 	M0_PRE(m0_be__tx_engine_invariant(eng));
 
-	eng->te_inmem = tx;
+	tx->t_hdr.th_reg_nr = tx->t_pos.tc_reg_nr;
+	tx->t_hdr.th_reg_size = tx->t_pos.tc_reg_size;
 	tx_state_set(tx, M0_BTS_CLOSED);
 
 	tx_engine_got_closed(eng, tx);
 
-	prepared  = tx_prepared_log_size(tx);
-	used      = tx_log_size(tx, &tx->t_used, tx->t_leader);
+	prepared  = tx_log_pre_size(tx);
+	used      = tx_log_size(tx, &tx->t_pos);
 
 	M0_ASSERT(used <= prepared);
-	M0_ASSERT(eng->te_reserved + used >= prepared);
+	M0_ASSERT(eng->te_reserved >= prepared);
 
-	/* release prepared, but not not used space back into the log. */
+	/* release prepared, but not used space back to the engine. */
 	eng->te_reserved -= prepared - used;
 
 	tx_engine_got_space(eng);
@@ -460,16 +583,24 @@ M0_INTERNAL void m0_be_tx_close(struct m0_be_tx *tx)
 	tx_engine_unlock(eng);
 }
 
+M0_INTERNAL m0_bcount_t tx_log_size(const struct m0_be_tx *tx,
+				    const struct m0_be_tx_credit *cr)
+{
+	return sizeof(struct m0_be_tx_hdr) + tx->t_hdr.th_payload_size
+		cr->tc_reg_nr * sizeof(struct m0_be_reg_d) + cr->tc_reg_size;
+}
+
+/* Worst case estimation of transaction size. */
+M0_INTERNAL m0_bcount_t tx_log_pre_size(const struct m0_be_tx *tx)
+{
+	return tx_log_size(tx, &tx->t_prepared);
+}
+
+/* Return amount of free unreserved space. */
 static m0_bcount_t tx_engine_free_space(const struct m0_be_tx_engine *te)
 {
 	M0_PRE(m0_be__tx_engine_invariant(te));
-#if 1 /*XXX*/
-	return tx_log_free_space(te);
-#else /* Nikita's code */
-	return te->te_log.lg_size -
-		(te->te_inmem->t_lsn - te->te_start->t_lsn +
-		 te->te_reserved);
-#endif
+	return tx_log_free_space(te) - te->te_reserved;
 }
 
 static void tx_engine_got_space(struct m0_be_tx_engine *eng)
@@ -478,7 +609,7 @@ static void tx_engine_got_space(struct m0_be_tx_engine *eng)
 
 	M0_PRE(m0_be__tx_engine_invariant(eng));
 	while ((head = tx_tlist_head(&eng->te_txs[M0_BTS_OPENING])) != NULL &&
-	       tx_prepared_log_size(head) <= tx_engine_free_space(eng))
+	       tx_log_pre_size(head) <= tx_engine_free_space(eng))
 		tx_open_tail(head);
 	M0_POST(m0_be__tx_engine_invariant(eng));
 }
@@ -486,34 +617,53 @@ static void tx_engine_got_space(struct m0_be_tx_engine *eng)
 static void tx_engine_got_closed(struct m0_be_tx_engine *eng,
 				 struct m0_be_tx *tx)
 {
-	struct m0_be_tx_group *gr = &eng->te_group;
-#if 0 /* Nikita's code */
-	m0_bcount_t used = tx_log_size(tx, &tx->t_used,
-				       gr_tlist_is_empty(&gr->tg_tx));
+	struct m0_be_tx_group *gr;
+	bool                   gr_active;
 
 	M0_PRE(tx_state(tx) == M0_BTS_CLOSED);
+	M0_PRE(m0_be__tx_engine_invariant(eng));
 
-	if (gr->tg_opened) {
-		if (gr->tg_used.tc_reg_size + used > eng->te_log.lg_gr_size_max)
-			tx_group_close(eng, gr);
-		else
-			tx_group_add(eng, gr, tx);
+	if (! tg_tlist_is_empty(&eng->te_tgs[M0_BGS_ACTIVE])) {
+		gr = tg_tlist_head(&eng->te_tgs[M0_BGS_ACTIVE]);
+		gr_active = true;
+	} else {
+		gr = tg_tlist_head(&eng->te_tgs[M0_BGS_EMPTY]);
+		gr_active = false;
+	}
+
+	if (gr_active && (tg_log_size(gr) + tx_log_size(tx, &tx->t_pos) >
+			  eng->te_log.lg_gr_size_max || gr->tg_hdr.gh_tx_nr
+			  >= eng->te_log.lg_gr_tx_nr_max)) {
+		tx_group_close(gr);
+		gr = tg_tlist_head(&eng->te_tgs[M0_BGS_EMPTY]);
 	}
-#else
-	/* XXX: close group after every tx close, for now */
-	tx_group_init(gr);
-	tx_group_add(eng, gr, tx);
-	tx_group_close(eng, gr);
-#endif
+
+	tx_group_add(gr, tx);
+
+	/* Check resulting group size again. */
+	if (tg_log_size(gr) >= eng->te_log.lg_gr_size_max ||
+	    gr->tg_hdr.gh_tx_nr >= eng->te_log.lg_gr_tx_nr_max)
+		tx_group_close(gr);
 }
 
 M0_INTERNAL void tx_state_set(struct m0_be_tx *tx, enum m0_be_tx_state state)
 {
 	M0_PRE(m0_be__tx_invariant(tx));
+	M0_PRE(m0_fom_group_is_locked(&tx->t_fom));
+
+	m0_fom_phase_set(&tx->t_fom, state);
+
+	tx_link(tx);
+	M0_POST(m0_be__tx_invariant(tx));
+}
+
+M0_INTERNAL void tx_state_move(struct m0_be_tx *tx, int err,
+			       enum m0_be_tx_state state)
+{
+	M0_PRE(m0_be__tx_invariant(tx));
+	M0_PRE(m0_fom_group_is_locked(&tx->t_fom));
 
-	m0_sm_group_lock(tx->t_sm.sm_grp);
-	m0_sm_state_set(&tx->t_sm, state);
-	m0_sm_group_unlock(tx->t_sm.sm_grp);
+	m0_fom_phase_move(&tx->t_fom, err, state);
 
 	tx_link(tx);
 	M0_POST(m0_be__tx_invariant(tx));
@@ -521,7 +671,7 @@ M0_INTERNAL void tx_state_set(struct m0_be_tx *tx, enum m0_be_tx_state state)
 
 static void tx_open_tail(struct m0_be_tx *tx)
 {
-	m0_bcount_t log_size = tx_prepared_log_size(tx);
+	m0_bcount_t log_size = tx_log_pre_size(tx);
 
 	M0_PRE(M0_IN(tx_state(tx), (M0_BTS_OPENING, M0_BTS_PREPARE)));
 	M0_PRE(tx_engine_free_space(tx_engine(tx)) >= log_size);
@@ -534,21 +684,21 @@ static void tx_fail(struct m0_be_tx *tx, int err)
 {
 	M0_PRE(m0_be__tx_invariant(tx));
 
-	m0_sm_fail(&tx->t_sm, M0_BTS_FAILED, err);
+	m0_fom_phase_move(&tx->t_fom, err, M0_BTS_FAILED);
 	tx_tlist_del(tx);
 
 	M0_POST(m0_be__tx_invariant(tx));
 }
 
-static enum m0_be_tx_state tx_state(const struct m0_be_tx *tx)
+M0_INTERNAL enum m0_be_tx_state tx_state(const struct m0_be_tx *tx)
 {
-	return tx->t_sm.sm_state;
+	return m0_fom_phase(&tx->t_fom);
 }
 
 static void tx_link(struct m0_be_tx *tx)
 {
 	M0_PRE(m0_be__tx_invariant(tx));
-	tx_tlist_move(&tx_engine(tx)->te_txs[tx->t_sm.sm_state], tx);
+	tx_tlist_move(&tx_engine(tx)->te_txs[tx_state(tx)], tx);
 	M0_POST(m0_be__tx_invariant(tx));
 }
 
@@ -560,31 +710,30 @@ static struct m0_be_tx_engine *tx_engine(const struct m0_be_tx *tx)
 M0_INTERNAL bool
 m0_be__tx_engine_invariant(const struct m0_be_tx_engine *engine)
 {
-	/* struct m0_be_log	     *log  = &engine->te_log; */
 	struct m0_be_tx		     *prev = NULL;
 	const struct m0_be_tx_engine *te   = engine;
 
-	return true || ( /* XXX: passify invariant for a while */
+	return
 		m0_forall(i, M0_BTS_NR,
-			  m0_tl_forall(tx, t, &engine->te_txs[i],
+			  m0_tl_forall(tx, t, &te->te_txs[i],
 				       m0_be__tx_invariant(t) &&
 				       ergo(prev != NULL && prev->t_lsn != 0,
 					    t->t_lsn != 0 &&
 					    prev->t_lsn > t->t_lsn) &&
 				       (prev = t, true))) &&
-		te->te_start->t_lsn <= te->te_placed->t_lsn &&
-		te->te_placed->t_lsn <= te->te_logged->t_lsn &&
-		te->te_logged->t_lsn <= te->te_submitted->t_lsn &&
-		te->te_submitted->t_lsn <= te->te_inmem->t_lsn &&
-
-		tx_engine_free_space(te) <= te->te_log.lg_size );
+		M0_IN(tg_tlist_length(&te->te_tgs[M0_BGS_ACTIVE]), (0, 1)) &&
+		tg_tlist_length(&te->te_tgs[M0_BGS_EMPTY]) >=
+		tx_tlist_length(&te->te_txs[M0_BTS_OPENING])
+		tx_tlist_length(&te->te_txs[M0_BTS_ACTIVE]) &&
+		tx_engine_free_space(te) <= te->te_log.lg_size;
 }
 
 M0_INTERNAL bool m0_be__tx_invariant(const struct m0_be_tx *tx)
 {
-	enum m0_be_tx_state state = tx_state(tx);
+	enum m0_be_tx_state    state = tx_state(tx);
+	struct m0_be_tx_group *gr    = tx->t_group;
 
-	return true || ( /* XXX: and this */
+	return
 		state < M0_BTS_NR &&
 		tx_tlist_contains(&tx_engine(tx)->te_txs[state], tx) &&
 		credit_le(&tx->t_captured, &tx->t_prepared) &&
@@ -593,12 +742,8 @@ M0_INTERNAL bool m0_be__tx_invariant(const struct m0_be_tx *tx)
 		(tx->t_lsn == 0) == (state < M0_BTS_GROUPED) &&
 		(tx->t_reg_area != NULL) == (state >= M0_BTS_ACTIVE) &&
 		(tx->t_reg_area == NULL) == (tx->t_reg_d_area == NULL) &&
-		(tx->t_group != NULL) == (state >= M0_BTS_GROUPED) &&
-		(tx->t_leader == (tx->t_group != NULL &&
-				  tx == gr_tlist_head(&tx->t_group->tg_tx))) &&
-		(tx->t_group != NULL) == gr_tlist_contains(&tx->t_group->tg_tx,
-							   tx)
-		);
+		(gr != NULL) == (state >= M0_BTS_GROUPED) &&
+		(gr != NULL) == gr_tlist_contains(&gr->tg_txs[state], tx);
 }
 
 static void tx_engine_lock(struct m0_be_tx_engine *eng)
@@ -611,23 +756,19 @@ static void tx_engine_unlock(struct m0_be_tx_engine *eng)
 	m0_rwlock_write_unlock(&eng->te_lock);
 }
 
-static const struct m0_be_tx *sm2tx(const struct m0_sm *sm)
-{
-	return container_of(sm, const struct m0_be_tx, t_sm);
-}
-
 static bool tx_invariant(const struct m0_sm *sm)
 {
-	return m0_be__tx_invariant(sm2tx(sm));
+	struct m0_fom *fom = container_of(sm, struct m0_fom, fo_sm_phase);
+	return m0_be__tx_invariant(container_of(fom, struct m0_be_tx, t_fom));
 }
 
 M0_INTERNAL int m0_be_tx_timedwait(struct m0_be_tx *tx, int state,
 				   m0_time_t timeout)
 {
-        m0_sm_group_lock(tx->t_sm.sm_grp);
-        m0_sm_timedwait(&tx->t_sm, state, timeout);
-        m0_sm_group_unlock(tx->t_sm.sm_grp);
-        return tx->t_sm.sm_rc;
+	m0_sm_group_lock(tx->t_fom.fo_sm_phase.sm_grp);
+	m0_sm_timedwait(&tx->t_fom.fo_sm_phase, state, timeout);
+	m0_sm_group_unlock(tx->t_fom.fo_sm_phase.sm_grp);
+	return tx->t_fom.fo_sm_phase.sm_rc;
 }
 
 /** @} struct of be group */
diff --git a/be/tx.h b/be/tx.h
index 388d7ea..c5504a0 100644
--- a/be/tx.h
+++ b/be/tx.h
@@ -22,10 +22,12 @@
 #ifndef __MERO_BE_TX_H__
 #define __MERO_BE_TX_H__
 
+#include "fop/fom.h"
 #include "lib/rwlock.h"
 #include "lib/tlist.h"
 #include "lib/types.h"
 #include "sm/sm.h"
+#include "be/tx_state.h"
 #include "be/tx_group.h"
 #include "be/tx_log.h"
 
@@ -38,6 +40,7 @@ struct m0_be_tx_engine;
 struct m0_be_tx;
 struct m0_be_reg_d;
 struct m0_be_reg;
+struct m0_reqh;
 
 /**
  * @defgroup be
@@ -171,6 +174,12 @@ struct m0_be_reg;
  * | (updates in place  |                     |
  * |  and in log)       |                     |
  * |                    |                     |
+ * +--------------------+---------------------+----> start
+ * |                    |                     |
+ * | PLACE              |  persistent         |
+ * | (updates in flight |                     |
+ * |  to place (seg))   |                     |
+ * |                    |                     |
  * +--------------------+---------------------+----> placed
  * |                    |                     |
  * | LOGGED             |  persistent         |
@@ -178,7 +187,7 @@ struct m0_be_reg;
  * |                    |                     |
  * +--------------------+---------------------+----> logged
  * |                    |                     |
- * | SUBMITTED          |  in flight          |
+ * | LOG                |  in flight          |
  * | (updates in flight |                     |
  * |  to log)           |                     |
  * |                    |                     |
@@ -216,70 +225,6 @@ struct m0_be_reg;
  * @endverbatim
  *
  */
-enum m0_be_tx_state {
-	/**
-	 * Transaction failed. It cannot be used further and should be finalised
-	 * (m0_be_tx_fini()).
-	 *
-	 * Currently, the only way a transaction can reach this state is by
-	 * failing to allocate internal memory in m0_be_tx_open() call or by
-	 * growing too large (larger than the total log space) in prepare state.
-	 */
-	M0_BTS_FAILED,
-	/**
-	 * Initial state after m0_be_tx_init().
-	 */
-	M0_BTS_INIT,
-	/**
-	 * State in which transaction is being prepared to opening.
-	 *
-	 * In this state, m0_be_tx_prep() calls should be made to reserve
-	 * internal resources for the future captures. It is allowed to prepare
-	 * for more than will be actually captured: typically it is impossible
-	 * to precisely estimate updates that will be done as part of
-	 * transaction, so a user should conservatively prepare for the
-	 * worst-case.
-	 */
-	M0_BTS_PREPARE,
-	/**
-	 * In this state transaction waits for internal resource to be
-	 * allocated.
-	 *
-	 * Specifically, the transaction is in this state until there is enough
-	 * free space in the log to store transaction updates.
-	 */
-	M0_BTS_OPENING,
-	/**
-	 * In this state transaction is used to capture updates.
-	 */
-	M0_BTS_ACTIVE,
-	/**
-	 * Transaction is closed, but not yet grouped.
-	 */
-	M0_BTS_CLOSED,
-	/**
-	 * Transaction is a member of transaction group.
-	 */
-	M0_BTS_GROUPED,
-	/**
-	 * Transaction updates are in flight to the log.
-	 */
-	M0_BTS_SUBMITTED,
-	/**
-	 * All transaction updates made it to the log.
-	 */
-	M0_BTS_LOGGED,
-	/**
-	 * All transaction in-place updates completed.
-	 */
-	M0_BTS_PLACED,
-	/**
-	 * Transaction was declared stable by call to m0_be_tx_stable().
-	 */
-	M0_BTS_STABLE,
-	M0_BTS_NR
-};
-
 typedef void (*m0_be_tx_cb_t)(const struct m0_be_tx *tx);
 
 /**
@@ -295,20 +240,8 @@ struct m0_be_tx_engine {
 	struct m0_rwlock      te_lock;
 	/** Transactional log. */
 	struct m0_be_log      te_log;
-	/**
-	 * Transactional group. (Currently the only one.)
-	 */
-	struct m0_be_tx_group te_group;
-
-	/*
-	 * Various interesting positions in the log. Probably not needed.
-	 */
-
-	struct m0_be_tx      *te_start;
-	struct m0_be_tx      *te_placed;
-	struct m0_be_tx      *te_logged;
-	struct m0_be_tx      *te_submitted;
-	struct m0_be_tx      *te_inmem;
+	/** Per-state lists of transactional groups. */
+	struct m0_tl          te_tgs[M0_BGS_NR];
 
 	/**
 	 * Total space reserved for transactions active transactions.
@@ -329,14 +262,26 @@ m0_be__tx_engine_invariant(const struct m0_be_tx_engine *engine);
 M0_INTERNAL void m0_be_tx_engine_init(struct m0_be_tx_engine *engine);
 M0_INTERNAL void m0_be_tx_engine_fini(struct m0_be_tx_engine *engine);
 
+/** On-disk transaction header.*/
+struct m0_be_tx_hdr {
+	uint64_t               th_id;  /* Transaction id. */
+	uint64_t               th_lsn; /* Transaction offset. */
+	/**
+	 * Size (in bytes) of "payload area" in the transaction log header,
+	 * reserved for user.
+	 */
+	m0_bcount_t            th_payload_size;
+	size_t                 th_reg_nr;
+	size_t                 th_reg_size;
+};
+
 /**
  * Transaction.
  */
 struct m0_be_tx {
 	uint64_t               t_magic;
-	struct m0_sm           t_sm;
-	/** Transaction identifier, assigned by the user. */
-	uint64_t               t_id;
+	struct m0_be_tx_hdr    t_hdr;
+	struct m0_fom          t_fom;
 	/**
 	 * lsn of transaction representation in the log. Assigned when the
 	 * transaction reaches GROUPED state.
@@ -348,18 +293,10 @@ struct m0_be_tx {
 	 */
 	struct m0_tlink        t_linkage;
 	/**
-	 * Linkage in m0_be_tx_group::tg_tx.
+	 * Linkage in m0_be_tx_group::tg_txs[] lists.
 	 */
 	struct m0_tlink        t_group_linkage;
 	/**
-	 * Size (in bytes) of "payload area" in the transaction log header,
-	 * reserved for user.
-	 *
-	 * User should directly set this field, while the transaction is in
-	 * PREPARE state.
-	 */
-	m0_bcount_t            t_payload_size;
-	/**
 	 * Updates prepared for at PREPARE state.
 	 */
 	struct m0_be_tx_credit t_prepared;
@@ -393,18 +330,18 @@ struct m0_be_tx {
 	 */
 	struct m0_be_tx_credit t_pos;
 	/**
-	 * Internal buffer, allocated in m0_be_tx_open(). It has
+	 * Internal buffer for array of reg_d descriptors. It has
 	 * ->t_prepared.tc_reg_nr elements and is filled with information about
 	 * the regions captured by the transaction.
 	 */
 	struct m0_be_reg_d    *t_reg_d_area;
 	/**
-	 * Internal buffer, allocated in m0_be_tx_open(). It has
+	 * Internal buffer for captured data. It has
 	 * ->t_prepared.tc_reg_size elements and is filled with contents of the
 	 * regions captured by the transaction.
 	 */
 	void                  *t_reg_area;
-	/* STOB i/o structure for seg and log i/o. */
+	/* STOB i/o structure for seg i/o. */
 	struct m0_stob_io      t_stobio;
 	struct m0_clink        t_clink;
 	/**
@@ -413,12 +350,6 @@ struct m0_be_tx {
 	 */
 	struct m0_be_tx_group *t_group;
 	/**
-	 * True iff the transaction is the first transaction in the group. In
-	 * this case, the overhead of group (specifically, the size of group
-	 * header and group commit log) are "billed" to the transaction.
-	 */
-	bool                   t_leader;
-	/**
 	 * Optional call-back called when the transaction is guaranteed to
 	 * survive all further failures. This is invoked when the transaction
 	 * reaches LOGGED state.
@@ -444,8 +375,7 @@ struct m0_be_tx {
 	 * A typical use of this call-back is to form a "fol record" used by DTM
 	 * for distributed transaction management.
 	 */
-	void                 (*t_filler)(struct m0_be_tx *tx, void *payload,
-					 void *datum);
+	void                 (*t_filler)(struct m0_be_tx *tx, void *payload);
 	/**
 	 * User-specified value, associated with the transaction. Transaction
 	 * engine doesn't interpret this value. It can be used to pass
@@ -478,25 +408,25 @@ struct m0_be_tx {
 
 M0_INTERNAL bool m0_be__tx_invariant(const struct m0_be_tx *tx);
 
+M0_INTERNAL void m0_be_tx_fom_type_init(void);
+
 M0_INTERNAL void m0_be_tx_init(struct m0_be_tx *tx, uint64_t tid,
 			       struct m0_be *be, struct m0_sm_group *tx_grp,
+			       struct m0_reqh *reqh,
 			       m0_be_tx_cb_t persistent,
 			       m0_be_tx_cb_t discarded,
 			       void (*filler)(struct m0_be_tx *tx,
-					      void *payload, void *datum),
+					      void *payload),
 			       void *datum);
 
 M0_INTERNAL void m0_be_tx_fini(struct m0_be_tx *tx);
 
-/**
- * Frees reg_area, reg_d_area and regions' tree (t_root).
- *
- * XXX DELETEME? Do we really need this function?
- */
+/** Frees reg_area, reg_d_area and regions' tree (t_root). */
 M0_INTERNAL void m0_be_tx_free(struct m0_be_tx *tx);
 
 M0_INTERNAL void m0_be_tx_prep(struct m0_be_tx *tx,
-			       const struct m0_be_tx_credit *credit);
+			       const struct m0_be_tx_credit *credit,
+			       m0_bcount_t payload_size);
 
 M0_INTERNAL void m0_be_tx_open(struct m0_be_tx *tx);
 
@@ -508,6 +438,10 @@ M0_INTERNAL void m0_be_tx_close(struct m0_be_tx *tx);
 M0_INTERNAL int m0_be_tx_timedwait(struct m0_be_tx *tx, int state,
 				   m0_time_t timeout);
 
+M0_INTERNAL m0_bcount_t tx_log_size(const struct m0_be_tx *tx,
+				    const struct m0_be_tx_credit *cr);
+M0_INTERNAL m0_bcount_t tx_log_pre_size(const struct m0_be_tx *tx);
+
 /** Forces the transaction to storage. */
 M0_INTERNAL void m0_be_tx_force(struct m0_be_tx *tx);
 
@@ -516,8 +450,6 @@ M0_INTERNAL void m0_be_tx_force(struct m0_be_tx *tx);
  */
 M0_INTERNAL void m0_be_tx_stable(struct m0_be_tx *tx);
 
-M0_INTERNAL void tx_state_set(struct m0_be_tx *tx, enum m0_be_tx_state state);
-
 M0_TL_DESCR_DECLARE(tx, M0_EXTERN);
 M0_TL_DECLARE(tx, M0_INTERNAL, struct m0_be_tx);
 
diff --git a/be/tx_fom.c b/be/tx_fom.c
index b80adfe..aead65c 100644
--- a/be/tx_fom.c
+++ b/be/tx_fom.c
@@ -127,86 +127,7 @@ static struct m0_sm_conf tx_fom_conf = {
  * TX FOM operations
  * ------------------------------------------------------------------ */
 
-static int tx_fom_tick(struct m0_fom *fom)
-{
-	struct m0_be_tx  *tx = m0_fom_phase(fom) > FS_STARTED ?
-		gr_tlist_head(&fom_to_txm(fom)->tf_engine->te_group.tg_tx) :
-		NULL;
-	int               rc;
-
-	M0_LOG(M0_DEBUG, "phase = %d", m0_fom_phase(fom));
-
-	switch (m0_fom_phase(fom)) {
-	case FS_STARTED:
-		m0_fom_phase_set(fom, FS_GROUP_CLOSED);
-		return M0_FSO_WAIT;
-
-	case FS_GROUP_CLOSED:
-	case FS_SUBMITTED_TO_LOG:
-	case FS_PAYLOAD_LOGGED:
-	case FS_GROUP_HEADER_LOGGED:
-		break;
-
-	case FS_LOG_HEADER_LOGGED:
-		tx_state_set(tx, M0_BTS_SUBMITTED);
-		break;
-
-	case FS_LOGGED:
-		tx_state_set(tx, M0_BTS_LOGGED);
-		break;
-
-	case FS_SUBMITTED_TO_SEG:
-		/* chan_lock &tx->t_stobio.si_wait */
-		m0_mutex_lock(tx->t_stobio.si_wait.ch_guard);
-		m0_fom_wait_on(fom, &tx->t_stobio.si_wait, &fom->fo_cb);
-		M0_LOG(M0_DEBUG, "set up wait on chan %p",
-		       &tx->t_stobio.si_wait);
-		/* chan_unlock &tx->t_stobio.si_wait */
-		rc = m0_be_launch_seg_write(tx);
-		m0_mutex_unlock(tx->t_stobio.si_wait.ch_guard);
-		if (rc == 0) {
-			M0_LOG(M0_DEBUG, "launched tx%p i/o", tx);
-			m0_fom_phase_set(fom, FS_PLACED);
-		} else {
-			m0_fom_phase_set(fom, FS_FAILED);
-		}
-		return M0_FSO_WAIT;
-
-	case FS_PLACED:
-		tx_state_set(tx, M0_BTS_PLACED);
-		m0_be_tx_free(tx);  /* free region and i/o buffers */
-		m0_fom_phase_set(fom, FS_STABLE);
-		return M0_FSO_AGAIN;
-
-	case FS_STABLE:
-		tx_state_set(tx, M0_BTS_STABLE);
-		gr_tlist_del(tx);
-		tx_tlist_del(tx);
-
-		m0_fom_phase_set(fom, M0_FOM_PHASE_FINISH);
-		return M0_FSO_WAIT;
-
-	case FS_FINISHED:
-	case FS_FAILED:
-	default:
-		M0_IMPOSSIBLE("XXX Just for now it's not possible...");
-	}
-
-	m0_fom_phase_set(fom, m0_fom_phase(fom) + 1);
-	return M0_FSO_AGAIN;
-}
 
-static void tx_fom_fini(struct m0_fom *fom)
-{
-	M0_ENTRY();
-	m0_fom_fini(fom);
-	M0_LEAVE();
-}
-
-static size_t tx_fom_home_locality(const struct m0_fom *fom)
-{
-	return 0; /* XXX TODO: reconsider */
-}
 
 static void tx_fom_addb_init(struct m0_fom *fom, struct m0_addb_mc *mc)
 {
diff --git a/be/tx_fom.h b/be/tx_fom.h
deleted file mode 100644
index 451aa52..0000000
--- a/be/tx_fom.h
+++ /dev/null
@@ -1,52 +0,0 @@
-/* -*- C -*- */
-/*
- * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
- *
- * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
- * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
- * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
- * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
- * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
- * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
- * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
- *
- * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
- * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
- * http://www.xyratex.com/contact
- *
- * Original author: Anatoliy Bilenko <anatoliy_bilenko@xyratex.com>
- * Original creation date: 17-Jun-2013
- */
-
-#pragma once
-#ifndef __MERO_BE_TX_FOM_H__
-#define __MERO_BE_TX_FOM_H__
-
-struct m0_reqh;
-struct m0_be_tx_engine;
-
-/**
- * @defgroup be
- * @{
- */
-
-M0_INTERNAL int m0_tx_processing_start(struct m0_reqh *reqh,
-				       struct m0_be_tx_engine *engine);
-
-M0_INTERNAL void m0_tx_processing_stop(void);
-
-/** @} end of be group */
-#endif /* __MERO_BE_TX_FOM_H__ */
-
-/*
- *  Local variables:
- *  c-indentation-style: "K&R"
- *  c-basic-offset: 8
- *  tab-width: 8
- *  fill-column: 80
- *  scroll-step: 1
- *  End:
- */
-/*
- * vim: tabstop=8 shiftwidth=8 noexpandtab textwidth=80 nowrap
- */
diff --git a/be/tx_group.c b/be/tx_group.c
index 960df72..362239b 100644
--- a/be/tx_group.c
+++ b/be/tx_group.c
@@ -20,6 +20,9 @@
 
 #include "be/tx_group.h"
 #include "be/tx.h"
+#include "lib/list.h"    /* M0_TL_DESCR_DEFINE */
+#include "lib/misc.h"    /* m0_forall */
+#include "lib/memory.h"  /* m0_alloc */
 
 /**
  * @addtogroup be
@@ -27,38 +30,119 @@
  * @{
  */
 
-M0_TL_DESCR_DEFINE(gr, "tx group", M0_INTERNAL, struct m0_be_tx,
+M0_TL_DESCR_DEFINE(gr, "transaction group", M0_INTERNAL, struct m0_be_tx,
 		   t_group_linkage, t_magic,
 		   M0_TRACE_TX_MAGIC,
 		   M0_TRACE_TX_GROUP_LIST_MAGIC);
 
 M0_TL_DEFINE(gr, M0_INTERNAL, struct m0_be_tx);
 
-M0_INTERNAL void tx_group_init(struct m0_be_tx_group *gr)
+M0_TL_DESCR_DEFINE(tg, "groups", M0_INTERNAL, struct m0_be_tx_group,
+		   tg_linkage, tg_magic,
+		   M0_TRACE_TG_MAGIC,
+		   M0_TRACE_TG_HEAD_MAGIC);
+
+M0_TL_DEFINE(tg, M0_INTERNAL, struct m0_be_tx_group);
+
+
+/* Must be called with eng lock hold.*/
+M0_INTERNAL void tx_group_init(struct m0_be_tx_group *gr,
+			       struct m0_be_tx_engine *eng)
 {
-#if 0 /* Nikita's code. */
-	M0_SET0(gr);
-#else /*XXX*/
-	gr->tg_lsn = 0ULL;
-	gr->tg_opened = true;
-	m0_be_tx_credit_init(&gr->tg_used);
-	gr_tlist_init(&gr->tg_tx);
-#endif
+	m0_mutex_init(&gr->tg_lock);
+	gr->tg_hdr.gh_tx_nr   = 0;
+	gr->tg_hdr.gh_tx_size = 0;
+	gr->tg_eng            = eng;
+	gr->tg_lsn            = 0ULL;
+	gr->tg_state          = M0_BGS_INIT;
+	m0_forall(i, ARRAY_SIZE(gr->tg_txs),
+		  (tg_tlist_init(&gr->tg_txs[i]), true));
+	m0_stob_io_init(&gr->tg_stobio);
+	tg_tlink_init_at(gr, &eng->te_tgs[gr->tg_state]);
+}
+
+M0_INTERNAL struct m0_be_tx_group *tx_group_alloc(struct m0_be_tx_engine *eng)
+{
+	struct m0_be_tx_group *gr;
+	m0_bcount_t            vec_nr;
+	struct m0_bufvec      *bv;
+	struct m0_indexvec    *iv;
+
+	gr = m0_alloc(sizeof *gr);
+	if (gr == NULL)
+		return NULL;
+
+	m0_stob_io_init(&gr->tg_stobio);
+
+	vec_nr = 3 + 4 * eng->te_log.lg_gr_tx_nr_max;
+	iv = &gr->tg_stobio.si_stob;
+	bv = &gr->tg_stobio.si_user;
+	M0_ALLOC_ARR(bv->ov_vec.v_count, vec_nr);
+	iv->iv_vec.v_count = bv->ov_vec.v_count;
+	if (bv->ov_vec.v_count == NULL)
+		goto stob_fin;
+	M0_ALLOC_ARR(bv->ov_buf, vec_nr);
+	if (bv->ov_buf == NULL)
+		goto free_v_count;
+	M0_ALLOC_ARR(iv->iv_index, vec_nr);
+	if (iv->iv_index == NULL)
+		goto free_bv;
+
+	m0_mutex_init(&gr->tg_lock);
+	gr->tg_hdr.gh_tx_nr   = 0;
+	gr->tg_hdr.gh_tx_size = 0;
+	gr->tg_eng            = eng;
+	gr->tg_lsn            = 0ULL;
+	gr->tg_state          = M0_BGS_EMPTY;
+	m0_forall(i, ARRAY_SIZE(gr->tg_txs),
+		  (tg_tlist_init(&gr->tg_txs[i]), true));
+	tg_tlink_init_at(gr, &eng->te_tgs[gr->tg_state]);
+	return gr;
+
+free_bv:
+	m0_free(bv->ov_buf);
+free_v_count:
+	m0_free(bv->ov_vec.v_count);
+stob_fin:
+	m0_stob_io_fini(&gr->tg_stobio);
+	m0_free(gr);
+	return NULL;
 }
 
 M0_INTERNAL void tx_group_fini(struct m0_be_tx_group *gr)
 {
+	m0_stob_io_fini(&gr->tg_stobio);
+	m0_forall(i, ARRAY_SIZE(gr->tg_txs),
+		  (tg_tlist_fini(&gr->tg_txs[i]), true));
+	m0_mutex_fini(&gr->tg_lock);
 }
 
-M0_INTERNAL void tx_group_add(struct m0_be_tx_engine *eng,
-			 struct m0_be_tx_group *gr, struct m0_be_tx *tx)
+M0_INTERNAL void tx_group_add(struct m0_be_tx_group *gr, struct m0_be_tx *tx)
 {
+	M0_PRE(tx_state(tx) == M0_BTS_CLOSED);
+	M0_PRE(M0_IN(gr->tg_state, (M0_BGS_EMPTY, M0_BGS_ACTIVE)));
+
+	m0_mutex_lock(&gr->tg_lock);  /* XXX: lock before calling
+					 tx_group_add ? */
+	tx->t_group      = gr;
+	gr_tlist_add(&gr->tg_txs[tx_state(tx)], tx);
+
+	if (gr->tg_state == M0_BGS_EMPTY) {
+		/* Assign ID of the 1st transaction as grp ID. */
+		gr->tg_hdr.gh_id  = tx->t_hdr.th_id;
+		gr->tg_hdr.gh_lsn = gr->tg_eng->te_log.lg_lsn;
+		gr->tg_state      = M0_BGS_ACTIVE;
+		tg_tlist_move(&gr->tg_eng->te_tgs[M0_BGS_ACTIVE], gr);
+		/* TODO:XXX Start grop close timer. */
+	}
+	/* Calculate tx offset in log. */
+	tx->t_hdr.th_lsn = gr->tg_hdr.gh_lsn + sizeof(struct m0_be_tg_hdr) +
+		gr->tg_hdr.gh_tx_size;
+	gr->tg_hdr.gh_tx_nr++;
+	gr->tg_hdr.gh_tx_size += tx_log_size(tx, &tx->t_pos);
 
-	tx->t_group  = gr;
-	tx->t_leader = gr_tlist_is_empty(&gr->tg_tx);
+	m0_mutex_unlock(&gr->tg_lock);
 	tx_state_set(tx, M0_BTS_GROUPED);
-	gr_tlist_add(&gr->tg_tx, tx);
-	/* gr->tg_used.     XXX: what's here? */
 }
 
 /**
@@ -66,8 +150,7 @@ M0_INTERNAL void tx_group_add(struct m0_be_tx_engine *eng,
  *
  * A group is closed when it either grows too large or too old.
  */
-M0_INTERNAL void
-tx_group_close(struct m0_be_tx_engine *eng, struct m0_be_tx_group *gr)
+M0_INTERNAL void tx_group_close(struct m0_be_tx_group *gr)
 {
 	/*
 	 * A group is stored as a contiguous extent of the logical log with the
@@ -120,7 +203,21 @@ tx_group_close(struct m0_be_tx_engine *eng, struct m0_be_tx_group *gr)
 	 * When all group's transactions reach PLACED state, the group is
 	 * finalised.
 	 */
-	gr->tg_opened = false; /* XXX FIXME */
+
+	M0_PRE(gr->tg_state == M0_BGS_ACTIVE);
+	m0_mutex_lock(&gr->tg_lock);  /* XXX: lock before calling
+					 tx_group_close ? */
+	gr->tg_state = M0_BGS_CLOSED;
+	gr->tg_eng->te_log.lg_lsn += tg_log_size(gr);
+	tg_tlist_move(&gr->tg_eng->te_tgs[M0_BGS_CLOSED], gr);
+	/* TODO: launch log i/o */
+	m0_mutex_unlock(&gr->tg_lock);
+}
+
+M0_INTERNAL m0_bcount_t tg_log_size(const struct m0_be_tx_group *gr)
+{
+	return sizeof(struct m0_be_tg_hdr) + gr->tg_hdr.gh_tx_size
+		+ sizeof(struct m0_be_tg_cblk);
 }
 
 /** @} end of be group */
diff --git a/be/tx_group.h b/be/tx_group.h
index dc23b1f..0e023cd 100644
--- a/be/tx_group.h
+++ b/be/tx_group.h
@@ -22,7 +22,9 @@
 #ifndef __MERO_BE_TX_GROUP_H__
 #define __MERO_BE_TX_GROUP_H__
 
+#include "be/tx_state.h"
 #include "be/tx_credit.h"
+#include "lib/types.h"
 
 struct m0_be_tx_engine;
 
@@ -32,51 +34,110 @@ struct m0_be_tx_engine;
  * @{
  */
 
+enum m0_be_tg_state {
+        /** Initial state without i/o buffers allocated. */
+	M0_BGS_INIT,
+	/** Initial state with i/o buffers pre-allocated. */
+	M0_BGS_EMPTY,
+	/** Group contains at least one transaction and ready to accept
+	 *  more. */
+	M0_BGS_ACTIVE,
+	/** Group is full and ready for log i/o and seg i/o. */
+	M0_BGS_CLOSED,
+	M0_BGS_LOGGED,
+	M0_BGS_PLACED,
+	M0_BGS_NR
+};
+
+/** On-disk group header. */
+struct m0_be_tg_hdr {
+	m0_bindex_t             gh_lsn;
+	uint64_t                gh_id;    /* id of 1st transaction in group. */
+	m0_bcount_t             gh_tx_nr; /* Number of transactions in group. */
+	m0_bcount_t             gh_tx_size;  /* Number of bytes used by txs. */
+};
+/** On-disk group commit block. */
+struct m0_be_tg_cblk {
+	uint64_t                gc_id;    /* id of last transaction in group. */
+	struct m0_uint128       gc_md5;   /* checksum of all tx grp data
+					     excluding m0_be_tg_cblk. */
+};
+
 /**
  * Transaction group is a collection of transactions, consecutive in closing
  * order, that are written to the log and recovered together.
  *
- * A new group is initially empty. It absorbs transactions as they are closed,
- * until the group either grows larger than m0_be_log::lg_gr_size_max or grows
- * older than XXX. At that point, the group is closed and a new group is opened
- * up to an upper limit (XXX) on groups number (1 is a possible and reasonable
- * such limit).
+ * A new group is initially allocated when a transaction is opened and number
+ * of ready empty groups is to become lower than number of active transactions
+ * (here we aim for the worst case scenario).
+ * First active or empty group in a transaction engine absorbs transactions as
+ * they are closed, until the group either grows larger than
+ * m0_be_log::lg_gr_size_max, m0_be_log::lg_gr_tx_nr_max or grows older than
+ * XXX. At that point, the group is closed and a new group is opened up to an
+ * upper limit (XXX) on groups number (1 is a possible and reasonable such
+ * limit).
+ *
+ * Once a group and all its transactions are closed and the group becomes first
+ * in the transaction's engine te_tgs[M0_BGS_CLOSED] list, STOB i/o is prepared
+ * and launched to write tx group data to log in the next format:
+ *
+ *  grp_hdr, tx1_hdr, tx1_payload, tx1_reg_d_array, tx1_reg_area, tx2_hdr, ...
+ *  txN_hdr, txN_payload, txN_reg_d_array, txN_reg_area, grp_commit_blk
+ *  (where 1 <= N <= lg_gr_tx_nr_max)
+ *
+ * It's easy to see that STOB i/o involves 2+4*N vectors, and each vector is
+ * 3 64-bit entries (bufvec/indexvec/v_count arrays), for 48+176*N bytes total.
+ * If we decide to allocate all 4 parts of the transaction in the single buffer,
+ * the number of STOB i/o parts would be 2+N.
  *
- * Once a group is closed it constructs in memory its persistent representation,
- * consisting of group header, sequence of transaction representations and group
- * commit block. The memory for this representation is pre-allocated in
- * transaction engine to avoid dead-locks. Once representation is constructed,
- * it is written to the log in one or multiple asynchronous IOs. Before group
- * commit block is written, all other IOs for the group must complete. After
- * that, the commit block is written. Once commit block IO completes, it is
- * guaranteed that the entire group is on the log. Waiting for IO completion can
- * be eliminated by using (currently unimplemented) barrier interface provided
- * by m0_stob, or by placing in the commit block a strong checksum of group
- * representation (the latter approach allows to check whether the entire group
- * made it to the log).
+ * Before group commit block is written, all other IOs for the group must
+ * complete. After that, the commit block is written. Once commit block IO
+ * completes, it is guaranteed that the entire group is on the log. Waiting for
+ * IO completion can be eliminated by using (currently unimplemented) barrier
+ * interface provided by m0_stob, or by placing in the commit block a strong
+ * checksum of group representation (the latter approach allows to check whether
+ * the entire group made it to the log).
  *
+ * After grp_commit_blk is written, log superblock is updated to reflect new
+ * "end" position in log STOB. Memory for grp_hdr and grp_commit block is part
+ * of m0_be_tx_group structure, but STOB i/o vectors still need to be allocated.
+ * This allocation is performed when a first trasaction in the group is opened.
+ * New m0_be_tx_grp structure is allocated on heap, STOB i/o vectors are
+ * allocated for lg_gr_tx_nr_max elements, then the transaction's buffers
+ * are allocated.
  */
 struct m0_be_tx_group {
+	struct m0_be_tg_hdr     tg_hdr;  /* header */
+	struct m0_be_tg_cblk    tg_cblk; /* commit block */
+	struct m0_be_tx_engine *tg_eng;
+	uint64_t                tg_magic;
+	/** Linkage in the m0_be_tx_engine::te_tgs[...] lists. */
+	struct m0_tlink         tg_linkage;
 	/** lsn of transaction group header in the log. */
 	m0_bindex_t             tg_lsn;
-	bool                    tg_opened;
-	/** Total size of all updates in all transactions in this group. */
-	struct m0_be_tx_credit  tg_used;
-	/** List of transactions in the group. */
-	struct m0_tl            tg_tx;
+	bool                    tg_state;
+	/** Per-state lists of transactions in this group. */
+	struct m0_tl            tg_txs[M0_BTS_NR];
+	/** Protects all fields of this struct. */
+	struct m0_mutex         tg_lock;
+	/* STOB i/o structure for log i/o. */
+	struct m0_stob_io	tg_stobio;
 };
 
-M0_INTERNAL void tx_group_init(struct m0_be_tx_group *gr);
+M0_INTERNAL void tx_group_init(struct m0_be_tx_group *gr,
+			       struct m0_be_tx_engine *eng);
+M0_INTERNAL struct m0_be_tx_group *tx_group_alloc(struct m0_be_tx_engine *eng);
 M0_INTERNAL void tx_group_fini(struct m0_be_tx_group *gr);
 
-M0_INTERNAL void tx_group_add(struct m0_be_tx_engine *eng,
-			      struct m0_be_tx_group *gr,
+M0_INTERNAL void tx_group_add(struct m0_be_tx_group *gr,
 			      struct m0_be_tx *tx);
-M0_INTERNAL void tx_group_close(struct m0_be_tx_engine *eng,
-				struct m0_be_tx_group *gr);
+M0_INTERNAL void tx_group_close(struct m0_be_tx_group *gr);
+M0_INTERNAL m0_bcount_t tg_log_size(const struct m0_be_tx_group *gr);
 
 M0_TL_DESCR_DECLARE(gr, M0_EXTERN);
 M0_TL_DECLARE(gr, M0_INTERNAL, struct m0_be_tx);
+M0_TL_DESCR_DECLARE(tg, M0_EXTERN);
+M0_TL_DECLARE(tg, M0_INTERNAL, struct m0_be_tx_group);
 
 /** @} end of be group */
 #endif /* __MERO_BE_TX_GROUP_H__ */
diff --git a/be/tx_log.c b/be/tx_log.c
index a6aa6be..91fde01 100644
--- a/be/tx_log.c
+++ b/be/tx_log.c
@@ -68,39 +68,19 @@ struct m0_be_tx_group_desc {
 	uint64_t tgd_tx_nr;
 };
 
-M0_INTERNAL m0_bcount_t tx_log_size(const struct m0_be_tx *tx,
-				    const struct m0_be_tx_credit *cr,
-				    bool leader)
-{
-	return (leader ? sizeof(struct tx_group_header) : 0) +
-		sizeof(struct tx_group_entry) + sizeof(struct tx_header) +
-		tx->t_payload_size +
-		cr->tc_reg_nr * sizeof(struct m0_be_reg_d) + cr->tc_reg_size;
-}
-
 M0_INTERNAL m0_bcount_t tx_log_free_space(const struct m0_be_tx_engine *eng)
 {
-	return eng->te_log.lg_size - eng->te_reserved; /* XXX */
-}
-
-M0_INTERNAL m0_bcount_t tx_prepared_log_size(const struct m0_be_tx *tx)
-{
-	return tx_log_size(tx, &tx->t_prepared, true);
-}
-
-M0_INTERNAL m0_bcount_t tx_group_header_size(m0_bcount_t tx_nr)
-{
-	return sizeof(struct tx_group_header) +
-		tx_nr * sizeof(struct tx_group_entry);
+	return eng->te_log.lg_size - eng->te_reserved;
 }
 
 M0_INTERNAL void log_init(struct m0_be_log *log)
 {
 	*log = (struct m0_be_log) {
-		.lg_lsn         = 0ULL,
-		.lg_size        = 1ULL << 26, /* 64 MB */
-		.lg_gr_size_max = 1ULL << 20, /* 1  MB */
-		.lg_stob        = NULL /* XXX */
+		.lg_lsn          = 0ULL,
+		.lg_size         = 1ULL << 26, /* 64 MB */
+		.lg_gr_size_max  = 1ULL << 20, /* 1  MB */
+		.lg_gr_tx_nr_max = 10,
+		.lg_stob         = NULL /* XXX */
 	};
 }
 
diff --git a/be/tx_log.h b/be/tx_log.h
index 4e85e52..bf04fc6 100644
--- a/be/tx_log.h
+++ b/be/tx_log.h
@@ -62,26 +62,23 @@ struct m0_be_log {
 	struct m0_stob  *lg_stob;
 	/** Log size. */
 	m0_bcount_t      lg_size;
+	/** Maximal transaction group size. */
+	m0_bcount_t      lg_gr_size_max;
 	/**
-	 * Maximal transaction group size.
+	 * Maximal number of transactions per group.
 	 *
-	 * When a transaction group reaches this size, it is "closed" and new
-	 * group starts forming.
+	 * When either lg_gr_size_max or lg_gr_tx_nr_max is reached, the
+	 * transaction group is "closed" and a new group will be picked up
+	 * for the next transaction.
 	 */
-	m0_bcount_t      lg_gr_size_max;
+	m0_bcount_t      lg_gr_tx_nr_max;
 	/**
 	 * lsn to be used for the next log element.
 	 */
 	m0_bindex_t      lg_lsn;
 };
 
-M0_INTERNAL m0_bcount_t tx_log_size(const struct m0_be_tx *tx,
-				    const struct m0_be_tx_credit *cr,
-				    bool leader);
 M0_INTERNAL m0_bcount_t tx_log_free_space(const struct m0_be_tx_engine *eng);
-M0_INTERNAL m0_bcount_t tx_prepared_log_size(const struct m0_be_tx *tx);
-M0_INTERNAL m0_bcount_t tx_group_header_size(m0_bcount_t tx_nr);
-
 M0_INTERNAL void log_init(struct m0_be_log *log);
 
 /** @} end of be group */
diff --git a/be/tx_regmap.h b/be/tx_regmap.h
index 8f2505d..852aff0 100644
--- a/be/tx_regmap.h
+++ b/be/tx_regmap.h
@@ -37,6 +37,7 @@ struct m0_be_reg_d {
 	m0_bindex_t       rd_idx;
 	struct m0_be_reg  rd_reg;
 	void             *rd_buf;
+	bool              rd_skip;
 };
 
 /* Regions tree node for tsearch(). */
diff --git a/be/tx_state.h b/be/tx_state.h
new file mode 100644
index 0000000..c1aafdf
--- /dev/null
+++ b/be/tx_state.h
@@ -0,0 +1,79 @@
+#pragma once
+#ifndef __MERO_BE_TX_STATE_H__
+#define __MERO_BE_TX_STATE_H__
+
+enum m0_be_tx_state {
+	/**
+	 * Initial state after m0_be_tx_init().
+	 */
+	M0_BTS_INIT,
+	/**
+	 * Transaction failed. It cannot be used further and should be finalised
+	 * (m0_be_tx_fini()).
+	 *
+	 * Currently, the only way a transaction can reach this state is by
+	 * failing to allocate internal memory in m0_be_tx_open() call or by
+	 * growing too large (larger than the total log space) in prepare state.
+	 */
+	M0_BTS_FAILED,
+	/**
+	 * State in which transaction is being prepared to opening.
+	 *
+	 * In this state, m0_be_tx_prep() calls should be made to reserve
+	 * internal resources for the future captures. It is allowed to prepare
+	 * for more than will be actually captured: typically it is impossible
+	 * to precisely estimate updates that will be done as part of
+	 * transaction, so a user should conservatively prepare for the
+	 * worst-case.
+	 */
+	M0_BTS_PREPARE,
+	/**
+	 * In this state transaction waits for internal resource to be
+	 * allocated.
+	 *
+	 * Specifically, the transaction is in this state until there is enough
+	 * free space in the log to store transaction updates.
+	 */
+	M0_BTS_OPENING,
+	/**
+	 * In this state transaction is used to capture updates.
+	 */
+	M0_BTS_ACTIVE,
+	/**
+	 * Transaction is closed, but not yet grouped.
+	 */
+	M0_BTS_CLOSED,
+	/**
+	 * Transaction is a member of transaction group.
+	 */
+	M0_BTS_GROUPED,
+	/**
+	 * Transaction updates are in flight to the log.
+	 */
+	M0_BTS_LOG,
+	/**
+	 * Whole group made it to the log.
+	 */
+	M0_BTS_LOGGED,
+	/**
+	 * In-place updates are started.
+	 */
+	M0_BTS_PLACE,
+	/**
+	 * Transaction in-place updates completed.
+	 */
+	M0_BTS_PLACED,
+	/**
+	 * Transaction was declared stable by call to m0_be_tx_stable().
+	 */
+	M0_BTS_STABLE,
+	M0_BTS_NR
+};
+
+struct m0_be_tx;
+M0_INTERNAL enum m0_be_tx_state tx_state(const struct m0_be_tx *tx);
+M0_INTERNAL void tx_state_set(struct m0_be_tx *tx, enum m0_be_tx_state state);
+M0_INTERNAL void tx_state_move(struct m0_be_tx *tx, int err,
+			       enum m0_be_tx_state state);
+
+#endif /*__MERO_BE_TX_STATE_H__*/
diff --git a/be/ut/tx.c b/be/ut/tx.c
index 120f8d8..a12d3ff 100644
--- a/be/ut/tx.c
+++ b/be/ut/tx.c
@@ -32,6 +32,7 @@ static uint64_t           g_tid = 1;
 
 static int seg_create(void)
 {
+	m0_be_tx_fom_type_init();
 	m0_be_ut_h_init(&be_ut_tx_h);
 	m0_sm_group_init(&g_grp);
 	return 0;
diff --git a/mero/magic.h b/mero/magic.h
index 21ff67c..f08203a 100644
--- a/mero/magic.h
+++ b/mero/magic.h
@@ -728,6 +728,10 @@ enum m0_magic_satchel {
 	M0_TRACE_TX_LIST_MAGIC       = 0x3311FE1E556E1277,
 	/* m0_be_tx tx group list head magic (codified bee)  */
 	M0_TRACE_TX_GROUP_LIST_MAGIC = 0x33c0d1f1edbee377,
+	/* m0_be_tx_group::tg_magic for tg_linkage (starshine) */
+	M0_TRACE_TG_MAGIC            = 0x3357a35412e77777,
+	/* m0_be_tx_engine::te_groups head magic (double bass) */
+	M0_TRACE_TG_HEAD_MAGIC       = 0x33d08b1eba557777,
 };
 
 #endif /* __MERO_MERO_MAGIC_H__ */
-- 
1.8.3.2

