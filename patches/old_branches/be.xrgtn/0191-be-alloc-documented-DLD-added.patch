From dee96db22209b11de23334522931849d3f4b0dd5 Mon Sep 17 00:00:00 2001
From: Maxim Medved <Max_Medved@xyratex.com>
Date: Thu, 20 Jun 2013 20:43:22 +0300
Subject: [PATCH 191/228] be/alloc: documented, DLD added

---
 be/alloc.c          | 147 ++++++++++++++++++++++++++++++++++++++++++++--------
 be/alloc.h          | 130 ++++++++++++++++++++++++++++++++++++++++++++--
 be/alloc_internal.h |  16 ++++++
 3 files changed, 268 insertions(+), 25 deletions(-)

diff --git a/be/alloc.c b/be/alloc.c
index 677dde7..15cba0f 100644
--- a/be/alloc.c
+++ b/be/alloc.c
@@ -35,6 +35,127 @@
 
 /**
  * @addtogroup be
+ * @todo make a doxygen page
+ *
+ * Overview
+ *
+ * Definitions
+ *
+ * - allocator segment - memory segment (m0_be_seg) which is used as
+ *   memory for allocations;
+ * - allocator space - part of memory inside the allocator segment in which
+ *   all allocations will take place;
+ * - "B located just after A" - there is no free space in memory
+ *   after A before B, i.e. (char *) B == (char *) A + sizeof(A).
+ * - chunk - memory structure that contains allocator data and user data;
+ * - used chunk - chunk for which address of user data was returned
+ *   to user from m0_be_alloc() and for which m0_be_free() wasn't called;
+ * - free chunk - chunk that is not used;
+ * - adjacent chunks - a and b are adjacent chunks iff chunk a
+ *   located just after b or vice versa;
+ *
+ * Algorithm
+ *
+ * m0_be_alloc(): first-fit algorithm is used.
+ * Time complexity O(N), I/O complexity O(N).
+ *
+ * List of free chunks is scanned until first chunk that fit the alloation
+ * requirements (chunk can be split somehow to obtain the chunk with
+ * size >= requested size and for this chunk start of user data should be
+ * alighed according to "shift" parameter) found. Then free chunk is split
+ * into one or more chunks, and at least one of them should meet the allocation
+ * requirements - pointer to user data of this chunk will be returned as a
+ * result of m0_be_alloc().
+ *
+ * m0_be_free().
+ * Time complexity O(N), I/O complexity O(N).
+ *
+ * Chunk for the given pointer is marked as free and it is added to the free
+ * list. Then this chunk is merged with adjacent free chunks if any exists.
+ *
+ * Allocator space restrictions:
+ * - Each byte of allocator space belongs to a chunk. There is one exception -
+ *   if there is no space for chunk with at least 1 byte of user data from
+ *   the beginning of allocator space to other chunk then this space is
+ *   temporary unused;
+ *
+ * Chunk restrictions:
+ * - all chunks are mutually disjoint;
+ * - chunk is entirely inside the allocator space;
+ * - each chunk is either free or used;
+ * - user data in chunk located just after allocator data;
+ *
+ * Two lists of chunks are maintained:
+ * - m0_be_allocator_header.bah_chunks contains all chunks - the chunks list;
+ * - m0_be_allocator_header.bah_free contains free chunks - the free list.
+ *
+ * Lists of chunks restrictions:
+ * - all chunks in a list are ordered by address;
+ * - every chunk is in the chunks list;
+ * - every free chunk is in the free list;
+ * - free list don't contains used chunk;
+ * - any two unequal to each other chunks in the free list are not adjacent;
+ *
+ * Special cases
+ *
+ * Chunk split in be_alloc_chunk_split()
+ *
+ * @verbatim
+ * |		   |	|	   | |	      |	|	 |
+ * +---------------+	+----------+ +--------+ |	 |
+ * |	prev	   |	|  prev	   | |	      | |	 |
+ * +---------------+	+----------+ |  prev  | |	 | < start0
+ * |		   |	|  chunk0  | |	      | |	 |
+ * |		   |	+----------+ +--------+ +--------+ < start_new
+ * |    c	   |	|	   | |	      | |	 |
+ * |		   |	|  new	   | |  new   | |  new	 |
+ * |		   |	|	   | |	      | |	 |
+ * |		   |	+----------+ +--------+ |	 | < start1
+ * |		   |	|  chunk1  | |	      | |	 |
+ * +---------------+	+----------+ |	      | +--------+ < start_next
+ * |	next	   |	|  next	   | |	      | |  next	 |
+ * +---------------+	+----------+ |	      | +--------+
+ * |		   |	|	   | |	      |	|	 |
+ *
+ * initial position	after split  no space	 no space
+ *				     for chunk0  for chunk1
+ * @endverbatim
+ *
+ * Free chunks merge if it is possible in be_alloc_chunk_trymerge()
+ *
+ * @verbatim
+ * |	      | |	   |
+ * +----------+ +----------+
+ * |	      |	|	   |
+ * |	a     |	|	   |
+ * |	      |	|	   |
+ * |	      |	|	   |
+ * +----------+	|	   |
+ * |	      |	|    a	   |
+ * |	      |	|	   |
+ * |	      |	|	   |
+ * |	b     |	|	   |
+ * |	      |	|	   |
+ * |	      |	|	   |
+ * |	      |	|	   |
+ * +----------+	+----------+
+ * |	      | |	   |
+ * @endverbatim
+ *
+ * Locks
+ *
+ * Allocator lock is used to protect all allocator data. Only one allocation or
+ * freeing may take place at a some point of time for the same allocator.
+ *
+ * Know issues:
+ * - tx is not used in m0_be_alloc() and m0_be_free(), so nothing is
+ *   m0_be_tx_capture()'d;
+ * - op is unconditionally transitioned to state M0_BOS_SUCCESS in m0_be_alloc()
+ *   and m0_be_free().
+ */
+
+/*
+ * @addtogroup be
  *
  * @{
  */
@@ -42,8 +163,6 @@
 enum {
 	/** alignment for m0_be_allocator_header inside segment */
 	BE_ALLOC_HEADER_SHIFT = 3,
-	/** alignment for be_alloc_chunk */
-	BE_ALLOC_CHUNK_SHIFT  = 3,
 };
 
 M0_TL_DESCR_DEFINE(chunks_all, "list of all chunks in m0_be_allocator",
@@ -165,8 +284,8 @@ static struct be_alloc_chunk *be_alloc_chunk_next(struct m0_be_allocator *a,
 	return r;
 }
 
-void be_alloc_chunk_mark_free(struct m0_be_allocator *a,
-			      struct be_alloc_chunk *c)
+static void be_alloc_chunk_mark_free(struct m0_be_allocator *a,
+				     struct be_alloc_chunk *c)
 {
 	struct be_alloc_chunk *next;
 
@@ -230,24 +349,6 @@ be_alloc_chunk_add_after(struct m0_be_allocator *a,
 	return new;
 }
 
-/*
- * +---------------+	+----------+ +--------+ |	 |
- * |	prev	   |	|  prev	   | |	      | |	 |
- * +---------------+	+----------+ |  prev  | |	 | < start0
- * |		   |	|  chunk0  | |	      | |	 |
- * |		   |	+----------+ +--------+ +--------+ < start_new
- * |    c	   |	|	   | |	      | |	 |
- * |		   |	|  new	   | |  new   | |  new	 |
- * |		   |	|	   | |	      | |	 |
- * |		   |	+----------+ +--------+ |	 | < start1
- * |		   |	|  chunk1  | |	      | |	 |
- * +---------------+	+----------+ |	      | +--------+ < start_next
- * |	next	   |	|  next	   | |	      | |  next	 |
- * +-------------- +	+----------+ |	      | +--------+
- *
- * initial position	after split  no space	 no space
- *				     for chunk0  for chunk1
- */
 static struct be_alloc_chunk *
 be_alloc_chunk_split(struct m0_be_allocator *a, struct be_alloc_chunk *c,
 		     uintptr_t start_new, m0_bcount_t size)
@@ -485,6 +586,7 @@ M0_INTERNAL void m0_be_allocator_credit(struct m0_be_allocator *a,
 	struct m0_be_tx_credit header_credit;
 
 	M0_PRE(m0_be_allocator__invariant(a));
+	shift = max_check(shift, (unsigned) M0_BE_ALLOC_SHIFT_MIN);
 
 	chunk_credit  = M0_BE_TX_CREDIT_TYPE(struct be_alloc_chunk);
 	header_credit = M0_BE_TX_CREDIT_TYPE(struct m0_be_allocator_header);
@@ -517,6 +619,7 @@ M0_INTERNAL void *m0_be_alloc(struct m0_be_allocator *a,
 	struct be_alloc_chunk *c = NULL;
 
 	M0_PRE(m0_be_allocator__invariant(a));
+	shift = max_check(shift, (unsigned) M0_BE_ALLOC_SHIFT_MIN);
 
 	/* XXX */
 	m0_be_op_state_set(op, M0_BOS_ACTIVE);
diff --git a/be/alloc.h b/be/alloc.h
index 55847e6..04eed4c 100644
--- a/be/alloc.h
+++ b/be/alloc.h
@@ -34,58 +34,182 @@ struct m0_be_tx_credit;
 /**
  * @defgroup be
  *
+ *
  * @{
  */
 
+enum {
+	/**
+	 * Allocated memory will be aligned using at least this shift.
+	 * @see m0_be_alloc(), m0_be_allocator_credit().
+	 */
+	M0_BE_ALLOC_SHIFT_MIN  = 3,
+};
+
+/**
+ * @brief Allocator statistics
+ *
+ * It is embedded into m0_be_allocator_header.
+ */
 struct m0_be_allocator_stats {
 	m0_bcount_t bas_free_space;
 };
 
 struct m0_be_allocator_header;
 
+/** @brief Allocator */
 struct m0_be_allocator {
+	/**
+	 * Memory is allocated from the segment using first-fit algorithm.
+	 * Entire segment except m0_be_seg_hdr is used as a memory
+	 * for allocations.
+	 */
 	struct m0_be_seg	      *ba_seg;
+	/**
+	 * Lock protects allocator lists and allocator chunks
+	 * (but not allocated memory).
+	 */
 	struct m0_mutex		       ba_lock;
 	/** Internal allocator data. It is stored inside the segment. */
 	struct m0_be_allocator_header *ba_h;
 };
 
+/**
+ * Initialize allocator structure.
+ *
+ * @see m0_be_allocator_header.
+ */
 M0_INTERNAL int m0_be_allocator_init(struct m0_be_allocator *a,
 				     struct m0_be_seg *seg);
 
+/**
+ * Finalize allocator structure.
+ *
+ * It will not affect allocated memory, allocator space or allocator header.
+ */
 M0_INTERNAL void m0_be_allocator_fini(struct m0_be_allocator *a);
+
+/**
+ * Allocator invariant.
+ *
+ * It will perform detailed verefication of allocator data structures.
+ * It will ignore all user data.
+ */
 M0_INTERNAL bool m0_be_allocator__invariant(struct m0_be_allocator *a);
 
+/**
+ * Create allocator on the segment.
+ *
+ * @see m0_be_allocator.ba_seg, m0_be_allocator_init(),
+ * m0_be_allocator_header.
+ */
 M0_INTERNAL int m0_be_allocator_create(struct m0_be_allocator *a);
+
+/**
+ * Destroy allocator on the segment.
+ *
+ * All memory allocations obtained from m0_be_alloc()
+ * should be m0_be_free()'d before calling this function.
+ */
 M0_INTERNAL int m0_be_allocator_destroy(struct m0_be_allocator *a);
 
+/**
+ * Allocator operation.
+ *
+ * @see m0_be_allocator_credit().
+ */
 enum m0_be_allocator_op {
-	M0_BAO_ALLOC,
-	M0_BAO_FREE
+	M0_BAO_ALLOC,	/**< Allocator credit for m0_be_alloc() */
+	M0_BAO_FREE,	/**< Allocator credit for m0_be_free() */
 };
 
-/** add to accum credits for optype */
+/**
+ * Accumulate credits for optype in accum.
+ *
+ * @param a Allocator
+ * @param optype Allocator operation type
+ * @param size Size of allocation for optype = M0_BAO_ALLOC.
+ *	       It is ignored for optype = M0_BAO_FREE.
+ * @param shift Memory for optype = M0_BAO_ALLOC.
+ *	        It is ignored for optype = M0_BAO_FREE.
+ * @param accum Accumulator for credits.
+ *
+ * @see m0_be_alloc(), m0_be_free(), m0_be_tx_credit.
+ */
 M0_INTERNAL void m0_be_allocator_credit(struct m0_be_allocator *a,
 					enum m0_be_allocator_op optype,
 					m0_bcount_t size,
 					unsigned shift,
 					struct m0_be_tx_credit *accum);
 
+/**
+ * Allocate memory.
+ *
+ * @param a Allocator
+ * @param tx Allocation will be done in this transaction
+ * @param op XXX. Now m0_be_op state always set to M0_BOS_SUCCESS upon return
+ *	     from this function.
+ * @param size Memory size
+ * @param shift Memory will be aligned on (shift^2)-byte boundary.
+ *		It can be less than M0_BE_ALLOC_SHIFT_MIN - in this case
+ *		allocation will be done as if it is equal to
+ *		M0_BE_ALLOC_SHIFT_MIN.
+ *
+ * @todo use op.
+ * @see m0_be_allocator_credit(), M0_BAO_ALLOC,
+ * m0_alloc(), m0_alloc_aligned(), M0_BE_ALLOC_SHIFT_MIN.
+ */
 M0_INTERNAL void *m0_be_alloc(struct m0_be_allocator *a,
 			      struct m0_be_tx *tx, struct m0_be_op *op,
 			      m0_bcount_t size, unsigned shift);
 
+/**
+ * Free memory allocated with m0_be_alloc().
+ *
+ * @param a Allocator
+ * @param tx Free operation will be done in this transaction
+ * @param op XXX. Now m0_be_op state always set to M0_BOS_SUCCESS upon return
+ *	     from this function.
+ * @param ptr Pointer to memory to release. May be NULL - in this case
+ *	      op state set to M0_BOS_SUCCESS and call to this function is
+ *	      no-op. If ptr is not NULL, then it should be exactly the pointer
+ *	      returned from m0_be_alloc() for allocator a. Double m0_be_free()
+ *	      is not allowed for the same pointer from one call to
+ *	      m0_be_alloc().
+ *
+ * @todo use op.
+ * @see m0_be_alloc(), m0_be_allocator_credit(), M0_BAO_FREE,
+ * m0_be_allocator_destroy().
+ */
 M0_INTERNAL void m0_be_free(struct m0_be_allocator *a,
 			    struct m0_be_tx *tx, struct m0_be_op *op,
 			    void *ptr);
 
+/**
+ * Return allocator statistics.
+ *
+ * @note Not implemented yet.
+ * @see m0_be_allocator_stats.
+ */
 M0_INTERNAL void m0_be_alloc_stats(struct m0_be_allocator *a,
 				   struct m0_be_allocator_stats *out);
 
+/**
+ * Allocate array of structures.
+ *
+ * It is a wrapper around m0_be_alloc().
+ * @see m0_be_alloc(), M0_ALLOC_ARR().
+ */
 #define M0_BE_ALLOC_ARR(seg, tx, op, shift, arr, nr)			\
 	((arr) = m0_be_alloc(&(seg)->bs_allocator, (tx), (op),		\
 			     (nr) * sizeof ((arr)[0])), (shift))
 
+/**
+ * Allocate structure.
+ *
+ * It is a wrapper around m0_be_alloc().
+ * @see m0_be_alloc(), M0_ALLOC_PTR(), M0_BE_ALLOC_ARR().
+ */
 #define M0_BE_ALLOC_PTR(seg, tx, op, shift, ptr)			\
 		M0_ALLOC_ARR(seg, tx, op, shift, ptr, 1)
 
diff --git a/be/alloc_internal.h b/be/alloc_internal.h
index 171659a..485e8f0 100644
--- a/be/alloc_internal.h
+++ b/be/alloc_internal.h
@@ -34,6 +34,13 @@
  * @{
  */
 
+/**
+ * @brief Allocator chunk.
+ *
+ * - resides in the allocator space;
+ * - located just before allocated memory block;
+ * - there is at least one chunk in the allocator.
+ */
 struct be_alloc_chunk {
 	/**
 	 * M0_BE_ALLOC_MAGIC0
@@ -62,6 +69,15 @@ struct be_alloc_chunk {
 	char		bac_mem[0];
 };
 
+/**
+ * @brief Allocator header.
+ *
+ * - allocator space begins at m0_be_allocator_header.bah_addr and have size
+ *   m0_be_allocator_header.bah_size bytes;
+ * - resides in a segment address space;
+ * - is a part of a segment header. It may be changed in the future;
+ * - contains list headers for chunks lists.
+ */
 struct m0_be_allocator_header {
 	struct m0_be_list	      bah_chunks;	/**< all chunks */
 	struct m0_be_list	      bah_free;		/**< free chunks */
-- 
1.8.3.2

