From f2ed3b1d6882a6eb8126f456c73625ce58d8ab86 Mon Sep 17 00:00:00 2001
From: "anand.vidwansa" <anand_vidwansa@xyratex.com>
Date: Thu, 30 May 2013 02:30:58 -0700
Subject: [PATCH 01/10] Introduced a hash data structure. - Added hash list and
 hash bucket data structures. - Added APIs like add, del, lookup APIs to hash.
 - Added iterative APIs like hash_forall(), hash_for(). - Added UT. - Used
 hash instead of a simple tlist in client IO code where number of  
 target_ioreq objects belonging to a single io_request are kept in   a tlist.

---
 lib/Kbuild.sub                      |   3 +-
 lib/Makefile.sub                    |   2 +
 lib/hash.c                          | 256 +++++++++++++++++++++++++++++
 lib/hash.h                          | 313 ++++++++++++++++++++++++++++++++++++
 lib/ut/Makefile.sub                 |   3 +-
 lib/ut/hash.c                       | 155 ++++++++++++++++++
 lib/ut/main.c                       |   2 +
 m0t1fs/linux_kernel/file.c          | 182 ++++++++++++---------
 m0t1fs/linux_kernel/file_internal.h |   8 +-
 m0t1fs/linux_kernel/ut/file.c       |  25 +--
 mero/magic.h                        |   8 +
 11 files changed, 865 insertions(+), 92 deletions(-)
 create mode 100644 lib/hash.c
 create mode 100644 lib/hash.h
 create mode 100644 lib/ut/hash.c

diff --git a/lib/Kbuild.sub b/lib/Kbuild.sub
index cc26f4e..1a2b533 100644
--- a/lib/Kbuild.sub
+++ b/lib/Kbuild.sub
@@ -30,7 +30,8 @@ m0mero_objects += lib/assert.o \
                   lib/uuid.o \
                   lib/vec.o \
                   lib/vec.o \
-                  lib/vec_xc.o
+                  lib/vec_xc.o \
+		  lib/hash.o
 
 m0mero_objects += lib/linux_kernel/finject_init.o \
                   lib/linux_kernel/kassert.o \
diff --git a/lib/Makefile.sub b/lib/Makefile.sub
index 0bbf9a4..03a13a1 100644
--- a/lib/Makefile.sub
+++ b/lib/Makefile.sub
@@ -41,6 +41,7 @@ nobase_mero_include_HEADERS += lib/arith.h \
                                lib/uuid.h \
                                lib/vec.h \
                                lib/vec_xc.h \
+			       lib/hash.h \
                                lib/user_space/getopts.h \
                                lib/user_space/misc.h \
                                lib/user_space/mutex.h \
@@ -90,6 +91,7 @@ mero_libmero_la_SOURCES += lib/assert.c \
                            lib/uuid.c \
                            lib/vec.c \
                            lib/vec_xc.c \
+			   lib/hash.c \
                            lib/user_space/finject_init.c \
                            lib/user_space/memory.c \
                            lib/user_space/processor.c \
diff --git a/lib/hash.c b/lib/hash.c
new file mode 100644
index 0000000..0531ac1
--- /dev/null
+++ b/lib/hash.c
@@ -0,0 +1,256 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Anand Vidwana <anand_vidwansa@xyratex.com>
+ * Original creation date: 05/21/2013
+ */
+
+/**
+ * @addtogroup hash
+ * @{
+ */
+
+#include "lib/bob.h"	/* m0_bob_type */
+#include "lib/hash.h"   /* m0_hashlist */
+#include "lib/errno.h"  /* Include appropriate errno.h header. */
+#include "lib/arith.h"	/* min64u() */
+#include "lib/memory.h" /* M0_ALLOC_ARR() */
+
+static const struct m0_bob_type hashlist_bobtype;
+M0_BOB_DEFINE(static, &hashlist_bobtype, m0_hashlist);
+
+static const struct m0_bob_type hashlist_bobtype = {
+	.bt_name         = "hashlist",
+	.bt_magix_offset = offsetof(struct m0_hashlist, hl_magic),
+	.bt_magix        = M0_LIB_HASHLIST_MAGIC,
+	.bt_check        = NULL,
+};
+
+static bool hashlist_invariant(const struct m0_hashlist *hlist);
+
+M0_INTERNAL int m0_hashbucket_alloc_init(struct m0_hashlist *hlist,
+				         uint64_t            bucket_id)
+{
+	M0_PRE(hlist != NULL);
+	M0_PRE(hlist->hl_buckets != NULL);
+	M0_PRE(hlist->hl_buckets[bucket_id] == NULL);
+
+	M0_ALLOC_PTR(hlist->hl_buckets[bucket_id]);
+	if (hlist->hl_buckets[bucket_id] == NULL)
+		return -ENOMEM;
+
+	hlist->hl_buckets[bucket_id]->hb_bucket_id = bucket_id;
+	m0_tlist_init(hlist->hl_tldescr,
+		      &hlist->hl_buckets[bucket_id]->hb_objects);
+	hlist->hl_buckets[bucket_id]->hb_hlist = hlist;
+	return 0;
+}
+
+M0_INTERNAL void m0_hashbucket_dealloc_fini(struct m0_hashbucket *bucket)
+{
+	M0_PRE(bucket != NULL);
+	M0_PRE(bucket->hb_hlist != NULL);
+
+	bucket->hb_hlist->hl_buckets[bucket->hb_bucket_id] = NULL;
+	m0_tlist_fini(bucket->hb_hlist->hl_tldescr, &bucket->hb_objects);
+	bucket->hb_hlist = NULL;
+	m0_free(bucket);
+}
+
+static uint64_t hashlist_key_get(const struct m0_hashlist *hlist,
+				 const void               *obj)
+{
+	return *(uint64_t *)(obj + hlist->hl_key_offset);
+}
+
+static bool hashlist_invariant(const struct m0_hashlist *hlist)
+{
+	return
+		m0_hashlist_bob_check(hlist) &&
+		hlist->hl_bucket_nr >  0 &&
+		hlist->hl_hash_func != NULL &&
+		hlist->hl_buckets   != NULL &&
+		hlist->hl_tldescr   != NULL;
+}
+
+M0_INTERNAL int m0_hashlist_init(struct m0_hashlist       *hlist,
+		   		  uint64_t (*hfunc)
+				 (const struct m0_hashlist *hlist,
+				  uint64_t                  key),
+				 uint64_t                  bucket_nr,
+				 size_t                    key_offset,
+				 const struct m0_tl_descr *descr)
+{
+	M0_PRE(hlist != NULL);
+	M0_PRE(hfunc != NULL);
+	M0_PRE(bucket_nr > 0);
+	M0_PRE(descr != NULL);
+
+	m0_hashlist_bob_init(hlist);
+
+	/*
+	 * Number of buckets is determined based on minimum of
+	 * - number of objects to be stored.
+	 * - max number of buckets that can fit into M0_0VEC_ALIGN (4K)
+	 *   segment.
+	 * This helps in keeping buckets localized in one page while operating
+	 * in linux kernel.
+	 */
+	hlist->hl_key_offset = key_offset;
+	hlist->hl_hash_func  = hfunc;
+	hlist->hl_tldescr    = descr;
+	hlist->hl_bucket_nr  = min64u(bucket_nr, M0_0VEC_ALIGN /
+				      sizeof(struct m0_hashbucket *));
+	M0_ALLOC_ARR(hlist->hl_buckets, hlist->hl_bucket_nr);
+	if (hlist->hl_buckets == NULL)
+		return -ENOMEM;
+
+	M0_POST(hashlist_invariant(hlist));
+	return 0;
+}
+
+M0_INTERNAL int m0_hashlist_add(struct m0_hashlist *hlist, void *obj)
+{
+	int      rc;
+	uint64_t bucket_id;
+
+	M0_PRE(hashlist_invariant(hlist));
+	M0_PRE(obj != NULL);
+
+	bucket_id = hlist->hl_hash_func(hlist, hashlist_key_get(hlist, obj));
+
+	/*
+	 * Allocates and initializes the bucket if it is not
+	 * initialized already.
+	 */
+	if (hlist->hl_buckets[bucket_id] == NULL) {
+		rc = m0_hashbucket_alloc_init(hlist, bucket_id);
+		if (rc != 0)
+			return rc;
+	}
+	m0_tlist_add(hlist->hl_tldescr,
+		     &hlist->hl_buckets[bucket_id]->hb_objects, obj);
+	M0_POST(hashlist_invariant(hlist));
+	M0_POST(m0_tlink_is_in(hlist->hl_tldescr, obj));
+
+	return 0;
+}
+
+M0_INTERNAL void m0_hashlist_del(struct m0_hashlist *hlist, void *obj)
+{
+	uint64_t bucket_id;
+
+	M0_PRE(hashlist_invariant(hlist));
+	M0_PRE(obj != NULL);
+
+	bucket_id = hlist->hl_hash_func(hlist, hashlist_key_get(hlist, obj));
+
+	if (hlist->hl_buckets[bucket_id] == NULL)
+		return;
+	m0_tlist_del(hlist->hl_tldescr, obj);
+
+	/* Finalizes and deallocates the bucket if it is empty. */
+	if (m0_tlist_is_empty(hlist->hl_tldescr,
+			      &hlist->hl_buckets[bucket_id]->hb_objects))
+		m0_hashbucket_dealloc_fini(hlist->hl_buckets[bucket_id]);
+
+	M0_POST(hashlist_invariant(hlist));
+	M0_POST(!m0_tlink_is_in(hlist->hl_tldescr, obj));
+}
+
+M0_INTERNAL void *m0_hashlist_lookup(const struct m0_hashlist *hlist,
+				     uint64_t                  key)
+{
+	void                 *scan;
+	uint64_t              bucket_id;
+	struct m0_hashbucket *bucket;
+
+	M0_PRE(hashlist_invariant(hlist));
+
+	bucket_id = hlist->hl_hash_func(hlist, key);
+	bucket    = hlist->hl_buckets[bucket_id];
+	if (bucket == NULL)
+		return NULL;
+
+	m0_tlist_for (hlist->hl_tldescr, &bucket->hb_objects, scan) {
+		if (hashlist_key_get(hlist, scan) == key)
+			break;
+	} m0_tlist_endfor;
+
+	return scan;
+}
+
+M0_INTERNAL void m0_hashlist_fini(struct m0_hashlist *hlist)
+{
+	uint64_t              nr;
+	struct m0_hashbucket *bucket;
+
+	M0_PRE(hashlist_invariant(hlist));
+
+	for (nr = 0; nr < hlist->hl_bucket_nr; ++nr) {
+		bucket = hlist->hl_buckets[nr];
+		if (bucket != NULL)
+			m0_hashbucket_dealloc_fini(bucket);
+	}
+	m0_free(hlist->hl_buckets);
+	m0_hashlist_bob_fini(hlist);
+	hlist->hl_buckets   = NULL;
+	hlist->hl_bucket_nr = 0;
+	hlist->hl_tldescr   = NULL;
+	hlist->hl_hash_func = NULL;
+}
+
+M0_INTERNAL bool m0_hashlist_is_empty(const struct m0_hashlist *hlist)
+{
+	uint64_t nr;
+
+	M0_PRE(hashlist_invariant(hlist));
+
+	for (nr = 0; nr < hlist->hl_bucket_nr; ++nr) {
+		if (hlist->hl_buckets[nr] != NULL &&
+		    !m0_tlist_is_empty(hlist->hl_tldescr,
+			    &hlist->hl_buckets[nr]->hb_objects))
+			break;
+	}
+	return nr == hlist->hl_bucket_nr;
+}
+
+M0_INTERNAL uint64_t m0_hashlist_length(const struct m0_hashlist *hlist)
+{
+	uint64_t nr;
+	uint64_t len = 0;
+
+	M0_PRE(hashlist_invariant(hlist));
+
+	for (nr = 0; nr < hlist->hl_bucket_nr; ++nr) {
+		if (hlist->hl_buckets[nr] != NULL)
+			len += m0_tlist_length(hlist->hl_tldescr,
+					&hlist->hl_buckets[nr]->hb_objects);
+	}
+	return len;
+}
+
+/** @} end of hash */
+
+/*
+ *  Local variables:
+ *  c-indentation-style: "K&R"
+ *  c-basic-offset: 8
+ *  tab-width: 8
+ *  fill-column: 80
+ *  scroll-step: 1
+ *  End:
+ */
diff --git a/lib/hash.h b/lib/hash.h
new file mode 100644
index 0000000..8c07165
--- /dev/null
+++ b/lib/hash.h
@@ -0,0 +1,313 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Anand Vidwana <anand_vidwansa@xyratex.com>
+ * Original creation date: 05/21/2013
+ */
+
+#pragma once
+
+#ifndef __MERO_LIB_HASH_H__
+#define __MERO_LIB_HASH_H__
+
+#include "lib/types.h"
+#include "lib/tlist.h"
+
+/**
+ * @defgroup hash Hashed lists.
+ *
+ * Hashed list module provides a simple hash implementation built over
+ * top of typed lists. @see tlist.
+ *
+ * Often, lookup for objects stored in simple tlists prove to be expensive
+ * owing to lack of any efficient arrangement of objects in tlist.
+ * Hash list provides a simple way to distribute objects in hash using a
+ * key-value mechanism, which enhances lookup time of objects.
+ *
+ * Hash list contains array of hash buckets which contain bucket id
+ * and a tlist of objects.
+ * Every object is supposed to provide a key, based on which its location
+ * in hash list is decided. The caller is supposed to provide a hash function
+ * which is used to calculate bucket id in which object will lie.
+ *
+ * Similar to tlists, hash list is a simple algorithmic module. It does not
+ * deal with liveness or concurrency and other such issues. Caller is supposed
+ * to control liveness and use proper synchronization primitives to handle
+ * concurrency.
+ *
+ * A good hash function can ensure good distribution of objects
+ * throughout the hash list, thus owing to efficient operation of hash.
+ *
+ * Consider a scenario with struct bar containing multiple objects of
+ * struct foo.
+ *
+ * @code
+ *
+ * struct bar {
+ *         ...
+ *         // Hash list used to store multiple foo-s.
+ *         struct m0_hashlist b_foohash;
+ *         ...
+ * };
+ *
+ * struct foo {
+ *         // Magic to validate sanity of object.
+ *         uint64_t        f_magic;
+ *
+ *         // Key used to find out appropriate bucket.
+ *         uint64_t        f_hash_key;
+ *
+ *         ...
+ *         // linkage into list of foo-s hanging off bar::b_foohash.
+ *         struct m0_tlink f_link;
+ * };
+ *
+ * - Now, define the tlist descriptor.
+ *
+ *   M0_TL_DESCR_DEFINE(foohash, "Hash of foo-s", static, struct foo,
+ *                      f_link, f_magic, magix, M0_LIB_HASHBUCKET_MAGIC);
+ *
+ * - Define a hash function which will take care of distributing objects
+ *   throughtout the hash buckets.
+ *
+ *   uint64_t hash_func(uint64_t key)
+ *   {
+ *           return key % bucket_nr;
+ *   }
+ *
+ * - Now initialize the m0_hashlist like
+ *
+ *   m0_hashlist_init(&bar->b_foohash, hash_func, bucket_nr,
+ *                    offsetof(struct foo, f_key, &foohash_tl);
+ *
+ * Now, foo objects can be added/removed to/from bar::b_foohash using 
+ * APIs like m0_hashlist_add() and m0_hashlist_del().
+ *
+ * Also, lookup through hash can be done using API like m0_hashlist_lookup().
+ *
+ * @endcode
+ *
+ * Macros like m0_hashbucket_forall() and m0_hashlist_forall() can be used
+ * to evaluate a certain expression for all objects in hashbucket/hashlist.
+ *
+ * m0_hashlist_for() and m0_hashlist_endfor() can be used to have a loop
+ * over all objects in hashlist.
+ *
+ * @{
+ */
+
+/**
+ * Represents a simple hash bucket.
+ */
+struct m0_hashbucket {
+	/**
+	 * Bucket id. It is calculated by supplying key (provided by user)
+	 * to m0_hashlist::hl_hash_func().
+	 * Typically for struct m0_hashlist, m0_fid::f_key is used as hash key.
+	 * During initialization, this key is set to an invalid value.
+	 * As and when elements are added to hash, this key is updated.
+	 */
+	uint64_t            hb_bucket_id;
+
+	/**
+	 * List of target_ioreq objects which share
+	 * target_ioreq::ti_fid::f_key.
+	 * A single m0_tl_descr object would be used by all
+	 * m0_hashbucket::hb_objects lists in a single m0_hash object.
+	 */
+	struct m0_tl        hb_objects;
+
+	/** Backlink to parent m0_hashlist structure. */
+	struct m0_hashlist *hb_hlist;
+};
+
+/**
+ * Allocates and initializes m0_hashbucket structure.
+ * @pre   hlist != NULL && hlist->hl_buckets != NULL &&
+ *        hlist->hl_buckets[bucket_id] == NULL.
+ * @post  hlist->hl_buckets[bucket_id] != NULL.
+ */
+M0_INTERNAL int hashbucket_alloc_init(struct m0_hashlist *hlist,
+				      uint64_t            bucket_id);
+
+/**
+ * Finalizes and deallocates a m0_hashbucket structure.
+ * @pre bucket != NULL.
+ */
+M0_INTERNAL void hashbucket_dealloc_fini(struct m0_hashbucket *bucket);
+
+struct m0_hashlist;
+
+/**
+ * A simple hash data structure which helps to avoid the linear search
+ * of whole list of objects.
+ * However considering that linux kernel can not guarantee more than one
+ * contiguous pages during memory allocation, the upper threshold of
+ * number of buckets is limited by page_size / sizeof(m0_hashbucket *).
+ */
+struct m0_hashlist {
+	/** Magic value. Holds M0_LIB_HASHLIST_MAGIC.  */
+	uint64_t                   hl_magic;
+
+	/** Number of hash buckets used. */
+	uint64_t                   hl_bucket_nr;
+
+	/** Offset of key field in ambient structure. */
+	size_t                     hl_key_offset;
+
+	/**
+	 * Array of hash buckets. Hash buckets are supposed to be
+	 * indexed in increasing order of hash key.
+	 * Ergo, the very first bucket will have bucket id 0, the next one
+	 * will have bucket id 1 and so on.
+	 */
+	struct m0_hashbucket     **hl_buckets;
+
+	/** tlist descriptor used for m0_hashbucket::hb_objects tlist. */
+	const struct m0_tl_descr  *hl_tldescr;
+
+	/** Hash function. Has to be provided by user. */
+	uint64_t (*hl_hash_func)  (const struct m0_hashlist *hlist,
+			           uint64_t               key);
+};
+
+/**
+ * Initializes a hashlist.
+ * @param bucket_nr Number of buckets that will be housed in this m0_hashlist.
+ *        Max number of buckets has upper threshold of 512 buckets.
+ * @param key_offset Offset of key field in ambient object.
+ *        This key is used in operations like add, del, lookup &c.
+ * @param hfunc Hash function used to calculate bucket id.
+ * @param descr tlist descriptor used for tlist in hash buckets.
+ * @pre   hlist != NULL &&
+ *        hfunc != NULL &&
+ *        bucket_nr > 0    &&
+ *        descr != NULL.
+ * @post hlist->hl_magic == M0_LIB_HASHLIST_MAGIC &&
+ *       hlist->hl_bucket_nr > 0 &&
+ *       hlist->hl_hash_func == hfunc &&
+ *       hlist->hl_tldescr == descr.
+ */
+M0_INTERNAL int m0_hashlist_init(struct m0_hashlist *hlist,
+				 uint64_t (*hfunc)
+				 (const struct m0_hashlist *hlist,
+				  uint64_t                  key),
+				 uint64_t                   bucket_nr,
+				 size_t                     key_offset,
+				 const struct m0_tl_descr  *descr);
+
+/**
+ * Finalizes a struct m0_hashlist.
+ * @pre  hlist != NULL &&
+ *       hlist->hl_magic == M0_LIB_HASHLIST_MAGIC &&
+ *       hlist->hl_buckets != NULL.
+ * @post hlist->buckets == NULL &&
+ *       hlist->bucket_nr == 0.
+ */
+M0_INTERNAL void m0_hashlist_fini(struct m0_hashlist *hlist);
+
+/**
+ * Adds an object to hash list.
+ * The key must be set in object at specified location in order to
+ * identify the bucket.
+ * @pre  hlist != NULL &&
+ *       obj   != NULL &&
+ *       hlist->hl_buckets != NULL.
+ */
+M0_INTERNAL int m0_hashlist_add(struct m0_hashlist *hlist, void *obj);
+
+/**
+ * Removes an object from hash list.
+ * The key must be set in object at specified location in order to
+ * identify the bucket.
+ * @pre hlist != NULL &&
+ *      obj   != NULL &&
+ *      hlist->hl_buckets != NULL.
+ */
+M0_INTERNAL void m0_hashlist_del(struct m0_hashlist *hlist, void *obj);
+
+/**
+ * Looks up if given object is present in hash list based on input key.
+ * Returns ambient object on successful lookup, returns NULL otherwise.
+ * @pre hlist != NULL &&
+ *      hlist->hl_buckets != NULL.
+ */
+M0_INTERNAL void *m0_hashlist_lookup(const struct m0_hashlist *hlist,
+				     uint64_t		       key);
+
+/** Returns if m0_hashlist contains any objects. */
+M0_INTERNAL bool m0_hashlist_is_empty(const struct m0_hashlist *hlist);
+
+/** Returns number of objects stored within m0_hashlist. */
+M0_INTERNAL uint64_t m0_hashlist_length(const struct m0_hashlist *hlist);
+
+/**
+ * Iterates over the members of a m0_hashbucket and performs given operation
+ * for all of them.
+ */
+#define m0_hashbucket_forall(name, var, bucket, ...)			    \
+({									    \
+	m0_tl_forall(name, var, &bucket->hb_objects, ({ __VA_ARGS__ ; }));  \
+})
+
+/**
+ * Iterates over all hashbuckets and invokes m0_hashbucket_forall() for all
+ * buckets.
+ */
+#define m0_hashlist_forall(name, var, hlist, ...)			    \
+({									    \
+	uint64_t cnt;							    \
+	typeof (hlist) hl = (hlist);				 	    \
+ 									    \
+ 	for (cnt = 0; cnt < hl->hl_bucket_nr; ++cnt)	{		    \
+		if (hl->hl_buckets[cnt] != NULL && 			    \
+		    (!(m0_hashbucket_forall(name, var, hl->hl_buckets[cnt], \
+					 ({ __VA_ARGS__ ; })))))	    \
+ 			break;					 	    \
+ 	}								    \
+	cnt == hl->hl_bucket_nr;					    \
+})
+
+/**
+ * An open ended version of loop over all objects in all hash buckets
+ * in a m0_hashlist.
+ * This loop has to be closed using hashlist_endfor() macro.
+ */
+#define m0_hashlist_for(name, var, hlist)				    \
+({									    \
+	uint64_t __cnt;							    \
+	typeof (hlist) hl = (hlist);					    \
+									    \
+ 	for (__cnt = 0; __cnt < hl->hl_bucket_nr; ++__cnt) {		    \
+		if (hl->hl_buckets[__cnt] != NULL) {			    \
+			m0_tl_for(name, &hl->hl_buckets[__cnt]->hb_objects, \
+				  var)
+
+#define m0_hashlist_endfor m0_tl_endfor; } }; })
+
+/** @} end of hash */
+
+#endif /* __MERO_LIB_HASH_H__ */
+
+/*
+ *  Local variables:
+ *  c-indentation-style: "K&R"
+ *  c-basic-offset: 8
+ *  tab-width: 8
+ *  fill-column: 80
+ *  scroll-step: 1
+ *  End:
+ */
diff --git a/lib/ut/Makefile.sub b/lib/ut/Makefile.sub
index 8da057f..5e99a0e 100644
--- a/lib/ut/Makefile.sub
+++ b/lib/ut/Makefile.sub
@@ -24,4 +24,5 @@ ut_libmero_ut_la_SOURCES += lib/ut/main.c \
                                lib/ut/trace.c \
                                lib/ut/uuid.c \
                                lib/ut/vec.c \
-                               lib/ut/zerovec.c
+                               lib/ut/zerovec.c \
+			       lib/ut/hash.c
diff --git a/lib/ut/hash.c b/lib/ut/hash.c
new file mode 100644
index 0000000..3edf35c
--- /dev/null
+++ b/lib/ut/hash.c
@@ -0,0 +1,155 @@
+/* -*- C -*- */
+/*
+ * COPYRIGHT 2013 XYRATEX TECHNOLOGY LIMITED
+ *
+ * THIS DRAWING/DOCUMENT, ITS SPECIFICATIONS, AND THE DATA CONTAINED
+ * HEREIN, ARE THE EXCLUSIVE PROPERTY OF XYRATEX TECHNOLOGY
+ * LIMITED, ISSUED IN STRICT CONFIDENCE AND SHALL NOT, WITHOUT
+ * THE PRIOR WRITTEN PERMISSION OF XYRATEX TECHNOLOGY LIMITED,
+ * BE REPRODUCED, COPIED, OR DISCLOSED TO A THIRD PARTY, OR
+ * USED FOR ANY PURPOSE WHATSOEVER, OR STORED IN A RETRIEVAL SYSTEM
+ * EXCEPT AS ALLOWED BY THE TERMS OF XYRATEX LICENSES AND AGREEMENTS.
+ *
+ * YOU SHOULD HAVE RECEIVED A COPY OF XYRATEX'S LICENSE ALONG WITH
+ * THIS RELEASE. IF NOT PLEASE CONTACT A XYRATEX REPRESENTATIVE
+ * http://www.xyratex.com/contact
+ *
+ * Original author: Anand Vidwana <anand_vidwansa@xyratex.com>
+ * Original creation date: 05/28/2013
+ */
+
+#include "lib/bob.h"	/* m0_bob_type */
+#include "lib/hash.h"   /* m0_hashlist */
+#include "lib/errno.h"  /* Include appropriate errno.h header. */
+#include "ut/ut.h"  	/* M0_UT_ASSERT() */
+
+struct bar {
+	/* Holds BAR_MAGIC. */
+	uint64_t           b_magic;
+	int                b_rc;
+	struct m0_hashlist b_hash;
+};
+
+struct foo {
+	/* Holds FOO_MAGIC. */
+	uint64_t        f_magic;
+	uint64_t        f_hkey;
+	int             f_subject;
+	struct m0_tlink f_link;
+};
+
+enum {
+	BUCKET_NR = 8,
+	FOO_NR    = 19,
+	BAR_MAGIC = 0xa817115ad15ababaULL,
+	FOO_MAGIC = 0x911ea3a7096a96e5ULL,
+};
+
+static uint64_t hash_func(const struct m0_hashlist *hlist, uint64_t key)
+{
+	return key % hlist->hl_bucket_nr;
+}
+
+M0_TL_DESCR_DEFINE(foohash, "Hash of foos", static, struct foo,
+		   f_link, f_magic, FOO_MAGIC, BAR_MAGIC);
+M0_TL_DEFINE(foohash, static, struct foo);
+
+static struct foo foos[FOO_NR];
+static struct bar thebar;
+
+void test_hash(void)
+{
+	int                   i;
+	int                   rc;
+	struct foo           *f;
+	struct m0_hashbucket *hb;
+
+	for (i = 0; i < FOO_NR; ++i) {
+		foos[i].f_magic = FOO_MAGIC;
+		foos[i].f_hkey  = i;
+		foos[i].f_subject = 0;
+		m0_tlink_init(&foohash_tl, &foos[i]);
+	}
+
+	thebar.b_magic = BAR_MAGIC;
+	thebar.b_rc    = 0;
+	rc = m0_hashlist_init(&thebar.b_hash, hash_func, BUCKET_NR,
+			      offsetof(struct foo, f_hkey), &foohash_tl);
+	M0_UT_ASSERT(rc == 0);
+	M0_UT_ASSERT(thebar.b_hash.hl_magic == M0_LIB_HASHLIST_MAGIC);
+	M0_UT_ASSERT(thebar.b_hash.hl_bucket_nr == BUCKET_NR);
+	M0_UT_ASSERT(thebar.b_hash.hl_buckets != NULL);
+	M0_UT_ASSERT(thebar.b_hash.hl_hash_func == hash_func);
+
+	rc = m0_hashlist_add(&thebar.b_hash, &foos[0]);
+	M0_UT_ASSERT(rc == 0);
+	M0_UT_ASSERT(m0_hashlist_length(&thebar.b_hash) == 1);
+	M0_UT_ASSERT(!m0_hashlist_is_empty(&thebar.b_hash));
+	M0_UT_ASSERT(m0_hashlist_lookup(&thebar.b_hash, 0) == &foos[0]);
+	M0_UT_ASSERT(m0_hashlist_lookup(&thebar.b_hash, 1) == NULL);
+
+	M0_UT_ASSERT(thebar.b_hash.hl_buckets[0] != NULL);
+	M0_UT_ASSERT(thebar.b_hash.hl_buckets[0]->hb_bucket_id == 0);
+	M0_UT_ASSERT(!m0_tlist_is_empty(&foohash_tl, &thebar.b_hash.
+				        hl_buckets[0]->hb_objects));
+	M0_UT_ASSERT(thebar.b_hash.hl_buckets[0]->hb_hlist == &thebar.b_hash);
+
+	m0_hashlist_del(&thebar.b_hash, &foos[0]);
+	M0_UT_ASSERT(m0_hashlist_is_empty(&thebar.b_hash));
+	M0_UT_ASSERT(m0_hashlist_length(&thebar.b_hash) == 0);
+	M0_UT_ASSERT(m0_hashlist_lookup(&thebar.b_hash, foos[0].f_hkey) == NULL);
+	M0_UT_ASSERT(thebar.b_hash.hl_buckets[0] == NULL);
+
+	for (i = 0; i < FOO_NR; ++i) {
+		rc = m0_hashlist_add(&thebar.b_hash, &foos[i]);
+		M0_UT_ASSERT(rc == 0);
+		M0_UT_ASSERT(m0_tlink_is_in(&foohash_tl, &foos[i]));
+	}
+	M0_UT_ASSERT(m0_hashlist_length(&thebar.b_hash) == FOO_NR);
+
+	for (i = 0; i < BUCKET_NR; ++i) {
+		hb = thebar.b_hash.hl_buckets[i];
+		M0_UT_ASSERT(hb != NULL);
+		M0_UT_ASSERT(hb->hb_bucket_id == i);
+		M0_UT_ASSERT(!m0_tlist_is_empty(&foohash_tl, &hb->hb_objects));
+		M0_UT_ASSERT(m0_hashbucket_forall(foohash, f, hb,
+			     f->f_hkey % BUCKET_NR == hb->hb_bucket_id));
+	}
+	M0_UT_ASSERT(m0_hashlist_forall(foohash, f, &thebar.b_hash,
+		     f->f_subject == 0));
+
+	m0_hashlist_for(foohash, f, &thebar.b_hash) {
+		f->f_subject = 1;
+	} m0_hashlist_endfor;
+
+	M0_UT_ASSERT(m0_hashlist_forall(foohash, f, &thebar.b_hash,
+		     f->f_subject == 1));
+
+	for (i = 0; i < FOO_NR; ++i) {
+		m0_hashlist_del(&thebar.b_hash, &foos[i]);
+		M0_UT_ASSERT(m0_hashlist_length(&thebar.b_hash) ==
+			     FOO_NR - (i + 1));
+		M0_UT_ASSERT(m0_hashlist_lookup(&thebar.b_hash,
+					foos[i].f_hkey) == NULL);
+		M0_UT_ASSERT(!m0_tlink_is_in(&foohash_tl, &foos[i]));
+	}
+	M0_UT_ASSERT(m0_hashlist_length(&thebar.b_hash) == 0);
+	M0_UT_ASSERT(m0_hashlist_is_empty(&thebar.b_hash));
+
+	m0_hashlist_fini(&thebar.b_hash);
+	M0_UT_ASSERT(thebar.b_hash.hl_buckets   == NULL);
+	M0_UT_ASSERT(thebar.b_hash.hl_bucket_nr == 0);
+	M0_UT_ASSERT(thebar.b_hash.hl_magic     == 0);
+	M0_UT_ASSERT(thebar.b_hash.hl_tldescr   == NULL);
+	M0_UT_ASSERT(thebar.b_hash.hl_hash_func == NULL);
+}
+
+/*
+ *  Local variables:
+ *  c-indentation-style: "K&R"
+ *  c-basic-offset: 8
+ *  tab-width: 8
+ *  fill-column: 80
+ *  scroll-step: 1
+ *  End:
+ */
diff --git a/lib/ut/main.c b/lib/ut/main.c
index 80af21b..a3caff7 100644
--- a/lib/ut/main.c
+++ b/lib/ut/main.c
@@ -48,6 +48,7 @@ extern void test_trace(void);
 extern void test_vec(void);
 extern void test_zerovec(void);
 extern void test_locality(void);
+extern void test_hash(void);
 
 const struct m0_test_suite libm0_ut = {
 	.ts_name = "libm0-ut",
@@ -83,6 +84,7 @@ const struct m0_test_suite libm0_ut = {
 		{ "uuid",             m0_test_lib_uuid   },
 		{ "vec",              test_vec           },
 		{ "zerovec",          test_zerovec       },
+		{ "hash",	      test_hash          },
 		{ NULL,               NULL               }
 	}
 };
diff --git a/m0t1fs/linux_kernel/file.c b/m0t1fs/linux_kernel/file.c
index 22bf3c1..79cf2c5 100644
--- a/m0t1fs/linux_kernel/file.c
+++ b/m0t1fs/linux_kernel/file.c
@@ -40,6 +40,8 @@
 #include "mero/magic.h"  /* M0_T1FS_IOREQ_MAGIC */
 #include "m0t1fs/linux_kernel/m0t1fs.h" /* m0t1fs_sb */
 #include "rm/file.h"
+#include "lib/hash.h"	    /* m0_hashlist */
+
 #include "m0t1fs/linux_kernel/file_internal.h"
 
 /**
@@ -310,20 +312,15 @@ M0_INTERNAL bool m0t1fs_inode_bob_check(struct m0t1fs_inode *bob);
 M0_TL_DECLARE(rpcbulk, M0_INTERNAL, struct m0_rpc_bulk_buf);
 M0_TL_DESCR_DECLARE(rpcbulk, M0_EXTERN);
 
-M0_TL_DESCR_DEFINE(tioreqs, "List of target_ioreq objects", static,
-		   struct target_ioreq, ti_link, ti_magic,
-		   M0_T1FS_TIOREQ_MAGIC, M0_T1FS_NWREQ_MAGIC);
-
 M0_TL_DESCR_DEFINE(iofops, "List of IO fops", static,
 		   struct io_req_fop, irf_link, irf_magic,
 		   M0_T1FS_IOFOP_MAGIC, M0_T1FS_TIOREQ_MAGIC);
 
-M0_TL_DEFINE(tioreqs, static, struct target_ioreq);
 M0_TL_DEFINE(iofops,  static, struct io_req_fop);
 M0_TL_DESCR_DECLARE(rpcbulk, M0_EXTERN);
 M0_TL_DECLARE(rpcbulk, M0_INTERNAL, struct m0_rpc_bulk_buf);
 
-static struct m0_bob_type tioreq_bobtype;
+static const struct m0_bob_type tioreq_bobtype;
 static struct m0_bob_type iofop_bobtype;
 static const struct m0_bob_type ioreq_bobtype;
 static const struct m0_bob_type pgiomap_bobtype;
@@ -365,6 +362,13 @@ static const struct m0_bob_type dtbuf_bobtype = {
 	.bt_check	 = NULL,
 };
 
+static const struct m0_bob_type tioreq_bobtype = {
+	.bt_name         = "target_ioreq",
+	.bt_magix_offset = offsetof(struct target_ioreq, ti_magic),
+	.bt_magix        = M0_T1FS_TIOREQ_MAGIC,
+	.bt_check        = NULL,
+};
+
 /*
  * These are used as macros since they are used as lvalues which is
  * not possible by using static inline functions.
@@ -476,6 +480,12 @@ static inline uint64_t target_offset(uint64_t		       frame,
 	       (gob_offset % layout_unit_size(play));
 }
 
+M0_TL_DESCR_DEFINE(tioreq_hash, "Hash of target_ioreq objects", static,
+		   struct target_ioreq, ti_link, ti_magic, M0_T1FS_TIOREQ_MAGIC,
+		   M0_LIB_HASHBUCKET_MAGIC);
+
+M0_TL_DEFINE(tioreq_hash, static, struct target_ioreq);
+
 /* Finds out pargrp_iomap::pi_grpid from target index. */
 static inline uint64_t pargrp_id_find(m0_bindex_t index,
 		                      uint64_t    unit_size)
@@ -642,7 +652,6 @@ static void parity_page_offset_get(struct pargrp_iomap *map,
 /* Invoked during m0t1fs mount. */
 M0_INTERNAL void io_bob_tlists_init(void)
 {
-	m0_bob_type_tlist_init(&tioreq_bobtype, &tioreqs_tl);
 	M0_ASSERT(tioreq_bobtype.bt_magix == M0_T1FS_TIOREQ_MAGIC);
 	m0_bob_type_tlist_init(&iofop_bobtype, &iofops_tl);
 	M0_ASSERT(iofop_bobtype.bt_magix == M0_T1FS_IOFOP_MAGIC);
@@ -891,10 +900,10 @@ static bool io_request_invariant(const struct io_request *req)
 	       m0_fid_is_valid(file_to_fid(req->ir_file)) &&
 
 	       ergo(ioreq_sm_state(req) == IRS_READING,
-		    !tioreqs_tlist_is_empty(&req->ir_nwxfer.nxr_tioreqs)) &&
+		    !m0_hashlist_is_empty(&req->ir_nwxfer.nxr_tioreqs_hash)) &&
 
 	       ergo(ioreq_sm_state(req) == IRS_WRITING,
-		    !tioreqs_tlist_is_empty(&req->ir_nwxfer.nxr_tioreqs)) &&
+		    !m0_hashlist_is_empty(&req->ir_nwxfer.nxr_tioreqs_hash)) &&
 
 	       ergo(ioreq_sm_state(req) == IRS_WRITE_COMPLETE,
 		    req->ir_nwxfer.nxr_iofop_nr == 0) &&
@@ -922,13 +931,13 @@ static bool nw_xfer_request_invariant(const struct nw_xfer_request *xfer)
 		    (xfer->nxr_iofop_nr == 0)) &&
 
 	       ergo(xfer->nxr_state == NXS_INFLIGHT,
-		    !tioreqs_tlist_is_empty(&xfer->nxr_tioreqs)) &&
+		    !m0_hashlist_is_empty(&xfer->nxr_tioreqs_hash)) &&
 
 	       ergo(xfer->nxr_state == NXS_COMPLETE,
 		    xfer->nxr_iofop_nr == 0) &&
 
-	       m0_tl_forall(tioreqs, tioreq, &xfer->nxr_tioreqs,
-			    target_ioreq_invariant(tioreq));
+	       m0_hashlist_forall(tioreq_hash, tioreq, &xfer->nxr_tioreqs_hash,
+			          target_ioreq_invariant(tioreq));
 }
 
 static bool data_buf_invariant(const struct data_buf *db)
@@ -1011,20 +1020,35 @@ static bool pargrp_iomap_invariant_nr(const struct io_request *req)
 			 pargrp_iomap_invariant(req->ir_iomaps[i]));
 }
 
+static uint64_t tioreqs_hash_func(const struct m0_hashlist *hlist, uint64_t key)
+{
+	return key % hlist->hl_bucket_nr;
+}
+
 static void nw_xfer_request_init(struct nw_xfer_request *xfer)
 {
+	struct io_request        *req;
+	struct m0_pdclust_layout *play;
+
 	M0_ENTRY("nw_xfer_request : %p", xfer);
 	M0_PRE(xfer != NULL);
 
+	req = bob_of(xfer, struct io_request, ir_nwxfer, &ioreq_bobtype);
 	nw_xfer_request_bob_init(xfer);
 	xfer->nxr_rc	= 0;
 	xfer->nxr_bytes = 0;
 	xfer->nxr_iofop_nr = 0;
 	xfer->nxr_state = NXS_INITIALIZED;
 	xfer->nxr_ops	= &xfer_ops;
-	tioreqs_tlist_init(&xfer->nxr_tioreqs);
 
-	M0_POST(nw_xfer_request_invariant(xfer));
+	play = pdlayout_get(req);
+	xfer->nxr_rc = m0_hashlist_init(&xfer->nxr_tioreqs_hash,
+			tioreqs_hash_func, layout_n(play) + 2 * layout_k(play),
+			offsetof(struct target_ioreq, ti_fid) +
+			offsetof(struct m0_fid, f_container),
+			&tioreq_hash_tl);
+
+	M0_POST_EX(nw_xfer_request_invariant(xfer));
 	M0_LEAVE();
 }
 
@@ -1032,11 +1056,11 @@ static void nw_xfer_request_fini(struct nw_xfer_request *xfer)
 {
 	M0_ENTRY("nw_xfer_request : %p", xfer);
 	M0_PRE(xfer != NULL && xfer->nxr_state == NXS_COMPLETE);
-	M0_PRE(nw_xfer_request_invariant(xfer));
+	M0_PRE_EX(nw_xfer_request_invariant(xfer));
 
 	xfer->nxr_ops = NULL;
 	nw_xfer_request_bob_fini(xfer);
-	tioreqs_tlist_fini(&xfer->nxr_tioreqs);
+	m0_hashlist_fini(&xfer->nxr_tioreqs_hash);
 	M0_LEAVE();
 }
 
@@ -1077,7 +1101,7 @@ static int user_data_copy(struct pargrp_iomap *map,
 	M0_ENTRY("Copy %s user-space, start = %llu, end = %llu",
 		 dir == CD_COPY_FROM_USER ? (char *)"from" : (char *)"to",
 		 start, end);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 	M0_PRE(it != NULL);
 	M0_PRE(M0_IN(dir, (CD_COPY_FROM_USER, CD_COPY_TO_USER)));
 
@@ -1161,7 +1185,7 @@ static int pargrp_iomap_parity_recalc(struct pargrp_iomap *map)
 	struct m0_pdclust_layout *play;
 
 	M0_ENTRY("map = %p", map);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 
 	play = pdlayout_get(map->pi_ioreq);
 	M0_ALLOC_ARR_ADDB(dbufs, layout_n(play), &m0_addb_gmc,
@@ -1251,7 +1275,7 @@ static int ioreq_parity_recalc(struct io_request *req)
 	uint64_t map;
 
 	M0_ENTRY("io_request : %p", req);
-	M0_PRE(io_request_invariant(req));
+	M0_PRE_EX(io_request_invariant(req));
 
 	for (map = 0; map < req->ir_iomap_nr; ++map) {
 		rc = req->ir_iomaps[map]->pi_ops->pi_parity_recalc(req->
@@ -1306,7 +1330,7 @@ static int ioreq_user_data_copy(struct io_request   *req,
 	M0_ENTRY("io_request : %p, %s user-space. filter = 0x%x", req,
 		 dir == CD_COPY_FROM_USER ? (char *)"from" : (char *)"to",
 		 filter);
-	M0_PRE(io_request_invariant(req));
+	M0_PRE_EX(io_request_invariant(req));
 	M0_PRE(dir < CD_NR);
 
 	iov_iter_init(&it, req->ir_iovec, req->ir_ivec.iv_vec.v_nr,
@@ -1316,7 +1340,7 @@ static int ioreq_user_data_copy(struct io_request   *req,
 
 	for (map = 0; map < req->ir_iomap_nr; ++map) {
 
-		M0_ASSERT(pargrp_iomap_invariant(req->ir_iomaps[map]));
+		M0_ASSERT_EX(pargrp_iomap_invariant(req->ir_iomaps[map]));
 
 		count    = 0;
 		grpstart = data_size(play) * req->ir_iomaps[map]->pi_grpid;
@@ -1440,7 +1464,7 @@ static int pargrp_iomap_init(struct pargrp_iomap *map,
 				goto fail;
 		}
 	}
-	M0_POST(pargrp_iomap_invariant(map));
+	M0_POST_EX(pargrp_iomap_invariant(map));
 	M0_RETURN(0);
 
 fail:
@@ -1471,7 +1495,7 @@ static void pargrp_iomap_fini(struct pargrp_iomap *map)
 	struct m0_pdclust_layout *play;
 
 	M0_ENTRY("map %p", map);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 
 	play	     = pdlayout_get(map->pi_ioreq);
 	map->pi_ops  = NULL;
@@ -1520,7 +1544,7 @@ static bool pargrp_iomap_spans_seg(struct pargrp_iomap *map,
 {
 	uint32_t seg;
 
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 
 	for (seg = 0; seg < map->pi_ivec.iv_vec.v_nr; ++seg) {
 		if (index >= INDEX(&map->pi_ivec, seg) &&
@@ -1631,7 +1655,7 @@ static uint64_t pargrp_iomap_fullpages_count(struct pargrp_iomap *map)
 	struct m0_pdclust_layout *play;
 
 	M0_ENTRY("map %p", map);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 
 	play = pdlayout_get(map->pi_ioreq);
 
@@ -1653,7 +1677,7 @@ static uint64_t pargrp_iomap_auxbuf_alloc(struct pargrp_iomap *map,
 					  uint32_t	       col)
 {
 	M0_ENTRY();
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 	M0_PRE(map->pi_rtype == PIR_READOLD);
 
 	map->pi_databufs[row][col]->db_auxbuf.b_addr = (void *)
@@ -1684,7 +1708,7 @@ static int pargrp_iomap_readold_auxbuf_alloc(struct pargrp_iomap *map)
 	struct m0_pdclust_layout *play;
 
 	M0_ENTRY("map %p", map);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 	M0_PRE(map->pi_rtype == PIR_READOLD);
 
 	inode = map->pi_ioreq->ir_file->f_dentry->d_inode;
@@ -1794,7 +1818,7 @@ static int pargrp_iomap_readrest(struct pargrp_iomap *map)
 	struct m0_pdclust_layout *play;
 
 	M0_ENTRY("map %p", map);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 	M0_PRE(map->pi_rtype == PIR_READREST);
 
 	play	 = pdlayout_get(map->pi_ioreq);
@@ -1854,7 +1878,7 @@ static int pargrp_iomap_paritybufs_alloc(struct pargrp_iomap *map)
 	struct m0_pdclust_layout *play;
 
 	M0_ENTRY("map %p", map);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 
 	play = pdlayout_get(map->pi_ioreq);
 	for (row = 0; row < parity_row_nr(play); ++row) {
@@ -2094,7 +2118,7 @@ static int pargrp_iomap_populate(struct pargrp_iomap	  *map,
 	if (map->pi_ioreq->ir_type == IRT_WRITE)
 		rc = pargrp_iomap_paritybufs_alloc(map);
 
-	M0_POST(ergo(rc == 0, pargrp_iomap_invariant(map)));
+	M0_POST_EX(ergo(rc == 0, pargrp_iomap_invariant(map)));
 
 	M0_RETURN(rc);
 }
@@ -2178,7 +2202,7 @@ static int pargrp_iomap_dgmode_process(struct pargrp_iomap *map,
 	struct m0_pdclust_src_addr src;
 	struct m0_pdclust_tgt_addr tgt;
 
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 	M0_ENTRY("grpid = %llu, count = %u\n", map->pi_grpid, count);
 	M0_PRE(tio   != NULL);
 	M0_PRE(index != NULL);
@@ -2296,7 +2320,7 @@ static int pargrp_iomap_dgmode_postprocess(struct pargrp_iomap *map)
 	 */
 	M0_ENTRY("parity group id %llu, state = %d",
 		 map->pi_grpid, map->pi_state);
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 
 	inode = map->pi_ioreq->ir_file->f_dentry->d_inode;
 	play  = pdlayout_get(map->pi_ioreq);
@@ -2424,7 +2448,7 @@ static int pargrp_iomap_dgmode_recover(struct pargrp_iomap *map)
 	struct m0_pdclust_layout *play;
 
 	M0_ENTRY();
-	M0_PRE(pargrp_iomap_invariant(map));
+	M0_PRE_EX(pargrp_iomap_invariant(map));
 	M0_PRE(map->pi_state == PI_DEGRADED);
 
 	play = pdlayout_get(map->pi_ioreq);
@@ -2755,7 +2779,7 @@ static int nw_xfer_io_distribute(struct nw_xfer_request *xfer)
 	struct m0_pdclust_tgt_addr  tgt;
 
 	M0_ENTRY("nw_xfer_request %p", xfer);
-	M0_PRE(nw_xfer_request_invariant(xfer));
+	M0_PRE_EX(nw_xfer_request_invariant(xfer));
 
 	req	  = bob_of(xfer, struct io_request, ir_nwxfer, &ioreq_bobtype);
 	play	  = pdlayout_get(req);
@@ -2836,12 +2860,13 @@ static int nw_xfer_io_distribute(struct nw_xfer_request *xfer)
 
 	M0_RETURN(0);
 err:
-	m0_tl_teardown(tioreqs, &xfer->nxr_tioreqs, ti) {
+	m0_hashlist_for(tioreq_hash, ti, &xfer->nxr_tioreqs_hash) {
+		m0_hashlist_del(&xfer->nxr_tioreqs_hash, ti);
 		target_ioreq_fini(ti);
 		m0_free(ti);
 		++iommstats.d_target_ioreq_nr;
 		ti = NULL;
-	}
+	} m0_hashlist_endfor;
 
 	M0_RETERR(rc, "io_prepare failed");
 }
@@ -2868,7 +2893,7 @@ static int ioreq_dgmode_recover(struct io_request *req)
 	uint64_t cnt;
 
 	M0_ENTRY();
-	M0_PRE(io_request_invariant(req));
+	M0_PRE_EX(io_request_invariant(req));
 	M0_PRE(ioreq_sm_state(req) == IRS_READ_COMPLETE);
 
 	for (cnt = 0; cnt < req->ir_iomap_nr; ++cnt) {
@@ -2902,7 +2927,7 @@ static int device_check(struct io_request *req)
 					   IRS_WRITE_COMPLETE)));
 	csb = file_to_sb(req->ir_file);
 
-	m0_tl_for (tioreqs, &req->ir_nwxfer.nxr_tioreqs, ti) {
+	m0_hashlist_for (tioreq_hash, ti, &req->ir_nwxfer.nxr_tioreqs_hash) {
 		rc = m0_poolmach_device_state(csb->csb_pool.po_mach,
 				              ti->ti_fid.f_container, &state);
 		if (rc != 0)
@@ -2912,7 +2937,7 @@ static int device_check(struct io_request *req)
 		if (M0_IN(state, (M0_PNDS_FAILED, M0_PNDS_OFFLINE,
 			          M0_PNDS_SNS_REPAIRING)))
 			st_cnt++;
-	} m0_tl_endfor;
+	} m0_hashlist_endfor;
 
 	/*
 	 * Since m0t1fs IO only supports XOR at the moment, max number of
@@ -2936,7 +2961,7 @@ static int ioreq_dgmode_write(struct io_request *req, bool rmw)
 	struct m0t1fs_sb        *csb;
 
 	M0_ENTRY();
-	M0_PRE(io_request_invariant(req));
+	M0_PRE_EX(io_request_invariant(req));
 
 	rc = device_check(req);
 	if (req->ir_nwxfer.nxr_rc == 0)
@@ -2996,11 +3021,12 @@ static int ioreq_dgmode_write(struct io_request *req, bool rmw)
 		 * Fops meant for failed devices are dropped in
 		 * nw_xfer_req_dispatch().
 		 */
-		m0_tl_for (tioreqs, &req->ir_nwxfer.nxr_tioreqs, ti) {
+		m0_hashlist_for(tioreq_hash, ti,
+			     &req->ir_nwxfer.nxr_tioreqs_hash) {
 			ti->ti_databytes = 0;
 			ti->ti_parbytes  = 0;
 			ti->ti_rc        = 0;
-		} m0_tl_endfor;
+		} m0_hashlist_endfor;
 
 	} else {
 		/*
@@ -3047,7 +3073,7 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 	enum m0_pool_nd_state    state;
 
 	M0_ENTRY();
-	M0_PRE(io_request_invariant(req));
+	M0_PRE_EX(io_request_invariant(req));
 
 	rc = device_check(req);
 	/*
@@ -3063,7 +3089,7 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 
 	csb = file_to_sb(req->ir_file);
 	start = m0_time_now();
-	m0_tl_for (tioreqs, &req->ir_nwxfer.nxr_tioreqs, ti) {
+	m0_hashlist_for(tioreq_hash, ti, &req->ir_nwxfer.nxr_tioreqs_hash) {
 		rc = m0_poolmach_device_state(csb->csb_pool.po_mach,
 				ti->ti_fid.f_container, &state);
 		if (rc != 0)
@@ -3092,7 +3118,7 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 			if (rc != 0)
 				break;
 		} m0_tl_endfor;
-	} m0_tl_endfor;
+	} m0_hashlist_endfor;
 
 	if (rc != 0)
 		M0_RETERR(rc, "dgmode failed");
@@ -3120,18 +3146,19 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 		 * Ergo, page counts in index and buffer vectors are reset.
 		 */
 
-		m0_tl_for (tioreqs, &req->ir_nwxfer.nxr_tioreqs, ti) {
+		m0_hashlist_for(tioreq_hash, ti,
+			     &req->ir_nwxfer.nxr_tioreqs_hash) {
 			ti->ti_ivec.iv_vec.v_nr = 0;
-		} m0_tl_endfor;
+		} m0_hashlist_endfor;
 	}
 
 	req->ir_nwxfer.nxr_ops->nxo_complete(&req->ir_nwxfer, rmw);
 
-	m0_tl_for (tioreqs, &req->ir_nwxfer.nxr_tioreqs, ti) {
+	m0_hashlist_for(tioreq_hash, ti, &req->ir_nwxfer.nxr_tioreqs_hash) {
 		ti->ti_databytes = 0;
 		ti->ti_parbytes  = 0;
 		ti->ti_rc        = 0;
-	} m0_tl_endfor;
+	} m0_hashlist_endfor;
 
 	/* Resets the status code before starting degraded mode read IO. */
 	if (req->ir_nwxfer.nxr_rc != 0)
@@ -3210,7 +3237,7 @@ static int ioreq_iosm_handle(struct io_request *req)
 	struct target_ioreq *ti;
 
 	M0_ENTRY("io_request %p", req);
-	M0_PRE(io_request_invariant(req));
+	M0_PRE_EX(io_request_invariant(req));
 
 	for (map = 0; map < req->ir_iomap_nr; ++map) {
 		if (M0_IN(req->ir_iomaps[map]->pi_rtype,
@@ -3293,11 +3320,12 @@ static int ioreq_iosm_handle(struct io_request *req)
 		m0_bcount_t read_pages = 0;
 
 		rmw = true;
-		m0_tl_for (tioreqs, &req->ir_nwxfer.nxr_tioreqs, ti) {
+		m0_hashlist_for(tioreq_hash, ti,
+			     &req->ir_nwxfer.nxr_tioreqs_hash) {
 			for (seg = 0; seg < ti->ti_bufvec.ov_vec.v_nr; ++seg)
 				if (ti->ti_pageattrs[seg] & PA_READ)
 					++read_pages;
-		} m0_tl_endfor;
+		} m0_hashlist_endfor;
 
 		/* Read IO is issued only if byte count > 0. */
 		if (read_pages > 0) {
@@ -3433,6 +3461,8 @@ static int io_request_init(struct io_request  *req,
 
 	io_request_bob_init(req);
 	nw_xfer_request_init(&req->ir_nwxfer);
+	if (req->ir_nwxfer.nxr_rc != 0)
+		M0_RETERR(req->ir_nwxfer.nxr_rc, "nw_xfer_req_init() failed");
 
 	m0_sm_init(&req->ir_sm, &io_sm_conf, IRS_INITIALIZED,
 		   file_to_smgroup(req->ir_file));
@@ -3452,7 +3482,7 @@ static int io_request_init(struct io_request  *req,
 	/* Sorts the index vector in increasing order of file offset. */
 	indexvec_sort(&req->ir_ivec);
 
-	M0_POST(ergo(rc == 0, io_request_invariant(req)));
+	M0_POST_EX(ergo(rc == 0, io_request_invariant(req)));
 	M0_RETURN(rc);
 }
 
@@ -3461,7 +3491,7 @@ static void io_request_fini(struct io_request *req)
 	struct target_ioreq *ti;
 
 	M0_ENTRY("io_request %p", req);
-	M0_PRE(io_request_invariant(req));
+	M0_PRE_EX(io_request_invariant(req));
 
 	m0_sm_fini(&req->ir_sm);
 	io_request_bob_fini(req);
@@ -3471,7 +3501,8 @@ static void io_request_fini(struct io_request *req)
 	req->ir_ops    = NULL;
 	m0_indexvec_free(&req->ir_ivec);
 
-	m0_tl_teardown(tioreqs, &req->ir_nwxfer.nxr_tioreqs, ti) {
+	m0_hashlist_for(tioreq_hash, ti, &req->ir_nwxfer.nxr_tioreqs_hash) {
+		m0_hashlist_del(&req->ir_nwxfer.nxr_tioreqs_hash, ti);
 		/*
 		 * All io_req_fop structures in list target_ioreq::ti_iofops
 		 * are already finalized in nw_xfer_req_complete().
@@ -3479,7 +3510,7 @@ static void io_request_fini(struct io_request *req)
 		target_ioreq_fini(ti);
 		m0_free(ti);
 		++iommstats.d_target_ioreq_nr;
-	}
+	} m0_hashlist_endfor;
 
 	nw_xfer_request_fini(&req->ir_nwxfer);
 	M0_LEAVE();
@@ -3520,7 +3551,7 @@ static int nw_xfer_tioreq_map(struct nw_xfer_request           *xfer,
 	int			    rc;
 
 	M0_ENTRY("nw_xfer_request %p", xfer);
-	M0_PRE(nw_xfer_request_invariant(xfer));
+	M0_PRE_EX(nw_xfer_request_invariant(xfer));
 	M0_PRE(src != NULL);
 	M0_PRE(tgt != NULL);
 
@@ -3685,7 +3716,7 @@ static int target_ioreq_init(struct target_ioreq    *ti,
 	ti->ti_databytes = 0;
 
 	iofops_tlist_init(&ti->ti_iofops);
-	tioreqs_tlink_init(ti);
+	tioreq_hash_tlink_init(ti);
 	target_ioreq_bob_init(ti);
 
 	rc = m0_indexvec_alloc(&ti->ti_ivec, page_nr(size),
@@ -3722,7 +3753,7 @@ static int target_ioreq_init(struct target_ioreq    *ti,
 	 */
 	ti->ti_ivec.iv_vec.v_nr = 0;
 
-	M0_POST(target_ioreq_invariant(ti));
+	M0_POST_EX(target_ioreq_invariant(ti));
 	M0_RETURN(0);
 fail:
 	m0_indexvec_free(&ti->ti_ivec);
@@ -3735,10 +3766,10 @@ out:
 static void target_ioreq_fini(struct target_ioreq *ti)
 {
 	M0_ENTRY("target_ioreq %p", ti);
-	M0_PRE(target_ioreq_invariant(ti));
+	M0_PRE_EX(target_ioreq_invariant(ti));
 
 	target_ioreq_bob_fini(ti);
-	tioreqs_tlink_fini(ti);
+	tioreq_hash_tlink_fini(ti);
 	iofops_tlist_fini(&ti->ti_iofops);
 	ti->ti_ops     = NULL;
 	ti->ti_session = NULL;
@@ -3767,13 +3798,11 @@ static struct target_ioreq *target_ioreq_locate(struct nw_xfer_request *xfer,
 	struct target_ioreq *ti;
 
 	M0_ENTRY("nw_xfer_request %p, fid %p", xfer, fid);
-	M0_PRE(nw_xfer_request_invariant(xfer));
+	M0_PRE_EX(nw_xfer_request_invariant(xfer));
 	M0_PRE(fid != NULL);
 
-	m0_tl_for (tioreqs, &xfer->nxr_tioreqs, ti) {
-		if (m0_fid_eq(&ti->ti_fid, fid))
-			break;
-	} m0_tl_endfor;
+	ti = m0_hashlist_lookup(&xfer->nxr_tioreqs_hash, fid->f_container);
+	M0_ASSERT(ergo(ti != NULL, m0_fid_cmp(fid, &ti->ti_fid) == 0));
 
 	M0_LEAVE();
 	return ti;
@@ -3789,7 +3818,7 @@ static int nw_xfer_tioreq_get(struct nw_xfer_request *xfer,
 	struct target_ioreq *ti;
 	struct io_request   *req;
 
-	M0_PRE(nw_xfer_request_invariant(xfer));
+	M0_PRE_EX(nw_xfer_request_invariant(xfer));
 	M0_PRE(fid     != NULL);
 	M0_PRE(session != NULL);
 	M0_PRE(out     != NULL);
@@ -3807,7 +3836,7 @@ static int nw_xfer_tioreq_get(struct nw_xfer_request *xfer,
 
 		rc = target_ioreq_init(ti, xfer, fid, session, size);
 		if (rc == 0) {
-			tioreqs_tlist_add(&xfer->nxr_tioreqs, ti);
+			m0_hashlist_add(&xfer->nxr_tioreqs_hash, ti);
 			M0_LOG(M0_INFO, "New target_ioreq added for fid "
 					"%llu:%llu", fid->f_container,
 					fid->f_key);
@@ -3905,7 +3934,7 @@ static void target_ioreq_seg_add(struct target_ioreq              *ti,
 
 	M0_ENTRY("tio req %p, gob_offset %llu, count %llu frame %llu unit %llu",
 		 ti, gob_offset, count, frame, unit);
-	M0_PRE(target_ioreq_invariant(ti));
+	M0_PRE_EX(target_ioreq_invariant(ti));
 	M0_PRE(map != NULL);
 
 	req	= bob_of(ti->ti_nwxfer, struct io_request, ir_nwxfer,
@@ -4618,7 +4647,7 @@ static int nw_xfer_req_dispatch(struct nw_xfer_request *xfer)
 	                 &csb->csb_addb_ctx);
 	m0t1fs_fs_unlock(csb);
 
-	m0_tl_for (tioreqs, &xfer->nxr_tioreqs, ti) {
+	m0_hashlist_for(tioreq_hash, ti, &xfer->nxr_tioreqs_hash) {
 		if (ti->ti_state != M0_PNDS_ONLINE) {
 			M0_LOG(M0_INFO, "Skipped iofops prepare for fid"
 			       "%llu:%llu", ti->ti_fid.f_container,
@@ -4633,9 +4662,9 @@ static int nw_xfer_req_dispatch(struct nw_xfer_request *xfer)
 		rc = ti->ti_ops->tio_iofops_prepare(ti, PA_PARITY);
 		if (rc != 0)
 			M0_RETERR(rc, "parity fop failed");
-	} m0_tl_endfor;
+	} m0_hashlist_endfor;
 
-	m0_tl_for (tioreqs, &xfer->nxr_tioreqs, ti) {
+	m0_hashlist_for(tioreq_hash, ti, &xfer->nxr_tioreqs_hash) {
 
 		/* Skips the target device if it is not online. */
 		if (ti->ti_state != M0_PNDS_ONLINE) {
@@ -4655,7 +4684,7 @@ static int nw_xfer_req_dispatch(struct nw_xfer_request *xfer)
 						csb_pending_io_nr);
 		} m0_tl_endfor;
 
-	} m0_tl_endfor;
+	} m0_hashlist_endfor;
 
 out:
 	xfer->nxr_state = NXS_INFLIGHT;
@@ -4673,7 +4702,8 @@ static void nw_xfer_req_complete(struct nw_xfer_request *xfer, bool rmw)
 
 	xfer->nxr_state = NXS_COMPLETE;
 	req = bob_of(xfer, struct io_request, ir_nwxfer, &ioreq_bobtype);
-	m0_tl_for (tioreqs, &xfer->nxr_tioreqs, ti) {
+
+	m0_hashlist_for(tioreq_hash, ti, &xfer->nxr_tioreqs_hash) {
 		struct io_req_fop *irfop;
 
 		/* Maintains only the first error encountered. */
@@ -4698,7 +4728,7 @@ static void nw_xfer_req_complete(struct nw_xfer_request *xfer, bool rmw)
 			     ti->ti_fid.f_container, ti->ti_fid.f_key,
 			     ti->ti_databytes + ti->ti_parbytes,
 			     m0_time_sub(m0_time_now(), ti->ti_start_time));
-	} m0_tl_endfor;
+	} m0_hashlist_endfor;
 
 	M0_LOG(M0_INFO, "Number of bytes %s = %llu",
 	       ioreq_sm_state(req) == IRS_READ_COMPLETE ? "read" : "written",
@@ -4876,7 +4906,7 @@ static int target_ioreq_iofops_prepare(struct target_ioreq *ti,
 	M0_ENTRY("prepare io fops for target ioreq %p filter %u, tfid"
 		 "%llu:%llu", ti, filter, ti->ti_fid.f_container,
 		 ti->ti_fid.f_key);
-	M0_PRE(target_ioreq_invariant(ti));
+	M0_PRE_EX(target_ioreq_invariant(ti));
 	M0_PRE(M0_IN(filter, (PA_DATA, PA_PARITY)));
 
 	req	= bob_of(ti->ti_nwxfer, struct io_request, ir_nwxfer,
diff --git a/m0t1fs/linux_kernel/file_internal.h b/m0t1fs/linux_kernel/file_internal.h
index adc5d9f..84e0cf1 100644
--- a/m0t1fs/linux_kernel/file_internal.h
+++ b/m0t1fs/linux_kernel/file_internal.h
@@ -1193,8 +1193,12 @@ struct nw_xfer_request {
 
         const struct nw_xfer_ops *nxr_ops;
 
-        /** List of all target_ioreq structures. */
-        struct m0_tl              nxr_tioreqs;
+	/**
+	 * Hash of target_ioreq objects. Helps to speed up the lookup
+	 * of target_ioreq objects based on a key 
+	 * (target_ioreq::ti_fid::f_container)
+	 */
+	struct m0_hashlist        nxr_tioreqs_hash;
 
         /**
          * Number of IO fops issued by all target_ioreq structures
diff --git a/m0t1fs/linux_kernel/ut/file.c b/m0t1fs/linux_kernel/ut/file.c
index 6c7f00d..602eba3 100644
--- a/m0t1fs/linux_kernel/ut/file.c
+++ b/m0t1fs/linux_kernel/ut/file.c
@@ -348,6 +348,7 @@ static void ds_test(void)
 	ioreq_sm_state_set(&req, IRS_REQ_COMPLETE);
 	req.ir_nwxfer.nxr_state = NXS_COMPLETE;
 	req.ir_nwxfer.nxr_bytes = 1;
+	M0_UT_ASSERT(m0_hashlist_is_empty(&req.ir_nwxfer.nxr_tioreqs_hash));
 	io_request_fini(&req);
 	M0_UT_ASSERT(req.ir_file   == NULL);
 	M0_UT_ASSERT(req.ir_iovec  == NULL);
@@ -355,7 +356,6 @@ static void ds_test(void)
 	M0_UT_ASSERT(req.ir_ops    == NULL);
 	M0_UT_ASSERT(req.ir_ivec.iv_index       == NULL);
 	M0_UT_ASSERT(req.ir_ivec.iv_vec.v_count == NULL);
-	M0_UT_ASSERT(tioreqs_tlist_is_empty(&req.ir_nwxfer.nxr_tioreqs));
 
 	M0_UT_ASSERT(req.ir_nwxfer.nxr_ops == NULL);
 	M0_UT_ASSERT(req.ir_nwxfer.nxr_magic == 0);
@@ -637,8 +637,7 @@ static void nw_xfer_ops_test(void)
 	/* Test for nw_xfer_tioreq_map. */
 	rc = nw_xfer_tioreq_map(&req.ir_nwxfer, &src, &tgt, &ti);
 	M0_UT_ASSERT(rc == 0);
-	M0_UT_ASSERT(m0_tlist_length(&tioreqs_tl,
-				&req.ir_nwxfer.nxr_tioreqs) == 1);
+	M0_UT_ASSERT(!m0_hashlist_is_empty(&req.ir_nwxfer.nxr_tioreqs_hash));
 	M0_UT_ASSERT(ti->ti_ivec.iv_index != NULL);
 	M0_UT_ASSERT(ti->ti_ivec.iv_vec.v_count != NULL);
 	M0_UT_ASSERT(ti->ti_bufvec.ov_vec.v_count != NULL);
@@ -648,8 +647,9 @@ static void nw_xfer_ops_test(void)
 	/* Test for nw_xfer_io_distribute. */
 	rc = nw_xfer_io_distribute(&req.ir_nwxfer);
 	M0_UT_ASSERT(rc == 0);
-	M0_UT_ASSERT(tioreqs_tlist_length(&req.ir_nwxfer.nxr_tioreqs) == LAY_P);
-	m0_tl_for (tioreqs, &req.ir_nwxfer.nxr_tioreqs, ti) {
+	M0_UT_ASSERT(m0_hashlist_length(&req.ir_nwxfer.nxr_tioreqs_hash) ==
+			LAY_P);
+	m0_hashlist_for(tioreq_hash, ti, &req.ir_nwxfer.nxr_tioreqs_hash) {
 		M0_UT_ASSERT(ti->ti_nwxfer == &req.ir_nwxfer);
 		M0_UT_ASSERT(ti->ti_ops != NULL);
 
@@ -659,11 +659,12 @@ static void nw_xfer_ops_test(void)
 			M0_UT_ASSERT(ti->ti_ivec.iv_vec.v_count[cnt] ==
 				     PAGE_CACHE_SIZE);
 		}
-	} m0_tl_endfor;
+	} m0_hashlist_endfor;
+
+	m0_hashlist_for(tioreq_hash, ti1, &req.ir_nwxfer.nxr_tioreqs_hash) {
+		m0_hashlist_del(&req.ir_nwxfer.nxr_tioreqs_hash, ti1);
+	} m0_hashlist_endfor;
 
-	m0_tl_teardown(tioreqs, &req.ir_nwxfer.nxr_tioreqs, ti1) {
-		;
-	}
 	ioreq_iomaps_destroy(&req);
 	req.ir_sm.sm_state      = IRS_REQ_COMPLETE;
 	req.ir_nwxfer.nxr_state = NXS_COMPLETE;
@@ -722,8 +723,8 @@ static void target_ioreq_test(void)
 	aligned_buf = m0_alloc_aligned(M0_0VEC_ALIGN, M0_0VEC_SHIFT);
 
         io_request_bob_init(&req);
-        nw_xfer_request_init(&req.ir_nwxfer);
 	req.ir_file = &lfile;
+        nw_xfer_request_init(&req.ir_nwxfer);
 
 	rc = target_ioreq_init(&ti, &req.ir_nwxfer, &cfid, &session, size);
 	M0_UT_ASSERT(rc == 0);
@@ -898,8 +899,8 @@ static void dgmode_readio_test(void)
 
 	ioreq_sm_state_set(req, IRS_LOCK_ACQUIRED);
 	ioreq_sm_state_set(req, IRS_READING);
-	ti = tioreqs_tlist_head(&req->ir_nwxfer.nxr_tioreqs);
-
+	ti = m0_hashlist_lookup(&req->ir_nwxfer.nxr_tioreqs_hash, 1);
+	
 	/*
 	 * Fake data structure members so that UT passes through
 	 * PRE checks unhurt.
diff --git a/mero/magic.h b/mero/magic.h
index ace26a9..bdc763e 100644
--- a/mero/magic.h
+++ b/mero/magic.h
@@ -736,6 +736,14 @@ enum m0_magic_satchel {
 
 	/* m0_be_tx_group::tg_txs (codified bee)  */
 	M0_BE_TX_GROUP_MAGIC = 0x33c0d1f1edbee377,
+
+/* lib */
+	/* hashlist::hl_magic = invincibilis */
+	M0_LIB_HASHLIST_MAGIC = 0x3319519c1b111577,
+
+	/* hashbucket::hb_tioreqs::td_head_magic = desirability */
+	M0_LIB_HASHBUCKET_MAGIC = 0x33de512ab1111777,
+
 };
 
 #endif /* __MERO_MERO_MAGIC_H__ */
-- 
1.8.3.2

