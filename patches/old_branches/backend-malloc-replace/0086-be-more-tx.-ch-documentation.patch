From 1e9d1f78a5032246b1e1e1f576f334720b3603fe Mon Sep 17 00:00:00 2001
From: Nikita Danilov <nikita_danilov@xyratex.com>
Date: Sun, 2 Jun 2013 19:18:56 +0400
Subject: [PATCH 086/161] be: more tx.[ch] documentation.

---
 be/tx.c |  33 +-----------
 be/tx.h | 178 +++++++++++++++++++++++++++++++++++++++++++++++++++++-----------
 2 files changed, 150 insertions(+), 61 deletions(-)

diff --git a/be/tx.c b/be/tx.c
index 6a53163..537f97e 100644
--- a/be/tx.c
+++ b/be/tx.c
@@ -360,35 +360,6 @@ static void tx_group_add(struct m0_be_tx_engine *eng,
 	}
 }
 
-static int index_add(void **tree, struct m0_be_tx_reg *old,
-		     struct m0_be_tx_reg *new,
-		     struct m0_be_tx_credit *delta)
-{
-	struct m0_be_tx *told   = r0->tr_tx;
-	struct m0_be_tx *tnew   = r1->tr_tx;
-	m0_bindex_t      idxold = r0 - t0->t_reg_index;
-	m0_bindex_t      idxnew = r1 - t1->t_reg_index;
-	struct m0_ext   *eold   = &t0->t_reg_d[idx0].rd_ext;
-	struct m0_ext   *enew   = &t1->t_reg_d[idx1].rd_ext;
-	struct m0_ext    intersection;
-	struct m0_ext    lold;
-	struct m0_ext    lnew;
-	struct m0_ext    rold;
-	struct m0_ext    rnew;
-
-	m0_ext_split(eold, enew, &lold, &lnew, &intersection, &rold, &rnew);
-	M0_PRE(!m0_ext_is_empty(&intersection));
-
-	if (m0_ext_is_partof(enew, eold)) {
-		/* new region completely covers the old. */
-		tdelete(old, tree, &tx_reg_cmp);
-		delta->tc_reg_nr--;
-		delta->tc_reg_size -= m0_ext_length(eold);
-	} else {
-
-	}
-}
-
 static void tx_state_set(struct m0_be_tx *tx, enum m0_be_tx_state state)
 {
 	M0_PRE(m0_be__tx_invariant(tx));
@@ -512,9 +483,9 @@ M0_INTERNAL bool m0_be__tx_invariant(const struct m0_be_tx *tx)
 	return
 		state < M0_BTS_NR &&
 		tx_tlist_contains(tx_engine(tx)->te_txs[state], tx) &&
-		credit_le(&tx->t_used, &tx->t_captured) &&
 		credit_le(&tx->t_captured, &tx->t_prepared) &&
-		credit_le(&tx->t_pos, &tx->t_used) &&
+		credit_le(&tx->t_pos, &tx->t_captured) &&
+		credit_le(&tx->t_used, &tx->t_pos) &&
 		(tx->t_lsn == 0) == (state < M0_BTS_GROUPED) &&
 		(tx->t_reg_area != NULL) == (state >= M0_BTS_ACTIVE) &&
 		(tx->t_reg_area == NULL) == (tx->t_reg_d_area == NULL) &&
diff --git a/be/tx.h b/be/tx.h
index 4cfda48..9b11d1c 100644
--- a/be/tx.h
+++ b/be/tx.h
@@ -68,8 +68,8 @@ struct m0_be_tx_group;
  *
  * When a memory region is captured in a transaction, the contents of this
  * region, i.e., new values placed in the memory by the user, are copied in a
- * transaction-private memory buffer. Eventually a transaction is closed, i.e.,
- * the user indicates that no more updates will be captured in the
+ * transaction-private memory buffer. Eventually the transaction is closed,
+ * i.e., the user indicates that no more updates will be captured in the
  * transaction. Closed transactions are collected in "transaction groups"
  * (m0_be_tx_group), which are units of IO. When a group is formed it is written
  * to the log. When log IO for the group completes, transactions from the group
@@ -91,11 +91,11 @@ struct m0_be_tx_group;
  *
  *     - currently, the transaction engine writes modified memory in place, as
  *       described in the "Overview of operation" section. In the future, the
- *       transaction engine would leave this task to the (currently non-exiting)
- *       segment page daemon;
+ *       transaction engine would leave this task to the (currently
+ *       non-existing) segment page daemon;
  *
  *     - transaction close call (m0_be_tx_close()) does not guarantee
- *       transaction persistency. Transaction become persistent later. The user
+ *       transaction persistence. Transaction become persistent later. The user
  *       can set a call-back m0_be_tx::t_persistent() that is called when the
  *       transaction becomes persistent;
  *
@@ -134,7 +134,7 @@ struct m0_be_tx_group;
  *                        | tx_group_add()
  *                        |
  *                        V
- *                     GROUPPED
+ *                     GROUPED
  *                        |
  *                        | log io completes
  *                        |
@@ -243,7 +243,8 @@ enum m0_be_tx_state {
 	 */
 	M0_BTS_PREPARE,
 	/**
-	 * In this state transaction wait for internal resource to be allocated.
+	 * In this state transaction waits for internal resource to be
+	 * allocated.
 	 *
 	 * Specifically, the transaction is in this state until there is enough
 	 * free space in the log to store transaction updates.
@@ -281,18 +282,30 @@ enum m0_be_tx_state {
 };
 
 /**
- * This structure incapsulates internals of transactional log.
+ * This structure encapsulates internals of transactional log.
  *
- * Logically, a log is a circular buffer stored on persistent storage. It can be
- * implemented as a single m0_stob (current implementation) or as a more complex
- * growable structure scattered across multiple stobs.
+ * Logically, a log is an infinite sequence of transaction groups. New groups
+ * are added to the log as they are formed and old groups are retired, when
+ * their transaction stabilise.
+ *
+ * Physically, the log is implemented as a circular buffer on persistent
+ * storage. To make this implementation possible, transaction engine guarantees
+ * that the used portion of infinite log is never larger than the physical log
+ * size.
  *
  * A position in the log is identified by a "log sequence number" (lsn), which
- * is simply an offset in the log. lsn does not wrap back to 0 when cyclic
- * buffer wraps around. lsn uniquely identifies a point in system history.
+ * is simply an offset in the logical log. lsn uniquely identifies a point in
+ * system history.
  */
 struct m0_be_log {
-	/** Underlying storage. */
+	/**
+	 * Underlying storage.
+	 *
+	 * @todo this might be changed to something more complicated to support
+	 * flexible deployment and grow-able logs. E.g., a log can be stored in
+	 * a sequence of regions in segments, linked to each other through
+	 * header blocks.
+	 */
 	struct m0_stob  *lg_stob;
 	/** Log size. */
 	m0_bcount_t      lg_size;
@@ -303,6 +316,10 @@ struct m0_be_log {
 	 * group starts forming.
 	 */
 	m0_bcount_t      lg_gr_size_max;
+	/**
+	 * lsn to be used for the next log element.
+	 */
+	m0_bindex_lsn    lg_lsn;
 };
 
 /**
@@ -323,7 +340,7 @@ struct m0_be_log {
  * commit block is written, all other IOs for the group must complete. After
  * that, the commit block is written. Once commit block IO completes, it is
  * guaranteed that the entire group is on the log. Waiting for IO completion can
- * be eliminated by using (currently unimplemneted) barrier interface provided
+ * be eliminated by using (currently unimplemented) barrier interface provided
  * by m0_stob, or by placing in the commit block a strong checksum of group
  * representation (the latter approach allows to check whether the entire group
  * made it to the log).
@@ -335,13 +352,8 @@ struct m0_be_tx_group {
 	bool                    tg_opened;
 	/** Total size of all updates in all transactions in this group. */
 	struct m0_be_tx_credit  tg_used;
-	/** Number of transactions in the group. */
-	m0_bcount_t             tg_tx_nr;
-	/**
-	 * A tree of disjoint updated memory regions in this group. This is
-	 * similar to m0_be_tx::t_tree, which see.
-	 */
-	void                   *tg_tree;
+	/** List of transactions in the group. */
+	struct m0_tl            tg_tx;
 };
 
 /**
@@ -407,10 +419,10 @@ M0_INTERNAL void m0_be_tx_engine_fini(struct m0_be_tx_engine *engine);
  *       these regions.
  *
  * Hence, the user should inform the engine about amount and size of regions
- * that the transaciton would modify. This is achieved by calling
+ * that the transaction would modify. This is achieved by calling
  * m0_be_tx_prep() (possibly multiple times), while the transaction is in
  * PREPARE state. The calls to m0_be_tx_prep() must be conservative: it is fine
- * to prepare for more updates that thet transaction will actually make (the
+ * to prepare for more updates than the transaction will actually make (the
  * latter quantity is usually impossible to know beforehand anyway), but the
  * transaction must never capture more than it prepared.
  */
@@ -444,35 +456,141 @@ struct m0_be_tx {
 	uint64_t               t_id;
 	/**
 	 * lsn of transaction representation in the log. Assigned when the
-	    transaction reaches GROUPED state.
-	*/
+	 * transaction reaches GROUPED state.
+	 */
 	uint64_t               t_lsn;
 	struct m0_be          *t_be;
+	/**
+	 * Linkage in one of m0_be_tx_engine::te_txs[] lists.
+	 */
 	struct m0_tlink        t_linkage;
+	/**
+	 * Linkage in m0_be_tx_group::tg_tx.
+	 */
 	struct m0_tlink        t_group_linkage;
+	/**
+	 * Size (in bytes) of "payload area" in the transaction log header,
+	 * reserved for user.
+	 *
+	 * User should directly set this field, while the transaction is in
+	 * PREPARE state.
+	 */
 	m0_bcount_t            t_payload_size;
+	/**
+	 * Updates prepared for at PREPARE state.
+	 */
 	struct m0_be_tx_credit t_prepared;
+	/**
+	 * Updates actually captured.
+	 */
 	struct m0_be_tx_credit t_captured;
+	/**
+	 * Updates actually stored in the transaction buffers
+	 * (m0_be_tx::t_reg_d_area and m0_be_tx::t_reg_area).
+	 *
+	 * This can be less that t_captured, when newly captured region overlaps
+	 * with previously captured one. In this case, old region is discarded
+	 * or partially overwritten.
+	 */
 	struct m0_be_tx_credit t_used;
+	/**
+	 * This records the positions in transaction buffers, that should be
+	 * used for the next captured region.
+	 *
+	 * ->t_pos.tc_reg_nr is the index of the first free element in
+	 * ->t_reg_d_area[]
+	 *
+	 * ->t_pos.tc_reg_size is the index of the first free element in
+	 * ->t_reg_area[].
+	 *
+	 * t_pos can be greater than t_used when a previously captured region is
+	 * completely overwritten by a new one. In this case old region is
+	 * discarded, but the space it uses in the internal buffers cannot be
+	 * re-used because it can be in the middle.
+	 */
 	struct m0_be_tx_credit t_pos;
+	/**
+	 * Internal buffer, allocated in m0_be_tx_open(). It has
+	 * ->t_prepared.tc_reg_nr elements and is filled with information about
+	 * the regions captured by the transaction.
+	 */
 	struct m0_be_reg_d    *t_reg_d_area;
+	/**
+	 * Internal buffer, allocated in m0_be_tx_open(). It has
+	 * ->t_prepared.tc_reg_size elements and is filled with contents of the
+	 * regions captured by the transaction.
+	 */
 	void                  *t_reg_area;
+	/**
+	 * The group the transaction is part of. This is non-NULL iff the
+	 * transaction is in GROUPED or later state.
+	 */
 	struct m0_be_tx_group *t_group;
+	/**
+	 * True iff the transaction is the first transaction in the group. In
+	 * this case, the overhead of group (specifically, the size of group
+	 * header and group commit log) are "billed" to the transaction.
+	 */
 	bool                   t_leader;
+	/**
+	 * Optional call-back called when the transaction is guaranteed to
+	 * survive all further failures. This is invoked when the transaction
+	 * reaches LOGGED state.
+	 */
 	m0_be_tx_cb_t          t_persistent;
+	/**
+	 * This optional call-back is called when a stable transaction is about
+	 * to be discarded from the history.
+	 *
+	 * A typical user of this call-back is ioservice that uses ->t_discarded
+	 * to initiate a new transaction to free storage space used by the
+	 * COW-ed file extents.
+	 */
 	m0_be_tx_cb_t          t_discarded;
-	void                 (*t_filler)(struct m0_be_tx *tx,
-					 void *payload, void *datum);
+	/**
+	 * An optional call-back called when the transaction is being closed.
+	 *
+	 * "payload" parameter is the pointer to a m0_be_tx::t_payload-sized
+	 * buffer, that will be written to the log.
+	 *
+	 * ->t_filler() can capture regions in the transaction.
+	 *
+	 * A typical use of this call-back is to form a "fol record" used by DTM
+	 * for distributed transaction management.
+	 */
+	void                 (*t_filler)(struct m0_be_tx *tx, void *payload);
+	/**
+	 * User-specified value, associated with the transaction. Transaction
+	 * engine doesn't interpret this value. It can be used to pass
+	 * additional information to the call-backs.
+	 */
 	void                  *t_datum;
+	/**
+	 * Tree of disjoint captured extents.
+	 *
+	 * This tree contains region descriptors (m0_be_reg_d), of regions
+	 * captured by the transaction, ordered by the starting address.
+	 *
+	 * The tree is used to detect when captured regions overlap and to store
+	 * only the newest data.
+	 *
+	 * This is used as an optimisation to reduce the amount of memory
+	 * consumed in the common case of capturing the same memory again and
+	 * also to simplify in-place IO (stob-io doesn't support writing
+	 * overlapping extents in the same IO operation).
+	 *
+	 * The tree is maintained by glibc tree functions from <search.h>.
+	 */
 	void                  *t_tree;
 };
 M0_INTERNAL bool m0_be__tx_invariant(const struct m0_be_tx *tx);
 
-M0_INTERNAL void m0_be_tx_init(struct m0_be_tx *tx, uint64_t tid, struct m0_be *be,
+M0_INTERNAL void m0_be_tx_init(struct m0_be_tx *tx, uint64_t tid,
+			       struct m0_be *be,
 			       m0_be_tx_cb_t persistent,
 			       m0_be_tx_cb_t discarded,
 			       void (*filler)(struct m0_be_tx *tx,
-					      void *payload, void *datum));
+					      void *payload));
 
 M0_INTERNAL void m0_be_tx_fini(struct m0_be_tx *tx);
 
-- 
1.8.3.2

