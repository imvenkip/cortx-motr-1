From f293c64235c877a2a238e1d7394e6ff6aeef8510 Mon Sep 17 00:00:00 2001
From: Nachiket Sahasrabuddhe <nachiket_sahasrabuddhe@xyratex.com>
Date: Sat, 7 Sep 2013 18:57:19 +0530
Subject: [PATCH 23/50] bigmemalloc.mf

Except m0_varr_for everything else is fixed.
---
 lib/linux_kernel/varr.c |  23 +++---
 lib/user_space/varr.c   |  11 +--
 lib/varr.c              | 210 +++++++++++++++++++++++++++---------------------
 lib/varr.h              |  23 +++---
 4 files changed, 144 insertions(+), 123 deletions(-)

diff --git a/lib/linux_kernel/varr.c b/lib/linux_kernel/varr.c
index fda883f..b43e8b2 100644
--- a/lib/linux_kernel/varr.c
+++ b/lib/linux_kernel/varr.c
@@ -23,28 +23,29 @@
 #include "lib/types.h"	/* Includes appropriate types header. */
 #include <linux/pagemap.h>
 
-M0_EXTERN void *m0_varr_buf_alloc(int bufsize)
+M0_EXTERN void *m0_varr_buf_alloc(size_t bufsize)
 {
-	M0_PRE(bufsize == PAGE_CACHE_SIZE);
-
-	return (void *)get_zeroed_page(GFP_KERNEL);
+	if (bufsize == PAGE_CACHE_SIZE);
+		return (void *)get_zeroed_page(GFP_KERNEL);
+	else
+		return m0_alloc(bufsize);
 }
 
-M0_EXTERN void m0_varr_buf_free(void *buf)
+M0_EXTERN void m0_varr_buf_free(void *buf, size_t bufsize)
 {
 	M0_PRE(buf != NULL);
-
-	free_page((unsigned long)buf);
+	if (bufsize == PAGECACHE_SIZE)
+		free_page((unsigned long)buf);
+	else
+		m0_free(buf);
 }
 
 M0_EXTERN bool m0_varr_size_is_valid(const struct m0_varr *arr)
 {
 	M0_PRE(arr != NULL);
 
-	return
-		arr->va_sizeof  <  arr->va_bufsize &&
-		arr->va_bufsize == PAGE_CACHE_SIZE &&
-		arr->va_bufsize %  arr->va_sizeof == 0;
+	return  arr->va_buf_shift <= PAGE_CACHE_SHIFT    &&
+		arr->va_obj_shift  <=  arr->va_buf_shift
 }
 
 /*
diff --git a/lib/user_space/varr.c b/lib/user_space/varr.c
index bdb4673..e81350f 100644
--- a/lib/user_space/varr.c
+++ b/lib/user_space/varr.c
@@ -23,27 +23,22 @@
 #include "lib/memory.h" /* m0_alloc, m0_free */
 #include "lib/types.h"	/* Includes appropriate types header. */
 
-M0_EXTERN void *m0_varr_buf_alloc(int bufsize)
+M0_EXTERN void *m0_varr_buf_alloc(size_t bufsize)
 {
 	M0_PRE(bufsize > 0);
-
 	return m0_alloc(bufsize);
 }
 
-M0_EXTERN void m0_varr_buf_free(void *buf)
+M0_EXTERN void m0_varr_buf_free(void *buf, size_t bufsize)
 {
 	M0_PRE(buf != NULL);
-
 	m0_free(buf);
 }
 
 M0_EXTERN bool m0_varr_size_is_valid(const struct m0_varr *arr)
 {
 	M0_PRE(arr != NULL);
-
-	return
-		arr->va_sizeof  < arr->va_bufsize &&
-		arr->va_bufsize % arr->va_sizeof == 0;
+	return arr->va_obj_shift  < arr->va_buf_shift;
 }
 
 /*
diff --git a/lib/varr.c b/lib/varr.c
index 372a6ed..f0868c5 100644
--- a/lib/varr.c
+++ b/lib/varr.c
@@ -48,6 +48,7 @@ static uint64_t max_buff_nr_till_lev_n_pn(const struct m0_varr *arr,
 M0_INTERNAL void m0_varr_fini(struct m0_varr *arr);
 M0_INTERNAL uint64_t cont_nr_for_objs(unsigned long nr,
 				      unsigned long obj_nr_in_1_cont);
+
 /* Shifts a given number to left/right by taking into account sizeof (number) */
 #define safe_bitshift(num, type, shifti, operator)			     \
 ({									     \
@@ -57,37 +58,37 @@ M0_INTERNAL uint64_t cont_nr_for_objs(unsigned long nr,
 	M0_ASSERT(__shift < 8 * sizeof __num);				     \
 	operator == "<<" ? __num << __shift : __num >> __shift;		     \
  })
+
+/* A record in a stack holding address and index within a buffer. */
+struct varr_stack_rec {
+	/* Backlink to parent node. */
+	void     *vsr_addr;
+
+	/* Index of parent node in the buffer. */
+	uint64_t  vsr_index;
+};
+
 /*
- * A LIFO stack which maintains the backlink to parent node as well as
+ * A stack which maintains the backlink to parent node as well as
  * the index of parent node in given buffer.
  * The parent backlink helps traverse up the tree (from child to parent)
  * and the index of parent node in given buffer helps identify the
  * number of buffer beneath parent node in current traversal.
- * User of this data structure typically maintains array of such structures
- * to help move from leaf node to root node.
  * Index of an element in the array is used an identifier to represent the
  * level in the tree.
  */
-struct varr_stack_rec {
-	/* Backlink to parent node. */
-	void     *sr_addr;
-
-	/* Index of parent node in the buffer. */
-	uint64_t  sr_index;
-};
-
 struct varr_stack {
-	struct varr_stack_rec *s_rec;
-	int		       s_sp;
+	struct varr_stack_rec *vs_rec;
+	int		       vs_sp;
 };
 
 /* Cache that holds pointer to recently accessed buffer along with range of
  * objects that reside in it.
  */
 struct varr_cache {
-	void    *c_buff;
-	uint64_t c_first_index;
-	uint64_t c_last_index;
+	void    *vc_buff;
+	uint64_t vc_first_index;
+	uint64_t vc_last_index;
 }
 
 /* Enumeration for action to be taken on a set of buffers. */
@@ -97,37 +98,6 @@ enum buffer_action {
 	BA_NR
 };
 
-M0_INTERNAL int stack_init(struct m0_varr *arr)
-{
-	M0_ALLOC_PTR(arr->va_stack);
-	if (arr->va_stack == NULL)
-		return -ENOMEM;
-	M0_ALLOC_ARR(arr->va_stack->ls_rec, arr->va_depth - 1);
-	if (arr->va_stack->ls_rec == NULL)
-		return -ENOMEM;
-	arr->va_stack->ls_sp = -1;
-}
-
-M0_INTERNAL int push(struct m0_varr *arr, void *addr, uint64_t index)
-{
-	++arr->va_stack->ls_sp;
-	if (arr->va_stack->ls_sp == arr->va_depth - 1)
-		return -EPERM;
-	arr->va_stack->ls_rec[arr->va_stack->ls_sp].lsr_addr  = addr;
-	arr->va_stack->ls_rec[arr->va_stack->ls_sp].lsr_index = index;
-	return 0;
-}
-
-M0_INTERNAL int pop(struct m0_varr *arr, void **addr, uint64_t *index)
-{
-	if (arr->va_stack->ls_sp == -1)
-		return -EPERM;
-	*addr  = arr->va_stack->ls_rec[arr->va_stack->ls_sp].lsr_addr;
-	*index = arr->va_stack->ls_rec[arr->va_stack->ls_sp].lsr_index;
-	--arr->va_stack->ls_sp;
-	return 0;
-}
-
 /* Returns logarithm to the base two, for the nearest power of two
  * which is not lesser than 'size'*/
 M0_INTERNAL uint8_t nearest_power_of_two(size_t size)
@@ -142,11 +112,6 @@ M0_INTERNAL uint8_t nearest_power_of_two(size_t size)
 	return aligned_shift;
 }
 
-M0_INTERNAL bool is_power_of_two(size_t size)
-{
-	return size && !(size & (size - 1));
-}
-
 /* Returns a 64-bit integer whose last n bits are set, rest are zero */
 M0_INTERNAL uint64_t last_nbits_set(uint8_t n)
 {
@@ -155,6 +120,38 @@ M0_INTERNAL uint64_t last_nbits_set(uint8_t n)
 		~(uint64_t)0;
 }
 
+
+M0_INTERNAL int stack_init(struct m0_varr *arr)
+{
+	M0_ALLOC_PTR(arr->va_stack);
+	if (arr->va_stack == NULL)
+		return -ENOMEM;
+	M0_ALLOC_ARR(arr->va_stack->vs_srec, arr->va_depth - 1);
+	if (arr->va_stack->vs_srec == NULL)
+		return -ENOMEM;
+	arr->va_stack->vs_sp = -1;
+}
+
+M0_INTERNAL int push(struct m0_varr *arr, void *addr, uint64_t index)
+{
+	++arr->va_stack->vs_sp;
+	if (arr->va_stack->vs_sp == arr->va_depth - 1)
+		return -EPERM;
+	arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_addr  = addr;
+	arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_index = index;
+	return 0;
+}
+
+M0_INTERNAL int pop(struct m0_varr *arr, void **addr, uint64_t *index)
+{
+	if (arr->va_stack->vs_sp == -1)
+		return -EPERM;
+	*addr  = arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_addr;
+	*index = arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_index;
+	--arr->va_stack->vs_sp;
+	return 0;
+}
+
 M0_INTERNAL unsigned long varr_obj_nr_in_buff(const struct m0_varr *arr)
 {
 	M0_PRE(arr != NULL);
@@ -163,11 +160,13 @@ M0_INTERNAL unsigned long varr_obj_nr_in_buff(const struct m0_varr *arr)
 }
 
 M0_INTERNAL uint64_t cont_nr_for_objs(unsigned long nr,
-				      unsigned long obj_nr_in_1_cont)
+				      unsigned long obj_nr_in_1_cont,
+				      uint8_t obj_nr_shift)
 {
 	M0_PRE(obj_nr_in_1_cont > 0);
 
-	return nr / obj_nr_in_1_cont + (nr % obj_nr_in_1_cont == 0 ? 0 : 1);
+	return safe_bitshift(nr, unsigned long, obj_nr_shift, ">>") +
+		(nr & (obj_nr_in_1_cont - 1) == 0 ? 0 : 1);
 }
 
 M0_INTERNAL bool within_tree_height(const struct m0_varr *arr, int level)
@@ -180,23 +179,41 @@ M0_INTERNAL bool within_tree_width(const struct m0_varr *arr, uint64_t child_id)
 	return child_id < arr->va_bufptr_nr;
 }
 
-M0_INTERNAL bool cache_fetch(struct m0_varr *arr, uint64_t index, void *holder)
+M0_INTERNAL bool cache_fetch(struct m0_varr *arr, uint64_t index,
+			     unsigned long *holder)
 {
-	return arr->va_cache->c_buff != NULL				 &&
-	       arr->va_cache->c_first_index <= index		         &&
-	       index <= (arr->va_cache->c_last_index) &&
-	       (unsigned long *)*holder = arr->va_cache->c_buff + index -
-			arr->va_cache->c_first_index;
+	return arr->va_cache->vc_buff != NULL				 &&
+	       arr->va_cache->vc_first_index <= index		         &&
+	       index <= (arr->va_cache->vc_last_index)			 &&
+	       /* Deliberately put single '=' sign. */
+	       ((unsigned long *)*holder = arr->va_cache->vc_buff + index -
+			arr->va_cache->vc_first_index);
+}
+
+M0_INTERNAL void cache_update(struct m0_varr *arr, void *holder,
+			      uint64_t start_index)
+{
+	M0_PRE(arr != NULL);
+	M0_PRE(start_index < arr->va_nr - 1);
+
+	arr->va_cache->vc_buff = holder;
+	arr->va_cache->vc_first_index = start_index;
+	arr->va_cache->vc_last_index = min64u(start_index +
+					      safe_bitshift((uint64_t)1,
+							    uint64_t,
+						            arr->va_buf_shift -
+							    arr->va_obj_shift,
+							    "<<"),
+					      arr->va_nr - 1);
 }
 
 static bool varr_invariant(const struct m0_varr *arr)
 {
-	return
-		m0_varr_bob_check(arr) &&
-		arr->va_nr > 0 &&
-		arr->va_alloc > 0 &&
-		arr->va_sizeof > 0 &&
-		M0_0VEC_ALIGN % arr->va_sizeof == 0;
+	return  m0_varr_bob_check(arr) &&
+		arr->va_nr > 0         &&
+		arr->va_alloc > 0      &&
+		arr->va_obj_shift > 0  &&
+		arr->va_buf_shift >= arr->va_obj_shift;
 }
 
 M0_INTERNAL int m0_varr_init(struct m0_varr *arr,
@@ -214,11 +231,15 @@ M0_INTERNAL int m0_varr_init(struct m0_varr *arr,
 
 	arr->va_nr              = nr;
 	arr->va_alloc           = arr->va_dealloc = 0;
+	/* Can result into padding if object and buffer sizes are not integer
+	 * powers of two. */
 	arr->va_obj_shift       = nearest_power_of_two(size);
 	arr->va_buf_shift       = nearest_power_of_two(bufsize);
+	arr->va_bufsize		= safe_bitshift((size_t)1, size_t,
+						arr->va_buf_shift, "<<");
 	arr->va_bufptr_nr_shift = arr->va_buf_shift -
 		neares_power_of_two(VA_TNODEPTR_SIZE);
-	arr->va_bufptr_nr       = safe_bitshift((uint64_t) 1, uint64_t,
+	arr->va_bufptr_nr       = safe_bitshift((uint64_t)1, uint64_t,
 						arr->va_bufptr_nr_shift, "<<");
 
 	/*
@@ -234,8 +255,9 @@ M0_INTERNAL int m0_varr_init(struct m0_varr *arr,
 	for (i = 0; i < VA_TNODE_NR; ++i)
 		arr->va_tree[i] = NULL;
 
-	buff_nr         = cont_nr_for_objs(nr, varr_obj_nr_in_buff(arr));
-	arr->va_depth   = level_find(arr, buff_nr);
+	buff_nr = cont_nr_for_objs(nr, varr_obj_nr_in_buff(arr),
+				   arr->va_buf_shift - arr->va_obj_shift);
+	arr->va_depth = level_find(arr, buff_nr);
 	if (arr->va_depth > 1) {
 		rc = stack_init(arr);
 	}
@@ -259,7 +281,7 @@ M0_INTERNAL void m0_varr_fini(struct m0_varr *arr)
 
 	varr_buffers_dealloc(arr, cont_nr_for_objs(arr->va_nr,
 			     varr_obj_nr_in_buff(arr)));
-	m0_free(arr->va_stack->ls_rec);
+	m0_free(arr->va_stack->vs_srec);
 	m0_free(arr->va_stack);
 	m0_free(arr->va_cache);
 	M0_POST(arr->va_alloc == arr->va_dealloc);
@@ -270,8 +292,8 @@ M0_INTERNAL void m0_varr_fini(struct m0_varr *arr)
 	arr->va_alloc  = arr->va_dealloc = 0;
 }
 
-M0_INTERNAL unsigned long *m0_varr_buffer(const struct m0_varr *arr,
-					  uint64_t index)
+M0_INTERNAL unsigned long *varr_buffr(const struct m0_varr *arr,
+				      uint64_t index)
 {
 	uint32_t       level;
 	uint64_t       obj_mask;
@@ -284,25 +306,22 @@ M0_INTERNAL unsigned long *m0_varr_buffer(const struct m0_varr *arr,
 
 	if (cache_fetch(arr, index, &holder))
 		return holder;
-	obj_mask  = last_nbits_set(arr->va_obj_shift);
-	buff_mask = last_nbits_set(arr->va_buff_shift);
-	index_local = index;
-	index_local = safe_bitshift(index_local, uint64_t,
+	obj_mask    = last_nbits_set(arr->va_obj_shift);
+	buff_mask   = last_nbits_set(arr->va_buff_shift);
+	index_local = safe_bitshift(index, uint64_t,
 				    arr->va_obj_shift + (arr->va_depth - 1) *
 				    arr->va_buf_shift, ">>");
 	holder = arr->va_tree[index_local];
-	index_local = index;
-	for (level = 1; level <= arr->va_depth - 1; ++level,
-	     index_local = index) {
-		index_local = safe_bitshift(index_local, uint64_t,
+	for (level = 1; level <= arr->va_depth - 1; ++level) {
+		index_local = safe_bitshift(index, uint64_t,
 					    arr->va_obj_shif +
-					    (arr->va_depth - level) *
+					    (arr->va_depth - level - 1) *
 					    arr->va_buf_shift, ">>");
 		index_local &= buff_mask;
 		holder += index;
 		/* Dereferences the buffer pointer at given offset. */
-		M0_ASSERT((unsigned long *)*holder!= NULL);
 		holder = (unsigned long *)*holder;
+		M0_ASSERT(holder != NULL);
 	}
 	cache_update(arr, holder, index & (~obj_mask));
 	M0_POST_EX(varr_invariant(arr));
@@ -333,7 +352,7 @@ static int buffers_helper(struct m0_varr     *arr,
 				break;
 		} else {
 			M0_ASSERT((unsigned long *)*h != NULL);
-			m0_varr_buf_free((void *)*h);
+			m0_varr_buf_free((void *)*h, arr->va_bufsize);
 			*h = (unsigned long)NULL;
 		}
 	}
@@ -367,14 +386,18 @@ static void varr_buffers_dealloc(struct m0_varr *arr,
 	M0_PRE(arr     != NULL);
 	M0_PRE(buff_nr  > 0);
 
-	arr->va_stack->ls_sp == -1;
-	for (done = 0, done_pt = 0, node = 0, child_id = 0; node < VA_TNODE_NR
-	     && done < buff_nr; ++node, done_pt = 0, level = 1, child_id = 0) {
+	arr->va_stack->vs_sp == -1;
+	for (done = 0, done_pt = 0, node = 0, child_id = 0, level = 1;
+	     node < VA_TNODE_NR && done < buff_nr;
+	     ++node, done_pt = 0, level = 1, child_id = 0) {
 		holder = arr->va_tree[node];
 		buff_nr_pn = min64u(max_buff_nr_till_lev_n_pn(arr, 1),
 				    buff_nr - done);
 		if (arr->va_depth == 1) {
 			done_pt = 1;
+			rc = buffers_helper(arr, arr->va_tree[node],
+					    1, BA_DEALLOC);
+			M0_ASSERT(rc == 0);
 			continue;
 		} else {
 			rc = push(arr, &arr->va_tree[node], 0);
@@ -409,10 +432,10 @@ static void varr_buffers_dealloc(struct m0_varr *arr,
 			--level;
 			++holder;
 			++child_id;
-			M0_ASSERT(arr->va_stack->ls_sp == level - 1);
+			M0_ASSERT(arr->va_stack->vs_sp == level - 1);
 		}
 		done += done_pt;
-		M0_ASSERT(arr->va_stack->ls_sp == -1);
+		M0_ASSERT(arr->va_stack->vs_sp == -1);
 	}
 }
 
@@ -433,8 +456,9 @@ static int varr_buffers_alloc(struct m0_varr *arr,
 	M0_PRE(arr     != NULL);
 	M0_PRE(buff_nr  > 0);
 
-	for (done = 0, done_pt = 0, node = 0, child_id = 0; node < VA_TNODE_NR
-	     && done < buff_nr; ++node, done_pt = 0, level = 1) {
+	for (done = 0, done_pt = 0, node = 0, child_id = 0, level = 1;
+	     node < VA_TNODE_NR && done < buff_nr;
+	     ++node, done_pt = 0, level = 1) {
 		buff_nr_pn = min64u(max_buff_nr_till_lev_n_pn(arr, 1),
 				    buff_nr - done);
 		rc = buffers_helper(arr, arr->va_tree[node], 1, BA_ALLOC);
@@ -480,11 +504,11 @@ static int varr_buffers_alloc(struct m0_varr *arr,
 			--level;
 			++holder;
 			++child_id;
-			M0_ASSERT(arr->va_stack->ls_sp == level - 1);
+			M0_ASSERT(arr->va_stack->vs_sp == level - 1);
 		}
 		done += done_pt;
 		/* Reset the stack pointer before parsing next tree. */
-		arr->va_stack->ls_sp = -1;
+		arr->va_stack->vs_sp = -1;
 	}
 end:
 	M0_POST(ergo(rc == 0, done == buff_nr));
@@ -544,7 +568,7 @@ M0_INTERNAL uint32_t level_find(const struct m0_varr *arr,
 	for (level = 0; !found; ++level)
 		if (pg <= safe_bitshift((uint32_t)1, uint32_t,
 					arr->va_bufptr_nr_shift*level +
-					VA_NODE_SHIFT),"<<")
+					VA_NODE_SHIFT, "<<"))
 			found = true;
 	return level + 1;
 }
diff --git a/lib/varr.h b/lib/varr.h
index 7f21976..7907a5e 100644
--- a/lib/varr.h
+++ b/lib/varr.h
@@ -79,8 +79,8 @@
 struct m0_varr;
 struct varr_stack;
 
-M0_EXTERN void *m0_varr_buf_alloc(int bufsize);
-M0_EXTERN void  m0_varr_buf_free(void *buf, int bufsize);
+M0_EXTERN void *m0_varr_buf_alloc(size_t bufsize);
+M0_EXTERN void  m0_varr_buf_free(void *buf, size_t bufsize);
 M0_EXTERN bool  m0_varr_size_is_valid(const struct m0_varr *arr);
 
 enum {
@@ -97,10 +97,12 @@ struct m0_varr {
 	/** Number of elements in array. */
 	uint64_t         va_nr;
 
-	/** Size of object type stored in m0_varr. */
+	/** Log of object-size to the base two. */
 	uint8_t          va_obj_shift;
 
 	/** Size of buffer which is used to store objects from array. */
+	size_t		 va_bufsize;
+	/** Log of va_bufsize to the base 2. */
 	uint8_t          va_buf_shift;
 
 	/** Level depth of tree proportional to number of objects stored. */
@@ -165,7 +167,7 @@ M0_INTERNAL unsigned long varr_obj_nr_in_buff(const struct m0_varr *arr);
 M0_INTERNAL uint32_t level_find(const struct m0_varr *arr, uint64_t pg);
 
 /**
- * Returns the buffer in which given object with index id falls.
+ * Returns address of an object with having index as 'index'.
  * @pre  arr != NULL && index < arr->va_nr.
  * @post varr_invariant(arr).
  */
@@ -177,8 +179,7 @@ M0_INTERNAL unsigned long *varr_buffer(const struct m0_varr *arr,
 	type *__ptr;						\
 								\
 	__ptr  = (type *)varr_buffer(arr, index);		\
-	__ptr += index % varr_obj_nr_in_buff(arr);		\
-	M0_POST(__ptr != NULL);					\
+	__ptr += index & (varr_obj_nr_in_buff(arr) - 1);		\
 	__ptr;							\
 })
 
@@ -198,16 +199,16 @@ M0_INTERNAL void m0_varr_fini(struct m0_varr *arr);
 	type          *ptr;					\
 	unsigned long *buffer;					\
 								\
-	buff_nr = cont_nr_for_objs(arr->va_nr,			\
-				   varr_obj_nr_in_buff(arr));	\
-	for (cnt = 0; cnt < buff_nr; ++cnt) {			\
-		buffer = varr_buffer(arr, cnt);			\
+	for (oi = 0; oi < arr->va_nr; ++oi) {			\
+								\
+		ptr  = (type*)m0_varr_buffer(arr, cnt);		\
+		ptr += index & varr_obj_nr_in_buff(arr)		\
 		for (oi = 0; oi < min64u(varr_obj_nr_in_buff(arr),\
 		     arr->va_nr - done); ++oi, ++done) {	\
 			ptr = (type *)buffer;			\
 			ptr += oi;				\
 
-#define m0_varr_endfor } } })
+#define m0_varr_endfor } } )
 
 #endif /* __MERO_LIB_VIRTUAL_ARRAY_H__ */
 
-- 
1.8.3.2

