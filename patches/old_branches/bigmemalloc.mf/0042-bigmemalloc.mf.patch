From 234305df809dcb15d7bf2c051d541b5800155b8b Mon Sep 17 00:00:00 2001
From: Nachiket Sahasrabuddhe <nachiket_sahasrabuddhe@xyratex.com>
Date: Mon, 21 Oct 2013 19:48:06 +0530
Subject: [PATCH 42/50] bigmemalloc.mf -Fixed couple of issues in cache_fetch()
 and cache_update(). -Fixed an issue in m0_varr_ele_get(). -Replaced
 log_radix() with children_of_level(). -Fixed an issue in index_within_level()

---
 lib/varr.c | 147 +++++++++++++++++++++++++++++++------------------------------
 1 file changed, 75 insertions(+), 72 deletions(-)

diff --git a/lib/varr.c b/lib/varr.c
index be03924..9acc46e 100644
--- a/lib/varr.c
+++ b/lib/varr.c
@@ -54,7 +54,8 @@ M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr);
  * buffers to be alocated. */
 M0_INTERNAL uint32_t depth_find(const struct m0_varr *arr, uint64_t buff_nr);
 /* Returns log to the base two for the radix associated with a level. */
-M0_INTERNAL uint8_t log_radix(const struct m0_varr *arr, uint32_t level);
+M0_INTERNAL uint32_t children_of_level(const struct m0_varr *arr,
+				       uint32_t level);
 /* Returns the yongest  common ancestor of two children within a tree */
 M0_INTERNAL uint32_t common_ancestor(const struct m0_varr *arr,
 				     uint64_t target_idx, uint64_t src_idx);
@@ -72,10 +73,10 @@ M0_INTERNAL void completed_leaves_update(struct m0_varr_cursor *cursor,
 /* Fetches address of an object with index 'index' within the array. Returns
  * 'true' when address is present in the cache. Returns 'false' otherwise. */
 M0_INTERNAL bool cache_fetch(const struct m0_varr *arr, uint64_t index,
-			     unsigned long **holder);
+			     void **holder);
 /* Updates the cache with address of a buffer and range of indices residing
  * in it. */
-M0_INTERNAL void cache_update(struct m0_varr *arr, unsigned long *holder,
+M0_INTERNAL void cache_update(struct m0_varr *arr, void *holder,
 			      uint64_t start_index);
 /* Returns number of objects that can fit in a single buffer. */
 M0_INTERNAL unsigned long varr_obj_nr_in_buff(const struct m0_varr *arr);
@@ -113,9 +114,7 @@ M0_INTERNAL int m0_varr_init(struct m0_varr *arr, uint64_t nr, size_t size,
 	uint64_t buff_nr;
 
 	M0_PRE(arr != NULL);
-	M0_PRE(nr > 0);
-	M0_PRE(size > 0);
-	M0_PRE(bufsize > 0);
+	M0_PRE(nr > 0 && size > 0 && bufsize > 0);
 
 	arr->va_nr              = nr;
 	/* Can result into padding if object and buffer sizes are not integer
@@ -232,18 +231,18 @@ M0_INTERNAL int varr_buffers_alloc(struct m0_varr *arr)
 {
 	struct m0_varr_cursor  cursor;
 	int		       rc;
-	unsigned long	       holder;
+	void		      *holder;
 
 	rc = m0_varr_cursor_init(&cursor, arr, ALLOC);
 	if (rc != 0)
 		goto end;
 	do {
-		holder = (unsigned long)m0_varr_buf_alloc(arr->va_bufsize);
-		if ((unsigned long *)holder == NULL) {
+		holder = m0_varr_buf_alloc(arr->va_bufsize);
+		if (holder == NULL) {
 			rc = -ENOMEM;
 			goto end;
 		}
-		*(void **)m0_varr_cursor_get(&cursor) = (void*)holder;
+		*(void **)m0_varr_cursor_get(&cursor) = holder;
 	} while (m0_varr_cursor_next(&cursor));
 end:
 	return rc;
@@ -254,7 +253,7 @@ M0_INTERNAL int m0_varr_cursor_init(struct m0_varr_cursor *cursor,
 				    enum m0_varr_cursor_trav traversal)
 {
 	struct m0_varr_path_element *pe;
-	unsigned long		    *buf;
+	void			    *buf;
 	void			    *root;
 	uint32_t		     depth;
 
@@ -276,33 +275,33 @@ M0_INTERNAL int m0_varr_cursor_init(struct m0_varr_cursor *cursor,
 	depth = traversal == ITERATE ? arr->va_depth : traversal == ALLOC ? 1 :
 						        arr->va_depth - 1;
 	while (cursor->vc_depth < depth) {
-		buf = (unsigned long *)pe->vp_buf;
+		buf = pe->vp_buf;
 		if (buf != NULL) {
 			++pe;
 			++cursor->vc_depth;
-			pe->vp_buf   = (void *)(*buf);
+			pe->vp_buf   = *(void **)buf;
 			pe->vp_idx   = 0;
-			pe->vp_width =
-				safe_bitshift((uint32_t)1,
-					      log_radix(arr, cursor->vc_depth),
-					      <<);
+			pe->vp_width = children_of_level(arr,
+							 cursor->vc_depth);
 		} else
 			return -EINVAL;
 	}
 	return 0;
 }
 
-M0_INTERNAL uint8_t log_radix(const struct m0_varr *arr, uint32_t level)
+M0_INTERNAL uint32_t children_of_level(const struct m0_varr *arr,
+				       uint32_t level)
 {
 	M0_PRE(arr != NULL);
 	M0_PRE(level <= arr->va_depth);
 
 	if (level <= 1)
-		return level == 1 ? M0_VA_TNODE_NR_SHIFT : 0;
+		return level == 1 ? M0_VA_TNODE_NR : 1;
 	else
 		return level == arr->va_depth ?
-			arr->va_buf_shift - arr->va_obj_shift :
-			arr->va_buf_shift - arr->va_bufptr_nr_shift;
+			safe_bitshift((uint32_t)1,
+				      arr->va_buf_shift - arr->va_obj_shift,
+				      <<) : arr->va_bufptr_nr;
 }
 
 M0_INTERNAL void* m0_varr_cursor_get(struct m0_varr_cursor *cursor)
@@ -326,8 +325,10 @@ M0_INTERNAL int m0_varr_cursor_move(struct m0_varr_cursor *cursor,
 	uint32_t		     index_in_level;
 
 	M0_PRE(cursor != NULL);
-	M0_PRE(d <= cursor->vc_arr->va_depth);
-	M0_PRE(ergo(cursor->vc_trav != ITERATE, inc == 1));
+	M0_PRE(ergo(cursor->vc_trav == ITERATE,
+		    d == cursor->vc_arr->va_depth));
+	M0_PRE(ergo(cursor->vc_trav != ITERATE, inc == 1 &&
+		    d < cursor->vc_arr->va_depth));
 
 	pe = &cursor->vc_path[d];
 	switch (cursor->vc_trav) {
@@ -335,6 +336,8 @@ M0_INTERNAL int m0_varr_cursor_move(struct m0_varr_cursor *cursor,
 		target_idx = cursor->vc_done + inc;
 		if (target_idx >= cursor->vc_arr->va_nr)
 			goto end;
+		else if (target_idx == cursor->vc_done)
+			goto next;
 		common_anct = common_ancestor(cursor->vc_arr, target_idx,
 					      cursor->vc_done);
 		while (d > common_anct) {
@@ -362,64 +365,55 @@ M0_INTERNAL int m0_varr_cursor_move(struct m0_varr_cursor *cursor,
 		/* Increments of cursor->vc_done are in the quantum of objects
 		 * in a single leaf buffer. Hence strict equality constraint is
 		 * avoided below. */
-		if (cursor->vc_done > cursor->vc_arr->va_nr)
+		if (cursor->vc_done >= cursor->vc_arr->va_nr)
 			goto end;
-		if (cursor->vc_depth < cursor->vc_arr->va_depth - 1) {
+		if (d < cursor->vc_arr->va_depth - 1) {
 			buf = pe->vp_buf;
 			++pe;
-			++cursor->vc_depth;
+			++d;
 			pe->vp_buf = *(void **)buf;
 			pe->vp_idx = 0;
-			pe->vp_width =
-				safe_bitshift((uint32_t)1,
-					      log_radix(cursor->vc_arr,
-						        cursor->vc_depth),
-					      <<);
+			pe->vp_width = children_of_level(cursor->vc_arr, d);
 		} else {
 			completed_leaves_update(cursor, d, 1);
-			while (!within_tree_width(cursor, cursor->vc_depth,
-						  pe->vp_idx + 1) &&
-				cursor->vc_depth > 0) {
+			while (!within_tree_width(cursor, d, pe->vp_idx + 1) &&
+				d > 0) {
 				--pe;
-				--cursor->vc_depth;
-				d = cursor->vc_depth;
+				--d;
 			}
 			++pe->vp_idx;
-			pe->vp_buf = buff_incr(cursor->vc_arr,
-					       cursor->vc_depth, pe->vp_buf,
+			pe->vp_buf = buff_incr(cursor->vc_arr, d, pe->vp_buf,
 					       1);
 		}
+		cursor->vc_depth = d;
 		if (cursor->vc_depth != 0)
 			goto next;
 		else
 			goto end;
 		break;
 	case DEALLOC:
-		if (cursor->vc_depth == 0)
+		if (d == 0)
 			goto end;
-		if (cursor->vc_depth == cursor->vc_arr->va_depth - 1)
-			completed_leaves_update(cursor, cursor->vc_depth, 1);
-		if (within_tree_width(cursor, cursor->vc_depth,
-				      pe->vp_idx + 1) &&
-		    buff_incr(cursor->vc_arr, cursor->vc_depth,
-			      pe->vp_buf, 1) != NULL) {
+		if (d == cursor->vc_arr->va_depth - 1)
+			completed_leaves_update(cursor, d, 1);
+		if (within_tree_width(cursor, d, pe->vp_idx + 1) &&
+		    buff_incr(cursor->vc_arr, d, pe->vp_buf, 1) != NULL) {
 			++pe->vp_idx;
-			pe->vp_buf = buff_incr(cursor->vc_arr,
-					       cursor->vc_depth,
-					       pe->vp_buf, 1);
-			while (cursor->vc_depth <
-			       cursor->vc_arr->va_depth - 1 &&
+			pe->vp_buf = buff_incr(cursor->vc_arr, d, pe->vp_buf,
+					       1);
+			while (d < cursor->vc_arr->va_depth - 1 &&
 			       *(void **)pe->vp_buf != NULL) {
 				buf = pe->vp_buf;
 				++pe;
-				++cursor->vc_depth;
+				++d;
 				pe->vp_buf = *(void **)buf;
 				pe->vp_idx = 0;
 			}
 		} else {
 			--pe;
-			--cursor->vc_depth;
+			--d;
 		}
+		cursor->vc_depth = d;
 		if (cursor->vc_depth != 0)
 			goto next;
 		else
@@ -456,7 +450,8 @@ M0_INTERNAL uint32_t common_ancestor(const struct m0_varr *arr,
 M0_INTERNAL uint32_t index_within_level(const struct m0_varr *arr,
 					uint64_t target_idx, uint32_t depth)
 {
-	uint64_t  shift;
+	uint64_t shift;
+	uint64_t mask_bits;
 
 	M0_PRE(arr != NULL);
 	M0_PRE(depth <= arr->va_depth);
@@ -464,8 +459,11 @@ M0_INTERNAL uint32_t index_within_level(const struct m0_varr *arr,
 	shift = depth == arr->va_depth ? 0 :
 		arr->va_buf_shift - arr->va_obj_shift +
 		(arr->va_depth - depth - 1) * arr->va_bufptr_nr_shift;
+	mask_bits = depth == arr->va_depth ?
+		arr->va_buf_shift - arr->va_obj_shift :
+		arr->va_bufptr_nr_shift;
 	target_idx  = safe_bitshift(target_idx, shift, >>);
-	target_idx &= last_nbits_set(shift);
+	target_idx &= last_nbits_set(mask_bits);
 	return target_idx;
 }
 
@@ -495,8 +493,7 @@ M0_INTERNAL void completed_leaves_update(struct m0_varr_cursor *cursor,
 	else
 		cursor->vc_done += inc *
 			varr_obj_nr_in_buff(cursor->vc_arr) *
-			max_buff_nr_till_lev_n_pn(cursor->vc_arr,
-					depth);
+			max_buff_nr_till_lev_n_pn(cursor->vc_arr, depth);
 }
 
 /*
@@ -575,20 +572,22 @@ M0_INTERNAL bool varr_invariant(const struct m0_varr *arr)
 
 M0_INTERNAL void *m0_varr_ele_get(struct m0_varr *arr, uint64_t index)
 {
-	uint32_t       level;
-	unsigned long *holder;
+	uint32_t  level;
+	void	 *holder;
 
 	M0_PRE(arr != NULL);
 	M0_PRE(index < arr->va_nr);
 
 	if (cache_fetch(arr, index, &holder))
 		goto end;
-	holder = (unsigned long *)arr->va_tree;
-	for (level = 0; level <= arr->va_depth - 1; ++level) {
-		holder += index_within_level((const struct m0_varr *) arr,
-					     index, level);
+	holder = (void *)arr->va_tree;
+	for (level = 1; level <= arr->va_depth - 1; ++level) {
+
+		holder =  buff_incr(arr, level, holder,
+				    index_within_level((const struct m0_varr *)
+						       arr, index, level));
 		/* Dereferences the buffer pointer at given offset. */
-		holder = (unsigned long *)*holder;
+		holder = *(void **)holder;
 		M0_ASSERT(holder != NULL);
 	}
 	cache_update(arr, holder, index);
@@ -596,29 +595,33 @@ M0_INTERNAL void *m0_varr_ele_get(struct m0_varr *arr, uint64_t index)
 end:
 	/* Adds to holder the index of required object within a buffer */
 	return buff_incr(arr, arr->va_depth, holder,
-			(index & (varr_obj_nr_in_buff(arr) - 1)));
+			 index_within_level((const struct m0_varr *) arr,
+					    index, arr->va_depth));
 }
 
 M0_INTERNAL bool cache_fetch(const struct m0_varr *arr, uint64_t index,
-			     unsigned long **holder)
+			     void **holder)
 {
 	return arr->va_cache->vc_buff != NULL				 &&
 		arr->va_cache->vc_first_index <= index		         &&
 		index <= (arr->va_cache->vc_last_index)			 &&
 		/* Deliberately put single '=' sign. */
-		(*holder = arr->va_cache->vc_buff + index -
-		 arr->va_cache->vc_first_index);
+		(*holder = arr->va_cache->vc_buff);
 }
 
-M0_INTERNAL void cache_update(struct m0_varr *arr, unsigned long *holder,
-			      uint64_t start_index)
+M0_INTERNAL void cache_update(struct m0_varr *arr, void *holder,
+			      uint64_t index)
 {
+	uint64_t index_in_level;
+
 	M0_PRE(arr != NULL);
-	M0_PRE(start_index <= arr->va_nr - 1);
+	M0_PRE(index <= arr->va_nr - 1);
 
+	index_in_level = index_within_level((const struct m0_varr *)arr,
+					    index, arr->va_depth);
 	arr->va_cache->vc_buff = holder;
-	arr->va_cache->vc_first_index = start_index;
-	arr->va_cache->vc_last_index = min64u(start_index +
+	arr->va_cache->vc_first_index = index - index_in_level;
+	arr->va_cache->vc_last_index = min64u(arr->va_cache->vc_first_index +
 					      safe_bitshift((uint64_t)1,
 							    arr->va_buf_shift -
 							    arr->va_obj_shift,
-- 
1.8.3.2

