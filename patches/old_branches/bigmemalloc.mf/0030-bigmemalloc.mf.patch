From 15de0066a17caede6be96dc36cd9651469ad246d Mon Sep 17 00:00:00 2001
From: Nachiket Sahasrabuddhe <nachiket_sahasrabuddhe@xyratex.com>
Date: Fri, 27 Sep 2013 10:42:57 +0530
Subject: [PATCH 30/50] bigmemalloc.mf -First cut implementation and
 incorporation of cursor is ready. -Moving ahead to incorporate cursor_move()

---
 lib/varr.c | 337 ++++++++++++++++---------------------------------------------
 lib/varr.h |  37 ++++---
 2 files changed, 109 insertions(+), 265 deletions(-)

diff --git a/lib/varr.c b/lib/varr.c
index 73d451e..e6cba3b 100644
--- a/lib/varr.c
+++ b/lib/varr.c
@@ -81,7 +81,28 @@ struct m0_varr_cursor {
 M0_INTERNAL bool within_tree_width(const struct m0_varr_cursor *cursor,
 				   uint32_t depth, uint32_t index)
 {
-	return index < cursor->vc_path[depth - 1].vp_width;
+
+	return index < cursor->pe[depth].vp_width &&
+		cursor->vc_done < cursor->vc_arr->va_nr;
+}
+
+M0_INTERNAL uint32_t children_of_level(const struct m0_varr *arr,
+				       uint32_t level)
+{
+	uint32_t bit_shift;
+
+	M0_PRE(arr != NULL);
+	M0_PRE(level <= arr->va_depth);
+
+	if (level <= 1)
+		return level == 1 ? VA_TNODE_NR : 1;
+	else {
+		bit_shift = level == arr->va_depth ?
+			arr->va_buf_shift - arr->va_obj_shift :
+			arr->va_buf_shift - arr->va_buf_ptr_nr_shift;
+
+		return safe_bitshift((uint32_t)1, bit_shift, "<<");
+	}
 }
 
 M0_INTERNAL int m0_varr_cursor_init(struct m0_varr_cursor *cursor,
@@ -89,52 +110,41 @@ M0_INTERNAL int m0_varr_cursor_init(struct m0_varr_cursor *cursor,
 				    enum m0_varr_cursor_trav traversal)
 {
 	struct m0_varr_path_element *pe;
-	uint32_t		     depth;
 	unsigned long		    *buf;
+	uint32_t		     d = 0;
 
 	M0_PRE(cursor != NULL);
 	M0_PRE(arr != NULL);
 	M0_PRE(depth < arr->va_depth);
 
-	pe		 = &cursor->vc_path[0];
 	cursor->vc_arr   = arr;
 	cursor->vc_trav  = traversal;
+	cursor->vc_depth = 0;
+	cursor->vc_done  = 0;
+	pe		 = &cursor->vc_path[0];
 	pe->vp_idx	 = 0;
-	pe->vp_buf	 = arr->va_tree;
+	pe->vp_buf	 = (void *)arr->va_tree;
+	pe->vp_width	 = 1;
 
-	switch (traversal) {
-	case PRE_ORDER:
-		buf	   = pe->vp_buf;
-		++pe;
-		pe->vp_buf = (unsigned long *)*buf;
-		pe->vp_idx = 0;
-		cursor->vc_depth = 1;
-		break;
-	case ITERATE:
-		cursor->vc_depth = depth;
-		while (d < depth) {
-			buf = pe->vp_buf;
-			++pe;
-			pe->vp_idx = 0;
-			if (buf != NULL)
-				pe->vp_buf = (unsigned long *)*buf;
-			else
-				return -ENOMEM;
-			++d;
-		}
-		break;
-	case POST_ORDER:
-		while (d < arr->va_depth - 1) {
-			buf = pe->vp_buf;
+	while (cursor->vc_depth < depth) {
+		buf = pe->vp_buf;
+		if (buf != NULL) {
 			++pe;
 			pe->vp_idx = 0;
-			if (buf != NULL)
-				pe->vp_buf = (unsigned long *)*buf;
-			else
-				return -ENOMEM;
-			++d;
+			pe->vp_width = children_of_level(arr,
+							 cursor->vc_depth);
+			/*TODO*/
+			pe->vp_buf = (void *)(*buf);
 		}
-		break;
+		else
+			return -EINVAL;
+		++cursor->vc_depth;
+		++d;
+	}
+	/* Pre-calculate children of each level. */
+	while (d <= arr->va_depth) {
+		pe->vp_width = children_of_level(arr, d);
+		++d;
 	}
 	return 0;
 }
@@ -143,6 +153,17 @@ M0_INTERNAL void* m0_varr_cursor_get(const struct m0_varr_cursor *cursor)
 {
 	return cursor->vc_path[cursor->vc_depth].vp_buf;
 }
+
+M0_INTERNAL bool m0_varr_cursor_move(struct m0_varr_cursor *cursor,
+				     uint32_t inc)
+{
+	uint32_t i;
+
+	for (i = 0; i < inc && m0_varr_cursor_next(&cursor); ++i)
+		;
+	return i == inc;
+}
+
 M0_INTERNAL int m0_varr_cursor_next(struct m0_varr_cursor *cursor)
 {
 
@@ -163,12 +184,16 @@ M0_INTERNAL int m0_varr_cursor_next(struct m0_varr_cursor *cursor)
 		if (d > 0) {
 			++pe->vp_index;
 			++pe->vp_buf;
+			if (d == cursor->vc_depth)
+				cursor->vc_done +=
+				 max_buff_nr_till_lev_n_pn(cursor->vc_arr,
+							   cursor->vc_depth);
 			while (d < cursor->vc_depth) {
 				buf = pe->vp_buf;
 				++pe;
-				pe->buf = (unsigned long*)*buf;
-				pe->idx = 0;
 				++d;
+				pe->vp_buf = (unsigned long*)*buf;
+				pe->vp_idx = 0;
 			}
 			return 1;
 		} else
@@ -177,19 +202,26 @@ M0_INTERNAL int m0_varr_cursor_next(struct m0_varr_cursor *cursor)
 	case PRE_ORDER:
 		for (;d > 0 && !within_tree_width(cursor, d,
 						  pe->vp_idx + 1)
-		     --pe, --d)
-			;
+		     --pe, --d) {
+			if (d == cursor->vc_arr->va_depth - 1)
+				++cursor->vc_done;
+		}
+
 		if (d > 0) {
 			if (d == cursor->vc_depth &&
-			    d != cursor->vc_arr->va_depth - 1) {
-				buf = pe->vp_buf;
+			    d < cursor->vc_arr->va_depth - 1) {
+				buf = (unsigned long *)pe->vp_buf;
 				++pe;
-				pe->buf = (unsigned long *)*buf;
+				buf = (unsigned long *)*buf;
+				pe->buf = (void *)buf;
 				pe->idx = 0;
 				++cursor->vc_depth;
 			} else {
 				++pe->vp_idx;
 				++pe->vp_buf;
+				cursor->vc_depth = d;
+				if (d == cursor->vc_arr->va_depth - 1)
+					++cursor->vc_done;
 			}
 			return 1;
 		} else
@@ -197,6 +229,8 @@ M0_INTERNAL int m0_varr_cursor_next(struct m0_varr_cursor *cursor)
 
 		break;
 	case POST_ORDER:
+		if (d == cursor->vc_arr->va_depth)
+			++cursor->vc_done;
 		if (within_tree_width(cursor, d,
 				      pe->vp_idx + 1)) {
 			++pe->vp_idx;
@@ -204,6 +238,7 @@ M0_INTERNAL int m0_varr_cursor_next(struct m0_varr_cursor *cursor)
 		} else {
 			--pe;
 			--d;
+			cursor->vc_depth = d;
 		}
 		if (d > 0)
 			return 1;
@@ -219,7 +254,7 @@ M0_INTERNAL int varr_buffers_alloc(struct m0_varr *arr, uint64_t buf_nr)
 	int		      rc;
 	unsigned long	      holder;
 
-	rc = m0_varr_cursor_init(&cursor, arr, 0, PRE_ORDER);
+	rc = m0_varr_cursor_init(&cursor, arr, 1, PRE_ORDER);
 	if (rc != 0)
 		goto end;
 	do {
@@ -228,7 +263,7 @@ M0_INTERNAL int varr_buffers_alloc(struct m0_varr *arr, uint64_t buf_nr)
 			rc = -ENOMEM;
 			goto end;
 		}
-		m0_varr_cursor_get(&cursor) = (unsigned long*)holder;
+		m0_varr_cursor_get(&cursor) = (void*)holder;
 	} while (m0_varr_cursor_next(&cursor));
 end:
 	if (rc != 0)
@@ -245,27 +280,14 @@ M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr, uint64_t buf_nr)
 	rc = m0_varr_cursor_init(&cursor, arr, arr->va_depth - 1, POST_ORDER);
 	M0_ASSERT(rc == 0);
 
-	while (m0_varr_cursor_next(&cursor)) {
-		holder = m0_varr_cursor_get(&cursor);
-		m0_varr_buf_free(holder, arr->va_bufsize);
-	}
+	do {
+		holder = (unsigned long *)*m0_varr_cursor_get(&cursor);
+		/* This condition will fail when varr_buffers_alloc() has got
+		 * terminated intermittently. */
+		if ((unsigned long *)holder != NULL)
+			m0_varr_buf_free((void *)holder, arr->va_bufsize);
+	} while (m0_varr_cursor_next(&cursor));
 }
-/* A record in a stack holding address, and index associated with that address
- * within a buffer */
-struct varr_stack_rec {
-	void     *vsr_addr;
-	uint64_t  vsr_index;
-};
-
-/* Stack enables an efficient traversal of a tree during allocation and
- * deallocation processes. The maximum height to which a stack can grow is one
- * less than depth of a tree. Stack pointer vs_sp, indicates a location of
- * a top-most entry in a stack.
- */
-struct varr_stack {
-	struct varr_stack_rec *vs_rec;
-	int		       vs_sp;
-};
 
 /* Cache that holds pointer to recently accessed buffer along with range of
  * objects that reside in it.
@@ -305,38 +327,6 @@ M0_INTERNAL uint64_t last_nbits_set(uint8_t n)
 		~(uint64_t)0;
 }
 
-M0_INTERNAL int stack_init(struct m0_varr *arr)
-{
-	M0_ALLOC_PTR(arr->va_stack);
-	if (arr->va_stack == NULL)
-		return -ENOMEM;
-	M0_ALLOC_ARR(arr->va_stack->vs_rec, arr->va_depth - 1);
-	if (arr->va_stack->vs_rec == NULL)
-		return -ENOMEM;
-	arr->va_stack->vs_sp = -1;
-	return 0;
-}
-
-M0_INTERNAL int push(struct m0_varr *arr, void *addr, uint64_t index)
-{
-	++arr->va_stack->vs_sp;
-	if (arr->va_stack->vs_sp == arr->va_depth - 1)
-		return -EPERM;
-	arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_addr  = addr;
-	arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_index = index;
-	return 0;
-}
-
-M0_INTERNAL int pop(struct m0_varr *arr, void **addr, uint64_t *index)
-{
-	if (arr->va_stack->vs_sp == -1)
-		return -EPERM;
-	*addr  = arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_addr;
-	*index = arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_index;
-	--arr->va_stack->vs_sp;
-	return 0;
-}
-
 M0_INTERNAL bool cache_fetch(const struct m0_varr *arr, uint64_t index,
 			     unsigned long **holder)
 {
@@ -462,7 +452,6 @@ M0_INTERNAL bool varr_invariant(const struct m0_varr *arr)
 		arr->va_buf_shift >= arr->va_obj_shift;
 }
 
-
 M0_INTERNAL int m0_varr_init(struct m0_varr *arr, uint64_t nr, size_t size,
 			     size_t bufsize)
 {
@@ -604,162 +593,6 @@ M0_INTERNAL int buffers_helper(struct m0_varr *arr, void *holder, uint64_t nr,
 }
 
 /*
- * While deallocating buffers, the leaf node buffers are deallocated first
- * since during indexing these pages account for initial members of
- * virtual array.
- * The approach is centered towards maintaining a stack per iteration
- * which will store parent of a given level while traversing from top down.
- * The whole approach is taken in order to implement tree traversal in an
- * iterative manner rather than using recursive functions.
- * This approach is a similar to preorder traversal (left-right-root) of a
- * tree but not exactly the same.
- */
-M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr, uint64_t buff_nr)
-{
-	int            rc;
-	int            node;
-	uint64_t       level;
-	uint64_t       nr;
-	uint64_t       done;
-	uint64_t       done_pt;
-	uint64_t       child_id;
-	uint64_t       buff_nr_pn;
-	unsigned long *holder;
-
-	M0_PRE(arr != NULL);
-	M0_PRE(buff_nr > 0);
-
-	for (done = 0, done_pt = 0, node = 0, child_id = 0, level = 1;
-	     node < VA_TNODE_NR && done < buff_nr;
-	     ++node, done += done_pt, done_pt = 0, level = 1, child_id = 0) {
-		holder = arr->va_tree[node];
-		buff_nr_pn = min64u(max_buff_nr_till_lev_n_pn(arr, 1),
-				    buff_nr - done);
-		if (arr->va_depth == 1) {
-			done_pt = 1;
-			rc = buffers_helper(arr, arr->va_tree[node],
-					    1, BA_DEALLOC);
-			M0_ASSERT(rc == 0);
-			continue;
-		} else {
-			rc = push(arr, &arr->va_tree[node], 0);
-			M0_ASSERT(rc == 0);
-		}
-		while (within_tree_height(arr, level)) {
-			/*Keep going down the tree unless end (penultimate
-			 * level or NULL address) is reached. */
-			while (done_pt < buff_nr_pn &&
-			       within_tree_width(arr, child_id) &&
-			       (unsigned long *)*holder != NULL) {
-				nr = min64u(level != arr->va_depth - 1? 1 :
-					    arr->va_bufptr_nr,
-					    buff_nr_pn - done_pt);
-				if (level == arr->va_depth - 1) {
-					rc = buffers_helper(arr, holder, nr,
-							    BA_DEALLOC);
-					M0_ASSERT(rc == 0);
-					done_pt += nr;
-					break;
-				} else {
-					rc = push(arr, holder, child_id);
-					M0_ASSERT(rc == 0);
-					holder = (unsigned long *)*holder;
-					++level;
-					child_id = 0;
-				}
-			}
-			rc = pop(arr, (void **)&holder, &child_id);
-			M0_ASSERT(rc == 0);
-			rc = buffers_helper(arr, holder, 1, BA_DEALLOC);
-			M0_ASSERT(rc == 0);
-			--level;
-			++holder;
-			++child_id;
-			M0_ASSERT(arr->va_stack->vs_sp == level - 1);
-		}
-		M0_ASSERT(arr->va_stack->vs_sp == -1);
-	}
-}
-
-/* Allocates buffers for given virtual array from level 0 to varr::va_depth. */
-M0_INTERNAL int varr_buffers_alloc(struct m0_varr *arr, uint64_t buff_nr)
-{
-	int            rc;
-	int            node;
-	int            level;
-	uint64_t       nr;
-	uint64_t       done;
-	uint64_t       done_pt;
-	uint64_t       child_id;
-	uint64_t       buff_nr_pn;
-	unsigned long *holder;
-
-	M0_PRE(arr != NULL);
-	M0_PRE(buff_nr > 0);
-
-	arr->va_stack->vs_sp = -1;
-	for (done = 0, done_pt = 0, node = 0, child_id = 0, level = 1;
-	     node < VA_TNODE_NR && done < buff_nr;
-	     ++node, done += done_pt, done_pt = 0, level = 1, child_id = 0) {
-		buff_nr_pn = min64u(max_buff_nr_till_lev_n_pn(arr, 1),
-				    buff_nr - done);
-		rc = buffers_helper(arr, arr->va_tree[node], 1, BA_ALLOC);
-		if (rc != 0)
-			goto end;
-		holder = arr->va_tree[node];
-		/* If tree-depth is unity we do not use stack hence we continue
-		 * to the next tree in forest.*/
-		if (arr->va_depth == 1) {
-			done_pt = 1;
-			continue;
-		} else {
-			rc = push(arr, &arr->va_tree[node], 0);
-			if (rc != 0)
-				goto end;
-		}
-		while (done_pt < buff_nr_pn &&
-		       within_tree_height(arr, level)) {
-			/* Keep going down in the tree unless tree-depth is
-			 * reached. */
-			while (within_tree_width(arr, child_id)) {
-				nr = min64u(level != arr->va_depth - 1? 1 :
-					    arr->va_bufptr_nr,
-					    buff_nr_pn - done_pt);
-				rc = buffers_helper(arr, holder, nr,
-						    BA_ALLOC);
-				if (rc != 0)
-					goto end;
-				if (level == arr->va_depth - 1) {
-					done_pt += nr;
-					break;
-				} else {
-					rc = push(arr, holder, child_id);
-					if (rc != 0)
-						goto end;
-					holder = (unsigned long *)*holder;
-					child_id = 0;
-					++level;
-				}
-			}
-			rc = pop(arr, (void **)&holder, &child_id);
-			if (rc != 0)
-				goto end;
-			--level;
-			++holder;
-			++child_id;
-			M0_ASSERT(arr->va_stack->vs_sp == level - 1);
-		}
-		/* Reset the stack pointer before parsing the next tree. */
-		arr->va_stack->vs_sp = -1;
-	}
-end:
-	M0_POST(ergo(rc == 0, done == buff_nr));
-	if (arr->va_depth > 1)
-		arr->va_stack->vs_sp = -1;
-	return rc;
-}
-
-/*
  *  Local variables:
  *  c-indentation-style: "K&R"
  *  c-basic-offset: 8
diff --git a/lib/varr.h b/lib/varr.h
index cd44664..7c9fe13 100644
--- a/lib/varr.h
+++ b/lib/varr.h
@@ -169,22 +169,33 @@ M0_INTERNAL unsigned long *m0_varr_ele_get(struct m0_varr *arr,
 					   uint64_t index);
 
 /* Iterates over an arbitrary arithmetic progression of indices */
-#define m0_varr_for_arith_prog(arr, type, obj, start, end, inc) \
-	({							\
-	 uint64_t oi;						\
-	 type    *obj;						\
-	 M0_PRE(start < arr->va_nr && end < arr->va_nr)		\
-								\
-	 for (oi = start; oi <= end; oi += inc) {		\
-	 obj = (type*)m0_ele_get(arr, oi);			\
-
-#define m0_varr_end for_arith_prog } } )
+#define m0_varr_iter(arr, type, obj, start, end, inc)			\
+	({								\
+	 uint64_t	       idx   = (start);				\
+	 uint64_t	       end   = (end);				\
+	 uint64_t	       __inc = (inc);				\
+	 struct m0_varr	      *__arr = (arr);				\
+	 type		      *obj;					\
+	 int		       rc;					\
+	 struct m0_varr_cursor cursor;					\
+									\
+	 M0_PRE(idx < __arr->va_nr && __end < __arr->va_nr);		\
+	 M0_PRE(sizeof *obj == 1 << __arr->va_obj_shift);		\
+									\
+	 rc = m0_varr_cursor_init(&cursor, __arr,			\
+				  __arr->va_depth, ITERATE)		\
+	 M0_ASSERT(rc == 0);						\
+	 m0_varr_cursor_move(&cursor, idx);			\
+	 for (obj = m0_varr_cursor_get(&cursor);idx < end;		\
+	      idx += inc, m0_varr_cursor_move(&cursor, inc)) {		\
+
+#define m0_varr_end_iter } } )
 
 /** Iterates over whole virtual array. */
-#define m0_varr_for(arr, type, obj)				\
-	m0_varr_for_arith_prog(arr, type, obj, 0, arr->va_nr, 1)
+#define m0_varr_for(arr, type, obj)					\
+	m0_varr_iter(arr, type, obj, 0, arr->va_nr, 1)
 
-#define m0_varr_end_for m0_varr_end_for_arith_prog
+#define m0_varr_end_for m0_varr_end_iter
 
 #endif /* __MERO_LIB_VIRTUAL_ARRAY_H__ */
 
-- 
1.8.3.2

