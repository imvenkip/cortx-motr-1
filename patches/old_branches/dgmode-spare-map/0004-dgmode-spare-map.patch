From adffb9a59b6e8eeeed18c2ab8b75e3bdb4995f93 Mon Sep 17 00:00:00 2001
From: Nachiket Sahasrabuddhe <nachiket_sahasrabuddhe@xyratex.com>
Date: Mon, 13 Jan 2014 19:42:57 +0530
Subject: [PATCH 4/4] dgmode-spare-map -Basic tests of cascading run
 successfully. -These tests are part og
 m0t1fs/linux_kernel/st/m0t1fs_sns_repair_mf.sh -Many unnecessary M0_LOGs have
 been added which need to be removed. -Many unnecessary M0_FATALs are
 introduced which need to be changed  back to M0_INFO. -m0_spare_map() API
 implementation had a bug which has been fixed. -total failed-devices are now
 stored in io-request. -it is necessary to calculate total failed devices by
 iterating over entire  failure-vector. Currently we iterate over devices to
 which fops were sent.

---
 m0t1fs/linux_kernel/file.c                     | 97 +++++++++++++++++---------
 m0t1fs/linux_kernel/file_internal.h            |  5 ++
 m0t1fs/linux_kernel/st/m0t1fs_sns_repair_mf.sh | 91 +++++++++++++-----------
 sns/parity_repair.c                            |  4 +-
 4 files changed, 122 insertions(+), 75 deletions(-)

diff --git a/m0t1fs/linux_kernel/file.c b/m0t1fs/linux_kernel/file.c
index 17872fb..5103254 100644
--- a/m0t1fs/linux_kernel/file.c
+++ b/m0t1fs/linux_kernel/file.c
@@ -2227,22 +2227,22 @@ static int pargrp_iomap_dgmode_process(struct pargrp_iomap *map,
 		                       m0_bindex_t         *index,
 			               uint32_t             count)
 {
-	int                         rc = 0;
-	uint32_t                    seg;
-	uint32_t                    row;
-	uint32_t                    col;
-	uint32_t                    tgt_id;
-	m0_bindex_t                 goff;
-	struct m0_layout_enum      *le;
-	struct m0_pdclust_layout   *play;
+	int                        rc = 0;
+	uint32_t                   seg;
+	uint32_t                   row;
+	uint32_t                   col;
+	uint32_t                   tgt_id;
+	m0_bindex_t                goff;
+	struct m0_layout_enum     *le;
+	struct m0_pdclust_layout  *play;
 	struct m0_pdclust_instance *play_instance;
-	struct m0_pdclust_src_addr  src;
-	struct m0_pdclust_src_addr  spare;
-	struct m0_pdclust_tgt_addr  tgt;
-	enum m0_pdclust_unit_type   unit_type;
+	struct m0_pdclust_src_addr src;
+	struct m0_pdclust_src_addr spare;
+	struct m0_pdclust_tgt_addr tgt;
+	enum m0_pdclust_unit_type  unit_type;
 	enum m0_pool_nd_state	    dev_state;
-	struct m0t1fs_sb	   *msb;
-	const struct m0_fid	   *gfid;
+	struct m0t1fs_sb	  *msb;
+	const struct m0_fid	  *gfid;
 	uint32_t		    spare_slot;
 	uint32_t		    spare_slot_prev;
 
@@ -2252,7 +2252,6 @@ static int pargrp_iomap_dgmode_process(struct pargrp_iomap *map,
 	M0_PRE(index != NULL);
 	M0_PRE(count >  0);
 	M0_PRE(ioreq_sm_state(map->pi_ioreq) == IRS_DEGRADED_READING);
-	M0_PRE(M0_IN(dev_state,(M0_PNDS_FAILED, M0_PNDS_SNS_REPAIRED)));
 
 	/*
 	 * Finds out the id of target object to which failed IO fop
@@ -2264,7 +2263,6 @@ static int pargrp_iomap_dgmode_process(struct pargrp_iomap *map,
 			             &tio->ti_fid);
 	play   = pdlayout_get(map->pi_ioreq);
 	play_instance = pdlayout_instance(layout_instance(map->pi_ioreq));
-	map->pi_state = PI_DEGRADED;
 	msb = file_to_sb(map->pi_ioreq->ir_file);
 	gfid = file_to_fid(map->pi_ioreq->ir_file);
 	rc = m0_poolmach_device_state(msb->csb_pool.po_mach,
@@ -2285,8 +2283,10 @@ static int pargrp_iomap_dgmode_process(struct pargrp_iomap *map,
 		M0_ASSERT(src.sa_unit  <  layout_n(play) + layout_k(play));
 		unit_type = m0_pdclust_unit_classify(play, src.sa_unit);
 		if (dev_state == M0_PNDS_SNS_REPAIRED) {
-			if (unit_type == M0_PUT_SPARE)
-				continue;
+			if (unit_type == M0_PUT_SPARE) {
+				rc = 0;
+				goto end;
+			}
 			rc = m0_sns_repair_spare_map(msb->csb_pool.po_mach,
 						     gfid, play, play_instance,
 						     src.sa_group, src.sa_unit,
@@ -2301,16 +2301,26 @@ static int pargrp_iomap_dgmode_process(struct pargrp_iomap *map,
 			spare.sa_group = src.sa_group;
 			spare.sa_unit = spare_slot_prev;
 			rc = state_of_unit(&spare, map->pi_ioreq, &dev_state);
-			if (dev_state == M0_PNDS_SNS_REPAIRED)
-				continue;
+			if (rc != 0) {
+				M0_ADDB_FUNC_FAIL(&m0_addb_gmc,
+						  M0T1FS_ADDB_LOC_TIOREQ_MAP_QSPSLOT,
+						  rc, &m0t1fs_addb_ctx);
+				M0_RETURN(rc);
+			}
+			if (dev_state == M0_PNDS_SNS_REPAIRED) {
+				rc = 0;
+				goto end;
+			}
+			++map->pi_ioreq->ir_failed_nr;
 		}
 		if (unit_type == M0_PUT_SPARE) {
 			rc = m0_sns_repair_data_map(msb->csb_pool.po_mach,
 						    gfid, play, src.sa_group,
 						    src.sa_unit, &src.sa_unit);
-		if (rc != 0)
-			M0_RETERR(rc, "Failed to get data associated with a spare unit");
+			if (rc != 0)
+				M0_RETERR(rc, "Failed to get data associated with a spare unit");
 		}
+		map->pi_state = PI_DEGRADED;
 		/* Segment belongs to a data unit. */
 		if (src.sa_unit < layout_n(play)) {
 			goff = gfile_offset(index[seg], map, play, &src);
@@ -2362,6 +2372,7 @@ static int pargrp_iomap_dgmode_process(struct pargrp_iomap *map,
 		}
 	}
 	rc = pargrp_iomap_pages_mark(map, M0_PUT_SPARE);
+end:
 	M0_RETURN(rc);
 
 par_fail:
@@ -2556,6 +2567,7 @@ static int pargrp_iomap_dgmode_recover(struct pargrp_iomap *map)
 	struct m0_buf            *parity;
 	struct m0_buf             failed;
 	struct m0_pdclust_layout *play;
+	uint32_t		  failed_nr = 0;
 
 	M0_ENTRY();
 	M0_PRE_EX(pargrp_iomap_invariant(map));
@@ -2627,8 +2639,13 @@ static int pargrp_iomap_dgmode_recover(struct pargrp_iomap *map)
 				(map->pi_paritybufs[row][col]->db_flags &
 				 PA_READ_FAILED) ? 1 : 0;
 		}
+		for (col = 0; col < data_col_nr(play) + parity_col_nr(play); ++col)
+			if (*(fail + col) == 1)
+				++failed_nr;
+		M0_LOG(M0_FATAL,"Failed units in group %d are %d", (int)map->pi_grpid, failed_nr);
 		m0_parity_math_recover(parity_math(map->pi_ioreq), data,
 				       parity, &failed);
+		failed_nr = 0;
 	}
 
 	m0_free(data);
@@ -3044,6 +3061,7 @@ static int device_check(struct io_request *req)
 			M0_RETERR(rc, "Failed to retrieve target device state");
 		ti->ti_state = state;
 
+		M0_LOG(M0_FATAL,"Request to device %d found", (int)(ti->ti_fid.f_container));
 		if (M0_IN(state, (M0_PNDS_FAILED, M0_PNDS_OFFLINE,
 			          M0_PNDS_SNS_REPAIRING)))
 			st_cnt++;
@@ -3171,8 +3189,7 @@ static int ioreq_dgmode_write(struct io_request *req, bool rmw)
 
 static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 {
-	int                      rc              = 0;
-	int                      failed_dev_nr   = 0;
+	int                      rc            = 0;
 	int                      repaired_dev_nr = 0;
 	uint64_t                 id;
 	struct m0t1fs_sb        *csb;
@@ -3205,8 +3222,10 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 		if (rc != 0)
 			M0_RETERR(rc, "Failed to retrieve device state");
 
-		M0_LOG(M0_INFO, "device state for fid %llu:%llu is %d",
+		M0_LOG(M0_FATAL, "device state for fid %llu:%llu is %d",
 		       ti->ti_fid.f_container, ti->ti_fid.f_key, state);
+		if (ti->ti_state == M0_PNDS_SNS_REPAIRED)
+			++repaired_dev_nr;
 		if (!M0_IN(state, (M0_PNDS_FAILED, M0_PNDS_OFFLINE,
 			   M0_PNDS_SNS_REPAIRING)))
 			continue;
@@ -3217,7 +3236,7 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 		 * failed, rest of the parity group also needs to be read
 		 * (subject to file size) in order to re-generate lost data.
 		 */
-		++failed_dev_nr;
+		++req->ir_failed_nr;
 		if (ioreq_sm_state(req) == IRS_READ_COMPLETE)
 			ioreq_sm_state_set(req, IRS_DEGRADED_READING);
 
@@ -3227,8 +3246,8 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 				break;
 		} m0_tl_endfor;
 	} m0_htable_endfor;
-
-	if (repaired_dev_nr != 0 && failed_dev_nr != 0) {
+	if (repaired_dev_nr > 0 && req->ir_failed_nr > 0) {
+		M0_LOG(M0_FATAL, "Repaired devices = %d", (int)repaired_dev_nr);
 		m0_htable_for(tioreqht, ti, &req->ir_nwxfer.nxr_tioreqs_hash) {
 			rc = m0_poolmach_device_state(csb->csb_pool.po_mach,
 					ti->ti_fid.f_container, &state);
@@ -3244,7 +3263,6 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 
 		} m0_htable_endfor;
 	}
-
 	if (rc != 0)
 		M0_RETERR(rc, "dgmode failed");
 
@@ -3253,8 +3271,12 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 	 * are in one of the states
 	 * { M0_PNDS_FAILED, M0_PNDS_OFFLINE, M0_PNDS_SNS_REPAIRING }
 	 */
-	if (failed_dev_nr > 0) {
+	if (req->ir_failed_nr > 0) {
+		if (ioreq_sm_state(req) == IRS_READ_COMPLETE)
+			ioreq_sm_state_set(req, IRS_DEGRADED_READING);
 		for (id = 0; id < req->ir_iomap_nr; ++id) {
+			if (req->ir_iomaps[id]->pi_state != PI_DEGRADED)
+				continue;
 			rc = req->ir_iomaps[id]->pi_ops->
 			     pi_dgmode_postprocess(req->ir_iomaps[id]);
 			if (rc != 0)
@@ -3288,6 +3310,7 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 	if (req->ir_nwxfer.nxr_rc != 0)
 		req->ir_nwxfer.nxr_rc = 0;
 	req->ir_rc = req->ir_nwxfer.nxr_rc;
+	M0_LOG(M0_FATAL, "IN DEGRADED MODE");
 
 	rc = req->ir_nwxfer.nxr_ops->nxo_distribute(&req->ir_nwxfer);
 	if (rc != 0)
@@ -3314,7 +3337,7 @@ static int ioreq_dgmode_read(struct io_request *req, bool rmw)
 	 * Recovers lost data using parity recovery algorithms only if
 	 * one or more devices were in FAILED, OFFLINE, REPAIRING state.
 	 */
-	if (failed_dev_nr > 0) {
+	if (req->ir_failed_nr > 0) {
 		rc = req->ir_ops->iro_dgmode_recover(req);
 		if (rc != 0)
 			M0_RETERR(rc, "Failed to recover lost data.");
@@ -3832,8 +3855,14 @@ static int nw_xfer_tioreq_map(struct nw_xfer_request           *xfer,
 	rc = nw_xfer_tioreq_get(xfer, &tfid, session,
 				layout_unit_size(play) * req->ir_iomap_nr,
 				out);
+
+			rc = m0_poolmach_device_state(csb->csb_pool.po_mach,
+						      tfid.f_container,
+						      &device_state_prev);
+		M0_LOG(M0_FATAL, "(nw-map)device state for fid %llu:%llu is %d",
+		       out[0]->ti_fid.f_container, out[0]->ti_fid.f_key, device_state_prev);
 	if (ioreq_sm_state(req) == IRS_DEGRADED_READING &&
-	    device_state != M0_PNDS_ONLINE)
+	    device_state != M0_PNDS_ONLINE && device_state != M0_PNDS_SNS_REPAIRED)
 		(*out)->ti_state = device_state;
 	M0_RETURN(rc);
 }
@@ -4822,8 +4851,8 @@ static int nw_xfer_req_dispatch(struct nw_xfer_request *xfer)
 
 		/* Skips the target device if it is not online. */
 		if (ti->ti_state != M0_PNDS_ONLINE) {
-			M0_LOG(M0_INFO, "Skipped device %llu:%llu",
-			       ti->ti_fid.f_container, ti->ti_fid.f_key);
+			M0_LOG(M0_FATAL, "Skipped device %llu:%llu as it has state %d",
+			       ti->ti_fid.f_container, ti->ti_fid.f_key, (int)ti->ti_state);
 			continue;
 		}
 
diff --git a/m0t1fs/linux_kernel/file_internal.h b/m0t1fs/linux_kernel/file_internal.h
index d185d18..7224d81 100644
--- a/m0t1fs/linux_kernel/file_internal.h
+++ b/m0t1fs/linux_kernel/file_internal.h
@@ -1392,6 +1392,11 @@ struct io_request {
 	 *  - or SNS repair has completed on associated global fid.
 	 */
 	enum sns_repair_state        ir_sns_state;
+
+	/**
+	 * Total number of failed devices associated with the IO request.
+	 */
+	uint32_t		     ir_failed_nr;
 };
 
 /**
diff --git a/m0t1fs/linux_kernel/st/m0t1fs_sns_repair_mf.sh b/m0t1fs/linux_kernel/st/m0t1fs_sns_repair_mf.sh
index eaf6951..679b6a1 100755
--- a/m0t1fs/linux_kernel/st/m0t1fs_sns_repair_mf.sh
+++ b/m0t1fs/linux_kernel/st/m0t1fs_sns_repair_mf.sh
@@ -76,7 +76,7 @@ sns_repair_test()
 	local rc=0
 	local fail_device1=1
 	local fail_device2=3
-	local fail_device3=7
+	local fail_device3=9
 	local N=3
 	local K=3
 	local P=9
@@ -96,20 +96,22 @@ sns_repair_test()
 		return 1
 	}
 
-	dd if=/dev/urandom bs=$unit_size count=50 \
-	   of=$MERO_M0T1FS_MOUNT_DIR/file2_to_repair >> $MERO_TEST_LOGFILE || {
-		echo "Failed: dd failed.."
-		unmount_and_clean &>> $MERO_TEST_LOGFILE
-		return 1
-	}
-
-	dd if=/dev/urandom bs=$unit_size count=50 \
-	   of=$MERO_M0T1FS_MOUNT_DIR/file3_to_repair >> $MERO_TEST_LOGFILE || {
-		echo "Failed: dd failed.."
-		unmount_and_clean &>> $MERO_TEST_LOGFILE
-		return 1
-	}
-
+#	dd if=/dev/urandom bs=$unit_size count=50 \
+#	   of=$MERO_M0T1FS_MOUNT_DIR/file2_to_repair >> $MERO_TEST_LOGFILE || {
+#		echo "Failed: dd failed.."
+#		unmount_and_clean &>> $MERO_TEST_LOGFILE
+#		return 1
+#	}
+#
+#	dd if=/dev/urandom bs=$unit_size count=50 \
+#	   of=$MERO_M0T1FS_MOUNT_DIR/file3_to_repair >> $MERO_TEST_LOGFILE || {
+#		echo "Failed: dd failed.."
+#		unmount_and_clean &>> $MERO_TEST_LOGFILE
+#		return 1
+#	}
+
+	md5sum $MERO_M0T1FS_MOUNT_DIR/file1_to_repair | \
+		tee $MERO_M0T1FS_TEST_DIR/md5
 	for ((i=1; i < ${#EP[*]}; i++)) ; do
 		IOSEP="$IOSEP -S ${lnet_nid}:${EP[$i]}"
 	done
@@ -120,12 +122,15 @@ sns_repair_test()
 	then
 		return $?
 	fi
-
+	echo "IO dg-mode test 1"
+#	md5sum -c < $MERO_M0T1FS_TEST_DIR/md5
 	sns_repair
 	if [ $? -ne "0" ]
 	then
 		return $?
 	fi
+	echo "IO dg-mode test 2"
+#	md5sum -c < $MERO_M0T1FS_TEST_DIR/md5
 ####### Query device state
 
 	pool_mach_query $fail_device1 $fail_device2
@@ -139,30 +144,36 @@ sns_repair_test()
 	then
 		return $?
 	fi
-
-	sns_repair
-	if [ $? -ne "0" ]
-	then
-		return $?
-	fi
-
-	pool_mach_query $fail_device3
-	if [ $? -ne "0" ]
-	then
-		return $?
-	fi
-
-        echo "Starting SNS Re-balance.."
-	sns_rebalance
-	if [ $? -ne "0" ]
-	then
-		return $?
-	fi
-	pool_mach_query $fail_device1 $fail_device2 $fail_device3
-	if [ $? -ne "0" ]
-	then
-		return $?
-	fi
+	echo "" >/var/log/messages
+	echo "IO dg-mode test 3"
+	md5sum -c < $MERO_M0T1FS_TEST_DIR/md5
+	rm -f messages
+	cp /var/log/messages .
+#	cp /var/log/messages .
+
+#	sns_repair
+#	if [ $? -ne "0" ]
+#	then
+#		return $?
+#	fi
+
+#	pool_mach_query $fail_device3
+#	if [ $? -ne "0" ]
+#	then
+#		return $?
+#	fi
+
+ #       echo "Starting SNS Re-balance.."
+#	sns_rebalance
+#	if [ $? -ne "0" ]
+#	then
+#		return $?
+#	fi
+#	pool_mach_query $fail_device1 $fail_device2 $fail_device3
+#	if [ $? -ne "0" ]
+#	then
+#		return $?
+#	fi
 
 	echo "unmounting and cleaning.."
 	unmount_and_clean &>> $MERO_TEST_LOGFILE
diff --git a/sns/parity_repair.c b/sns/parity_repair.c
index ed2e3c1..0405d9b 100644
--- a/sns/parity_repair.c
+++ b/sns/parity_repair.c
@@ -93,7 +93,9 @@ M0_INTERNAL int m0_sns_repair_spare_map(struct m0_poolmach *pm,
 	 */
         if (rc == 0) {
                 *spare_slot_out += m0_pdclust_N(pl) + m0_pdclust_K(pl);
-		*spare_slot_out_prev += m0_pdclust_N(pl) + m0_pdclust_K(pl);
+		if (*spare_slot_out_prev != unit_number)
+			*spare_slot_out_prev += m0_pdclust_N(pl) +
+				m0_pdclust_K(pl);
 	}
 
         return rc;
-- 
1.8.3.2

