From f6a3a9443eea368f4cfe93cca14224366f63b46a Mon Sep 17 00:00:00 2001
From: Hua Huang <hua_huang@xyratex.com>
Date: Thu, 19 Dec 2013 18:02:40 +0800
Subject: [PATCH 05/11] m0_poolmach_store_destroy() to free all BE allocated
 memory. UT to init() and fini() with be_ut_* helpers.

---
 pool/pool.c       |   2 +-
 pool/pool_store.c | 109 ++++++++++++++++++++++++++++++++++++++++++++++++++----
 pool/ut/test_pm.c |  52 ++++++++++++++++++--------
 3 files changed, 138 insertions(+), 25 deletions(-)

diff --git a/pool/pool.c b/pool/pool.c
index 13838ad..0df40ff 100644
--- a/pool/pool.c
+++ b/pool/pool.c
@@ -354,7 +354,7 @@ M0_INTERNAL void m0_poolmach_fini(struct m0_poolmach *pm)
 	m0_rwlock_write_lock(&pm->pm_lock);
 
 	if (pm->pm_be_seg == NULL) {
-		/* iterate through events and free them */
+		/* On client: iterate through events and free them */
 		m0_tl_for(poolmach_events, &state->pst_events_list, scan) {
 			poolmach_events_tlink_del_fini(scan);
 			m0_free(scan);
diff --git a/pool/pool_store.c b/pool/pool_store.c
index 78cb733..efe8d87 100644
--- a/pool/pool_store.c
+++ b/pool/pool_store.c
@@ -109,12 +109,17 @@ M0_INTERNAL int m0_poolmach_store(struct m0_poolmach        *pm,
 
 
 	M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx, dest);
-	M0_BE_TX_CAPTURE_ARR(pm->pm_be_seg, tx, dest->pst_nodes_array, dest->pst_nr_nodes);
-	M0_BE_TX_CAPTURE_ARR(pm->pm_be_seg, tx, dest->pst_devices_array, dest->pst_nr_devices);
-	M0_BE_TX_CAPTURE_ARR(pm->pm_be_seg, tx, dest->pst_spare_usage_array, dest->pst_max_device_failures);
+	M0_BE_TX_CAPTURE_ARR(pm->pm_be_seg, tx, dest->pst_nodes_array,
+			     dest->pst_nr_nodes);
+	M0_BE_TX_CAPTURE_ARR(pm->pm_be_seg, tx, dest->pst_devices_array,
+			     dest->pst_nr_devices);
+	M0_BE_TX_CAPTURE_ARR(pm->pm_be_seg, tx, dest->pst_spare_usage_array,
+			     dest->pst_max_device_failures);
 	M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx, new_link);
-	M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx, new_link->pel_linkage.t_link.ll_prev);
-	M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx, new_link->pel_linkage.t_link.ll_next);
+	M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx,
+			     new_link->pel_linkage.t_link.ll_prev);
+	M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx,
+			     new_link->pel_linkage.t_link.ll_next);
 	return rc;
 }
 
@@ -190,7 +195,8 @@ M0_INTERNAL int m0_poolmach_store_init(struct m0_poolmach *pm,
 	M0_BE_ALLOC_CREDIT_PTR(state, be_seg, &cred);
 	M0_BE_ALLOC_CREDIT_ARR(nodes_array, nr_nodes, be_seg, &cred);
 	M0_BE_ALLOC_CREDIT_ARR(devices_array, nr_devices + 1, be_seg, &cred);
-	M0_BE_ALLOC_CREDIT_ARR(spare_usage_array, max_device_failures, be_seg, &cred);
+	M0_BE_ALLOC_CREDIT_ARR(spare_usage_array, max_device_failures, be_seg,
+			       &cred);
 	m0_be_seg_dict_insert_credit(be_seg, poolmach_name, &cred);
 	m0_be_tx_prep(tx, &cred);
 	rc = m0_be_tx_open_sync(tx);
@@ -198,7 +204,8 @@ M0_INTERNAL int m0_poolmach_store_init(struct m0_poolmach *pm,
 		M0_BE_ALLOC_PTR_SYNC(state, be_seg, tx);
 		M0_BE_ALLOC_ARR_SYNC(nodes_array, nr_nodes, be_seg, tx);
 		M0_BE_ALLOC_ARR_SYNC(devices_array, nr_devices + 1, be_seg, tx);
-		M0_BE_ALLOC_ARR_SYNC(spare_usage_array, max_device_failures, be_seg, tx);
+		M0_BE_ALLOC_ARR_SYNC(spare_usage_array, max_device_failures,
+				     be_seg, tx);
 		M0_ASSERT(state != NULL);
 		M0_ASSERT(nodes_array != NULL);
 		M0_ASSERT(devices_array != NULL);
@@ -235,7 +242,8 @@ M0_INTERNAL int m0_poolmach_store_init(struct m0_poolmach *pm,
 		M0_BE_TX_CAPTURE_PTR(be_seg, tx, state);
 		M0_BE_TX_CAPTURE_ARR(be_seg, tx, nodes_array, nr_nodes);
 		M0_BE_TX_CAPTURE_ARR(be_seg, tx, devices_array, nr_devices);
-		M0_BE_TX_CAPTURE_ARR(be_seg, tx, spare_usage_array, max_device_failures);
+		M0_BE_TX_CAPTURE_ARR(be_seg, tx, spare_usage_array,
+				     max_device_failures);
 		m0_be_tx_close_sync(tx);
 		M0_LOG(M0_DEBUG, "On-disk pool param: %u:%u:%u:%u",
 				 state->pst_nr_nodes,
@@ -251,6 +259,91 @@ out:
 	return rc;
 }
 
+/**
+ * Destroy pool machine state from persistent storage completely.
+ */
+M0_INTERNAL int m0_poolmach_store_destroy(struct m0_poolmach *pm,
+					  struct m0_be_seg   *be_seg,
+					  struct m0_sm_group *sm_grp,
+					  struct m0_dtm      *dtm)
+{
+	struct m0_be_tx_credit      cred = {};
+	struct m0_be_tx            *tx;
+	struct m0_poolmach_state   *state;
+	struct m0_poolnode         *nodes_array;
+	struct m0_pooldev          *devices_array;
+	struct m0_pool_spare_usage *spare_usage_array;
+	const char                 *poolmach_name = "poolmach_state";
+	struct m0_pool_event_link  *scan;
+	int                         rc;
+
+	M0_PRE(pm->pm_is_initialised);
+	M0_PRE(be_seg != NULL);
+	M0_ENTRY();
+
+	M0_ALLOC_PTR(tx);
+	if (tx == NULL)
+		return -ENOMEM;
+
+	rc = m0_be_seg_dict_lookup(be_seg, poolmach_name, (void**)&state);
+	if (rc != 0)
+		goto out;
+
+	m0_tl_for(poolmach_events, &state->pst_events_list, scan) {
+		M0_SET0(&cred);
+		m0_be_tx_init(tx, 0, be_seg->bs_domain, sm_grp,
+			      NULL, NULL, NULL, NULL);
+		M0_BE_FREE_CREDIT_PTR(scan, pm->pm_be_seg, &cred);
+		m0_be_tx_credit_add(&cred, &M0_BE_TX_CREDIT_TYPE(*scan));
+		m0_be_tx_credit_add(&cred,
+				    &M0_BE_TX_CREDIT_TYPE(struct m0_tlink));
+		m0_be_tx_credit_add(&cred,
+				    &M0_BE_TX_CREDIT_TYPE(struct m0_tlink));
+
+		m0_be_tx_prep(tx, &cred);
+		rc = m0_be_tx_open_sync(tx);
+		M0_ASSERT(rc == 0);
+		M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx, scan);
+		M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx,
+				     scan->pel_linkage.t_link.ll_prev);
+		M0_BE_TX_CAPTURE_PTR(pm->pm_be_seg, tx,
+				     scan->pel_linkage.t_link.ll_next);
+		poolmach_events_tlink_del_fini(scan);
+		M0_BE_FREE_PTR_SYNC(scan, be_seg, tx);
+		m0_be_tx_close_sync(tx);
+		m0_be_tx_fini(tx);
+	} m0_tl_endfor;
+
+
+	M0_SET0(&cred);
+	m0_be_tx_init(tx, 0, be_seg->bs_domain, sm_grp, NULL, NULL, NULL, NULL);
+	M0_BE_FREE_CREDIT_PTR(state, be_seg, &cred);
+	M0_BE_FREE_CREDIT_ARR(nodes_array, state->pst_nr_nodes, be_seg, &cred);
+	M0_BE_FREE_CREDIT_ARR(devices_array, state->pst_nr_devices, be_seg,
+			      &cred);
+	M0_BE_FREE_CREDIT_ARR(spare_usage_array, state->pst_max_device_failures,
+			      be_seg, &cred);
+	m0_be_seg_dict_delete_credit(be_seg, poolmach_name, &cred);
+	m0_be_tx_prep(tx, &cred);
+	rc = m0_be_tx_open_sync(tx);
+	M0_ASSERT(rc == 0);
+	poolmach_events_tlist_init(&state->pst_events_list);
+	M0_BE_FREE_PTR_SYNC(state->pst_nodes_array, be_seg, tx);
+	M0_BE_FREE_PTR_SYNC(state->pst_devices_array, be_seg, tx);
+	M0_BE_FREE_PTR_SYNC(state->pst_spare_usage_array, be_seg, tx);
+	M0_BE_FREE_PTR_SYNC(state, be_seg, tx);
+
+	rc = m0_be_seg_dict_delete(be_seg, tx, poolmach_name);
+	M0_ASSERT(rc == 0);
+	m0_be_tx_close_sync(tx);
+	m0_be_tx_fini(tx);
+
+out:
+	m0_free(tx);
+	return rc;
+}
+
+
 #else
 
 M0_INTERNAL int m0_poolmach_event_store(struct m0_poolmach *pm,
diff --git a/pool/ut/test_pm.c b/pool/ut/test_pm.c
index d541576..bb9a163 100644
--- a/pool/ut/test_pm.c
+++ b/pool/ut/test_pm.c
@@ -42,6 +42,12 @@ static struct m0_be_ut_backend	 ut_be;
 static struct m0_be_ut_seg	 ut_seg;
 static struct m0_be_seg		*be_seg;
 
+/* import from pool/pool_store.c */
+M0_INTERNAL int m0_poolmach_store_destroy(struct m0_poolmach *pm,
+					  struct m0_be_seg   *be_seg,
+					  struct m0_sm_group *sm_grp,
+					  struct m0_dtm      *dtm);
+
 static int seg_init()
 {
 	int rc;
@@ -56,12 +62,12 @@ static int seg_init()
 	return 0;
 }
 
-int seg_fini()
+static int seg_fini()
 {
-//	int rc;
-//	rc = m0_be_ut__seg_dict_destroy(be_seg, sm_grp);
-//	M0_ASSERT(rc == 0);
-//	m0_be_ut_seg_allocator_fini(&ut_seg, &ut_be);
+	int rc;
+	rc = m0_be_ut__seg_dict_destroy(be_seg, sm_grp);
+	M0_ASSERT(rc == 0);
+	m0_be_ut_seg_allocator_fini(&ut_seg, &ut_be);
 	m0_be_ut_seg_fini(&ut_seg);
 	m0_be_ut_backend_fini(&ut_be);
 	return 0;
@@ -71,10 +77,10 @@ static void pm_test_init_fini(void)
 {
 	struct m0_poolmach pm;
 	int                rc = 0;
-	return;
 
 	M0_SET0(&pm);
-	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL, PM_TEST_DEFAULT_NODE_NUMBER,
+	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL,
+					 PM_TEST_DEFAULT_NODE_NUMBER,
 					 PM_TEST_DEFAULT_DEVICE_NUMBER,
 					 PM_TEST_DEFAULT_MAX_NODE_FAILURE,
 					 PM_TEST_DEFAULT_MAX_DEVICE_FAILURE);
@@ -99,10 +105,10 @@ static void pm_test_transit(void)
 	uint32_t                       index;
 	struct m0_be_tx_credit         cred = {};
 	struct m0_be_tx                tx;
-	return;
 
 	M0_SET0(&pm);
-	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL, PM_TEST_DEFAULT_NODE_NUMBER,
+	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL,
+					 PM_TEST_DEFAULT_NODE_NUMBER,
 					 PM_TEST_DEFAULT_DEVICE_NUMBER,
 					 PM_TEST_DEFAULT_MAX_NODE_FAILURE,
 					 PM_TEST_DEFAULT_MAX_DEVICE_FAILURE);
@@ -401,6 +407,10 @@ static void pm_test_transit(void)
 	m0_ut_be_tx_end(&tx);
 	M0_UT_ASSERT(rc == -EINVAL);
 
+	/* Destroy poolmach persistent storage. We will have some different
+	 * poolmach parameters in next test case.
+	 */
+	m0_poolmach_store_destroy(&pm, be_seg, sm_grp, NULL);
 	/* finally */
 	m0_poolmach_fini(&pm);
 }
@@ -416,10 +426,10 @@ static void pm_test_spare_slot(void)
 	uint32_t              spare_slot;
 	struct m0_be_tx       tx;
 	struct m0_be_tx_credit cred = {};
-	return;
 
 	M0_SET0(&pm);
-	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL, PM_TEST_DEFAULT_NODE_NUMBER,
+	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL,
+					 PM_TEST_DEFAULT_NODE_NUMBER,
 					 PM_TEST_DEFAULT_DEVICE_NUMBER,
 					 PM_TEST_DEFAULT_MAX_NODE_FAILURE,
 					 2 /* two spare device */);
@@ -563,7 +573,10 @@ static void pm_test_spare_slot(void)
 	rc = m0_poolmach_sns_repair_spare_query(&pm, 1, &spare_slot);
 	M0_UT_ASSERT(rc == -ENOENT);
 
-	M0_LOG(M0_FATAL, "SSSSSSSSSSSSS");
+	/* Destroy poolmach persistent storage. We will have some different
+	 * poolmach parameters in next test case.
+	 */
+	m0_poolmach_store_destroy(&pm, be_seg, sm_grp, NULL);
 	/* finally */
 	m0_poolmach_fini(&pm);
 }
@@ -582,7 +595,8 @@ static void pm_test_multi_fail(void)
 	M0_ASSERT(rc == 0);
 	M0_UT_ASSERT(rc == 0);
 	M0_SET0(&pm);
-	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL, PM_TEST_DEFAULT_NODE_NUMBER,
+	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL,
+					 PM_TEST_DEFAULT_NODE_NUMBER,
 					 PM_TEST_DEFAULT_DEVICE_NUMBER,
 					 PM_TEST_DEFAULT_MAX_NODE_FAILURE,
 					 3 /*three spare device */);
@@ -754,9 +768,11 @@ static void pm_test_multi_fail(void)
 	M0_UT_ASSERT(rc == 0);
 	M0_UT_ASSERT(spare_slot == 0);
 
+	/* We will keep the poolmach in persistent storage. It will be loaded
+	 * in next test case.
+	 */
 	/* finally */
 	m0_poolmach_fini(&pm);
-	M0_LOG(M0_FATAL, "FFFFFFFFFFFF");
 }
 
 /* load from last test case */
@@ -767,13 +783,17 @@ static void pm_test_load_from_persistent_storage(void)
 
 	M0_ASSERT(rc == 0);
 	M0_SET0(&pm);
-	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL, PM_TEST_DEFAULT_NODE_NUMBER,
+	rc = m0_poolmach_init(&pm, be_seg, sm_grp, NULL,
+					 PM_TEST_DEFAULT_NODE_NUMBER,
 					 PM_TEST_DEFAULT_DEVICE_NUMBER,
 					 PM_TEST_DEFAULT_MAX_NODE_FAILURE,
 					 3);
 	M0_UT_ASSERT(rc == 0);
+
+	/* Destroy poolmach persistent storage.
+	 */
+	m0_poolmach_store_destroy(&pm, be_seg, sm_grp, NULL);
 	m0_poolmach_fini(&pm);
-	M0_LOG(M0_FATAL, "LLLLLLLLLLLLLL");
 }
 
 const struct m0_test_suite poolmach_ut = {
-- 
1.8.3.2

