From 32b459be0ec5cca9c0da4fc751d62ee73fd6b4ef Mon Sep 17 00:00:00 2001
From: Hua Huang <hua_huang@xyratex.com>
Date: Tue, 17 Dec 2013 14:45:35 +0800
Subject: [PATCH 03/11] pm->pm_state is allocated from be on server, and
 malloced from memory on client.

---
 m0t1fs/linux_kernel/dir.c  |   2 +-
 m0t1fs/linux_kernel/file.c |   2 +-
 pool/pool.c                | 237 ++++++++++++++++++++++++---------------------
 pool/pool.h                |  16 +--
 pool/pool_store.c          | 144 +++++++++------------------
 sns/cm/cm.c                |   4 +-
 sns/cm/repair/ut/net.c     |   2 +-
 sns/parity_repair.c        |   2 +-
 8 files changed, 184 insertions(+), 225 deletions(-)

diff --git a/m0t1fs/linux_kernel/dir.c b/m0t1fs/linux_kernel/dir.c
index 854e73f..21a11c5 100644
--- a/m0t1fs/linux_kernel/dir.c
+++ b/m0t1fs/linux_kernel/dir.c
@@ -1541,7 +1541,7 @@ static int m0t1fs_ios_cob_op(struct m0t1fs_sb    *csb,
 		 * call will be restarted.
 		 */
 		rc = -EAGAIN;
-		cli = &csb->csb_pool.po_mach->pm_state.pst_version;
+		cli = &csb->csb_pool.po_mach->pm_state->pst_version;
 		srv = (struct m0_pool_version_numbers *)&reply->cor_fv_version;
 		*cli = *srv;
 		while (i < reply->cor_fv_updates.fvu_count) {
diff --git a/m0t1fs/linux_kernel/file.c b/m0t1fs/linux_kernel/file.c
index bb1440f..3a0c416 100644
--- a/m0t1fs/linux_kernel/file.c
+++ b/m0t1fs/linux_kernel/file.c
@@ -4562,7 +4562,7 @@ static void failure_vector_mismatch(struct io_req_fop *irfop)
 	reply_version = &rw_reply->rwr_fv_version;
 	reply_updates = &rw_reply->rwr_fv_updates;
 	srv = (struct m0_pool_version_numbers *)reply_version;
-	cli = &csb->csb_pool.po_mach->pm_state.pst_version;
+	cli = &csb->csb_pool.po_mach->pm_state->pst_version;
 	M0_LOG(M0_DEBUG, ">>>VERSION MISMATCH!");
 	m0_poolmach_version_dump(cli);
 	m0_poolmach_version_dump(srv);
diff --git a/pool/pool.c b/pool/pool.c
index e4fcd8c..13838ad 100644
--- a/pool/pool.c
+++ b/pool/pool.c
@@ -276,51 +276,61 @@ M0_INTERNAL int m0_poolmach_init(struct m0_poolmach *pm,
 	M0_PRE(!pm->pm_is_initialised);
 
 	M0_SET0(pm);
-	pm->pm_state.pst_version.pvn_version[PVE_READ]  = 0;
-	pm->pm_state.pst_version.pvn_version[PVE_WRITE] = 0;
-	pm->pm_state.pst_nr_nodes = nr_nodes;
-	/* nr_devices io devices and 1 md device. md uses container 0 */
-	pm->pm_state.pst_nr_devices = nr_devices + 1;
-	pm->pm_state.pst_max_node_failures = max_node_failures;
-	pm->pm_state.pst_max_device_failures = max_device_failures;
-
-	M0_ALLOC_ARR(pm->pm_state.pst_nodes_array, pm->pm_state.pst_nr_nodes);
-	M0_ALLOC_ARR(pm->pm_state.pst_devices_array,
-		     pm->pm_state.pst_nr_devices);
-	M0_ALLOC_ARR(pm->pm_state.pst_spare_usage_array,
-		     pm->pm_state.pst_max_device_failures);
-	if (pm->pm_state.pst_nodes_array == NULL ||
-	    pm->pm_state.pst_devices_array == NULL ||
-	    pm->pm_state.pst_spare_usage_array == NULL) {
-		/* m0_free(NULL) is valid */
-		m0_free(pm->pm_state.pst_nodes_array);
-		m0_free(pm->pm_state.pst_devices_array);
-		m0_free(pm->pm_state.pst_spare_usage_array);
-		return -ENOMEM;
-	}
+	m0_rwlock_init(&pm->pm_lock);
 
-	for (i = 0; i < pm->pm_state.pst_nr_nodes; i++) {
-		pm->pm_state.pst_nodes_array[i].pn_state = M0_PNDS_ONLINE;
-		/* TODO use real node id */
-		pm->pm_state.pst_nodes_array[i].pn_id    = NULL;
-	}
+	if (be_seg == NULL) {
+		struct m0_poolmach_state *state;
+		/* This is On client, be_seg is NULL. */
+		M0_ALLOC_PTR(state);
+		if (state == NULL)
+			return -ENOMEM;
+
+		state->pst_version.pvn_version[PVE_READ]  = 0;
+		state->pst_version.pvn_version[PVE_WRITE] = 0;
+		state->pst_nr_nodes            = nr_nodes;
+		/* nr_devices io devices and 1 md device. md uses container 0 */
+		state->pst_nr_devices          = nr_devices + 1;
+		state->pst_max_node_failures   = max_node_failures;
+		state->pst_max_device_failures = max_device_failures;
+
+		M0_ALLOC_ARR(state->pst_nodes_array, state->pst_nr_nodes);
+		M0_ALLOC_ARR(state->pst_devices_array,
+			     state->pst_nr_devices);
+		M0_ALLOC_ARR(state->pst_spare_usage_array,
+			     state->pst_max_device_failures);
+		if (state->pst_nodes_array == NULL ||
+		    state->pst_devices_array == NULL ||
+		    state->pst_spare_usage_array == NULL) {
+			/* m0_free(NULL) is valid */
+			m0_free(state->pst_nodes_array);
+			m0_free(state->pst_devices_array);
+			m0_free(state->pst_spare_usage_array);
+			m0_free(state);
+			return -ENOMEM;
+		}
 
-	for (i = 0; i < pm->pm_state.pst_nr_devices; i++) {
-		pm->pm_state.pst_devices_array[i].pd_state = M0_PNDS_ONLINE;
-		/* TODO use real device id */
-		pm->pm_state.pst_devices_array[i].pd_id    = NULL;
-		pm->pm_state.pst_devices_array[i].pd_node  = NULL;
-	}
+		for (i = 0; i < state->pst_nr_nodes; i++) {
+			state->pst_nodes_array[i].pn_state = M0_PNDS_ONLINE;
+			/* TODO use real node id */
+			state->pst_nodes_array[i].pn_id    = NULL;
+		}
 
-	for (i = 0; i < pm->pm_state.pst_max_device_failures; i++) {
-		/* -1 means that this spare slot is not used */
-		pm->pm_state.pst_spare_usage_array[i].psu_device_index =
+		for (i = 0; i < state->pst_nr_devices; i++) {
+			state->pst_devices_array[i].pd_state = M0_PNDS_ONLINE;
+			/* TODO use real device id */
+			state->pst_devices_array[i].pd_id    = NULL;
+			state->pst_devices_array[i].pd_node  = NULL;
+		}
+
+		for (i = 0; i < state->pst_max_device_failures; i++) {
+			/* -1 means that this spare slot is not used */
+			state->pst_spare_usage_array[i].psu_device_index =
 						POOL_PM_SPARE_SLOT_UNUSED;
-	}
-	poolmach_events_tlist_init(&pm->pm_state.pst_events_list);
-	m0_rwlock_init(&pm->pm_lock);
-	if (be_seg != NULL) {
-		/* On client, be_seg is NULL. On server,  be_seg must be valid*/
+		}
+		poolmach_events_tlist_init(&state->pst_events_list);
+		pm->pm_state = state;
+	} else {
+		/* This is On server,  be_seg must be valid*/
 		rc = m0_poolmach_store_init(pm, be_seg, sm_grp, dtm, nr_nodes,
 					    nr_devices, max_node_failures,
 					    max_device_failures);
@@ -337,25 +347,27 @@ M0_INTERNAL int m0_poolmach_init(struct m0_poolmach *pm,
 M0_INTERNAL void m0_poolmach_fini(struct m0_poolmach *pm)
 {
 	struct m0_pool_event_link *scan;
+	struct m0_poolmach_state  *state = pm->pm_state;
 
 	M0_PRE(pm != NULL);
 
 	m0_rwlock_write_lock(&pm->pm_lock);
-	/* TODO Sync the pool machine state onto persistent storage */
 
-	/* iterate through events and free them */
-	m0_tl_for(poolmach_events, &pm->pm_state.pst_events_list, scan) {
-		poolmach_events_tlink_del_fini(scan);
-		m0_free(scan);
-	} m0_tl_endfor;
+	if (pm->pm_be_seg == NULL) {
+		/* iterate through events and free them */
+		m0_tl_for(poolmach_events, &state->pst_events_list, scan) {
+			poolmach_events_tlink_del_fini(scan);
+			m0_free(scan);
+		} m0_tl_endfor;
 
-	m0_free(pm->pm_state.pst_spare_usage_array);
-	m0_free(pm->pm_state.pst_devices_array);
-	m0_free(pm->pm_state.pst_nodes_array);
+		m0_free(state->pst_spare_usage_array);
+		m0_free(state->pst_devices_array);
+		m0_free(state->pst_nodes_array);
+		m0_free(state);
+		pm->pm_state = NULL;
+	}
 	m0_rwlock_write_unlock(&pm->pm_lock);
 
-	if (pm->pm_be_seg != NULL) {
-	}
 	pm->pm_is_initialised = false;
 	m0_rwlock_fini(&pm->pm_lock);
 }
@@ -377,13 +389,13 @@ M0_INTERNAL void m0_poolmach_fini(struct m0_poolmach *pm)
  *       |                                            v
  *       +------------------<-------------------------+
  */
-M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
-					  struct m0_pool_event *event,
-					  struct m0_be_tx      *tx)
+M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach         *pm,
+					  const struct m0_pool_event *event,
+					  struct m0_be_tx            *tx)
 {
-	struct m0_poolmach_state   *pm_state;
+	struct m0_poolmach_state   *state;
 	struct m0_pool_spare_usage *spare_array;
-	struct m0_pool_event_link  *event_link;
+	struct m0_pool_event_link   event_link;
 	enum m0_pool_nd_state       old_state = M0_PNDS_FAILED;
 	int                         rc = 0;
 	int                         i;
@@ -391,7 +403,7 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 	M0_PRE(pm != NULL);
 	M0_PRE(event != NULL);
 
-	pm_state = &pm->pm_state;
+	state = pm->pm_state;
 
 	if (!M0_IN(event->pe_type, (M0_POOL_NODE, M0_POOL_DEVICE)))
 		return -EINVAL;
@@ -405,16 +417,16 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 		return -EINVAL;
 
 	if ((event->pe_type == M0_POOL_NODE &&
-	     event->pe_index >= pm_state->pst_nr_nodes) ||
+	     event->pe_index >= state->pst_nr_nodes) ||
 	    (event->pe_type == M0_POOL_DEVICE &&
-	     event->pe_index >= pm_state->pst_nr_devices))
+	     event->pe_index >= state->pst_nr_devices))
 		return -EINVAL;
 
 	if (event->pe_type == M0_POOL_NODE) {
-		old_state = pm_state->pst_nodes_array[event->pe_index].pn_state;
+		old_state = state->pst_nodes_array[event->pe_index].pn_state;
 	} else if (event->pe_type == M0_POOL_DEVICE) {
 		old_state =
-			pm_state->pst_devices_array[event->pe_index].pd_state;
+			state->pst_devices_array[event->pe_index].pd_state;
 	}
 
 	switch (old_state) {
@@ -451,39 +463,32 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 	m0_rwlock_write_lock(&pm->pm_lock);
 
 	/* step 2: Update the state according to event */
-	M0_ALLOC_PTR(event_link);
-	if (event_link == NULL) {
-		rc = -ENOMEM;
-		goto out_unlock;
-	}
-	event_link->pel_event = *event;
+	event_link.pel_event = *event;
 	if (event->pe_type == M0_POOL_NODE) {
 		/* TODO if this is a new node join event, the index
 		 * might larger than the current number. Then we need
 		 * to create a new larger array to hold nodes info.
 		 */
-		pm_state->pst_nodes_array[event->pe_index].pn_state =
+		state->pst_nodes_array[event->pe_index].pn_state =
 				event->pe_state;
 	} else if (event->pe_type == M0_POOL_DEVICE) {
-		pm_state->pst_devices_array[event->pe_index].pd_state =
+		state->pst_devices_array[event->pe_index].pd_state =
 				event->pe_state;
 	}
 
 	/* step 3: Increase the version */
-	++ pm_state->pst_version.pvn_version[PVE_READ];
-	++ pm_state->pst_version.pvn_version[PVE_WRITE];
+	++ state->pst_version.pvn_version[PVE_READ];
+	++ state->pst_version.pvn_version[PVE_WRITE];
 
-	/* Step 4: copy new version into event, and link it into list */
-	event_link->pel_new_version = pm_state->pst_version;
-	poolmach_events_tlink_init_at_tail(event_link,
-					   &pm_state->pst_events_list);
+	/* Step 4: copy new version into event */
+	event_link.pel_new_version = state->pst_version;
 
 	/* Step 5: Alloc or free a spare slot if necessary.*/
-	spare_array = pm->pm_state.pst_spare_usage_array;
+	spare_array = state->pst_spare_usage_array;
 	switch (event->pe_state) {
 	case M0_PNDS_ONLINE:
 		/* clear spare slot usage if it is from rebalancing */
-		for (i = 0; i < pm->pm_state.pst_max_device_failures; i++) {
+		for (i = 0; i < state->pst_max_device_failures; i++) {
 			if (spare_array[i].psu_device_index == event->pe_index){
 				M0_ASSERT(M0_IN(spare_array[i].psu_device_state,
 					  (M0_PNDS_OFFLINE,
@@ -496,7 +501,7 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 		break;
 	case M0_PNDS_FAILED:
 		/* alloc a sns repare spare slot */
-		for (i = 0; i < pm->pm_state.pst_max_device_failures; i++) {
+		for (i = 0; i < state->pst_max_device_failures; i++) {
 			if (spare_array[i].psu_device_index ==
 						POOL_PM_SPARE_SLOT_UNUSED) {
 				spare_array[i].psu_device_index =
@@ -506,7 +511,7 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 				break;
 			}
 		}
-		if (i == pm->pm_state.pst_max_device_failures) {
+		if (i == state->pst_max_device_failures) {
 			/* No free spare space slot is found!!
 			 * The pool is in DUD state!!
 			 */
@@ -517,7 +522,7 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 	case M0_PNDS_SNS_REPAIRED:
 	case M0_PNDS_SNS_REBALANCING:
 		/* change the repair spare slot usage */
-		for (i = 0; i < pm->pm_state.pst_max_device_failures; i++) {
+		for (i = 0; i < state->pst_max_device_failures; i++) {
 			if (spare_array[i].psu_device_index == event->pe_index){
 				spare_array[i].psu_device_state =
 							event->pe_state;
@@ -525,7 +530,7 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 			}
 		}
 		/* must found */
-		M0_ASSERT(i < pm->pm_state.pst_max_device_failures);
+		M0_ASSERT(i < state->pst_max_device_failures);
 		break;
 	default:
 		/* Do nothing */
@@ -535,10 +540,18 @@ M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
 	if (pm->pm_be_seg != NULL) {
 		/* This poolmach is on server. Update to persistent storage. */
 		M0_ASSERT(tx != NULL);
-		rc = m0_poolmach_store(pm, tx, event_link);
+		rc = m0_poolmach_store(pm, tx, &event_link);
+	} else {
+		struct m0_pool_event_link *new_link;
+		M0_ALLOC_PTR(new_link);
+		if (new_link == NULL) {
+			rc = -ENOMEM;
+		} else {
+			*new_link = event_link;
+			poolmach_events_tlink_init_at_tail(new_link,
+						   &state->pst_events_list);
+		}
 	}
-
-out_unlock:
 	/* Finally: unlock the poolmach */
 	m0_rwlock_write_unlock(&pm->pm_lock);
 	return rc;
@@ -550,6 +563,7 @@ M0_INTERNAL int m0_poolmach_state_query(struct m0_poolmach *pm,
 					const struct m0_pool_version_numbers
 					*to, struct m0_tl *event_list_head)
 {
+	struct m0_poolmach_state      *state;
 	struct m0_pool_version_numbers zero = { {0, 0} };
 	struct m0_pool_event_link     *scan;
 	struct m0_pool_event_link     *event_link;
@@ -558,20 +572,21 @@ M0_INTERNAL int m0_poolmach_state_query(struct m0_poolmach *pm,
 	M0_PRE(pm != NULL);
 	M0_PRE(event_list_head != NULL);
 
+	state = pm->pm_state;
 	m0_rwlock_read_lock(&pm->pm_lock);
 	if (from != NULL && !m0_poolmach_version_equal(&zero, from)) {
-		m0_tl_for(poolmach_events, &pm->pm_state.pst_events_list, scan){
+		m0_tl_for(poolmach_events, &state->pst_events_list, scan){
 			if (m0_poolmach_version_equal(&scan->pel_new_version,
 						     from)) {
 				/* skip the current one and move to next */
 				scan = poolmach_events_tlist_next(
-						&pm->pm_state.pst_events_list,
+						&state->pst_events_list,
 						scan);
 				break;
 			}
 		} m0_tl_endfor;
 	} else {
-		scan = poolmach_events_tlist_head(&pm->pm_state.pst_events_list);
+		scan = poolmach_events_tlist_head(&state->pst_events_list);
 	}
 
 	while (scan != NULL) {
@@ -594,7 +609,7 @@ M0_INTERNAL int m0_poolmach_state_query(struct m0_poolmach *pm,
 		if (to != NULL &&
 		    m0_poolmach_version_equal(&scan->pel_new_version, to))
 			break;
-		scan = poolmach_events_tlist_next(&pm->pm_state.pst_events_list,
+		scan = poolmach_events_tlist_next(&state->pst_events_list,
 						  scan);
 	}
 
@@ -611,7 +626,7 @@ M0_INTERNAL int m0_poolmach_current_version_get(struct m0_poolmach *pm,
 	M0_PRE(curr != NULL);
 
 	m0_rwlock_read_lock(&pm->pm_lock);
-	*curr = pm->pm_state.pst_version;
+	*curr = pm->pm_state->pst_version;
 	m0_rwlock_read_unlock(&pm->pm_lock);
 	return 0;
 }
@@ -623,11 +638,11 @@ M0_INTERNAL int m0_poolmach_device_state(struct m0_poolmach *pm,
 	M0_PRE(pm != NULL);
 	M0_PRE(state_out != NULL);
 
-	if (device_index >= pm->pm_state.pst_nr_devices)
+	if (device_index >= pm->pm_state->pst_nr_devices)
 		return -EINVAL;
 
 	m0_rwlock_read_lock(&pm->pm_lock);
-	*state_out = pm->pm_state.pst_devices_array[device_index].pd_state;
+	*state_out = pm->pm_state->pst_devices_array[device_index].pd_state;
 	m0_rwlock_read_unlock(&pm->pm_lock);
 	return 0;
 }
@@ -639,11 +654,11 @@ M0_INTERNAL int m0_poolmach_node_state(struct m0_poolmach *pm,
 	M0_PRE(pm != NULL);
 	M0_PRE(state_out != NULL);
 
-	if (node_index >= pm->pm_state.pst_nr_nodes)
+	if (node_index >= pm->pm_state->pst_nr_nodes)
 		return -EINVAL;
 
 	m0_rwlock_read_lock(&pm->pm_lock);
-	*state_out = pm->pm_state.pst_nodes_array[node_index].pn_state;
+	*state_out = pm->pm_state->pst_nodes_array[node_index].pn_state;
 	m0_rwlock_read_unlock(&pm->pm_lock);
 
 	return 0;
@@ -655,8 +670,8 @@ m0_poolmach_device_is_in_spare_usage_array(struct m0_poolmach *pm,
 {
         int i;
 
-        for (i = 0; i < pm->pm_state.pst_max_device_failures; ++i) {
-                if (pm->pm_state.pst_spare_usage_array[i].psu_device_index ==
+        for (i = 0; i < pm->pm_state->pst_max_device_failures; ++i) {
+                if (pm->pm_state->pst_spare_usage_array[i].psu_device_index ==
                                 device_index) {
                         return true;
                 }
@@ -675,18 +690,18 @@ M0_INTERNAL int m0_poolmach_sns_repair_spare_query(struct m0_poolmach *pm,
 	M0_PRE(pm != NULL);
 	M0_PRE(spare_slot_out != NULL);
 
-	if (device_index >= pm->pm_state.pst_nr_devices)
+	if (device_index >= pm->pm_state->pst_nr_devices)
 		return -EINVAL;
 
 	rc = -ENOENT;
 	m0_rwlock_read_lock(&pm->pm_lock);
-	device_state = pm->pm_state.pst_devices_array[device_index].pd_state;
+	device_state = pm->pm_state->pst_devices_array[device_index].pd_state;
 	if (!M0_IN(device_state, (M0_PNDS_FAILED, M0_PNDS_SNS_REPAIRING,
 				  M0_PNDS_SNS_REPAIRED, M0_PNDS_SNS_REBALANCING)))
 		goto out;
 
-	spare_usage_array = pm->pm_state.pst_spare_usage_array;
-	for (i = 0; i < pm->pm_state.pst_max_device_failures; i++) {
+	spare_usage_array = pm->pm_state->pst_spare_usage_array;
+	for (i = 0; i < pm->pm_state->pst_max_device_failures; i++) {
 		if (spare_usage_array[i].psu_device_index == device_index) {
 			M0_ASSERT(M0_IN(spare_usage_array[i].psu_device_state,
 						(M0_PNDS_FAILED,
@@ -710,14 +725,14 @@ m0_poolmach_sns_repair_spare_contains_data(struct m0_poolmach *p,
 					   bool check_state)
 {
 	if (!check_state)
-		return p->pm_state.pst_spare_usage_array[spare_slot].
+		return p->pm_state->pst_spare_usage_array[spare_slot].
 		       psu_device_index != POOL_PM_SPARE_SLOT_UNUSED &&
-		       p->pm_state.pst_spare_usage_array[spare_slot].
+		       p->pm_state->pst_spare_usage_array[spare_slot].
 		       psu_device_state != M0_PNDS_SNS_REPAIRING;
 	else
-		return p->pm_state.pst_spare_usage_array[spare_slot].
+		return p->pm_state->pst_spare_usage_array[spare_slot].
 		       psu_device_index != POOL_PM_SPARE_SLOT_UNUSED &&
-		       p->pm_state.pst_spare_usage_array[spare_slot].
+		       p->pm_state->pst_spare_usage_array[spare_slot].
 		       psu_device_state != M0_PNDS_SNS_REPAIRED;
 }
 
@@ -732,17 +747,17 @@ M0_INTERNAL int m0_poolmach_sns_rebalance_spare_query(struct m0_poolmach *pm,
 	M0_PRE(pm != NULL);
 	M0_PRE(spare_slot_out != NULL);
 
-	if (device_index >= pm->pm_state.pst_nr_devices)
+	if (device_index >= pm->pm_state->pst_nr_devices)
 		return -EINVAL;
 
 	rc = -ENOENT;
 	m0_rwlock_read_lock(&pm->pm_lock);
-	device_state = pm->pm_state.pst_devices_array[device_index].pd_state;
+	device_state = pm->pm_state->pst_devices_array[device_index].pd_state;
 	if (!M0_IN(device_state, (M0_PNDS_SNS_REBALANCING)))
 		goto out;
 
-	spare_usage_array = pm->pm_state.pst_spare_usage_array;
-	for (i = 0; i < pm->pm_state.pst_max_device_failures; i++) {
+	spare_usage_array = pm->pm_state->pst_spare_usage_array;
+	for (i = 0; i < pm->pm_state->pst_max_device_failures; i++) {
 		if (spare_usage_array[i].psu_device_index == device_index) {
 			M0_ASSERT(M0_IN(spare_usage_array[i].psu_device_state,
 						(M0_PNDS_SNS_REBALANCING)));
@@ -794,7 +809,7 @@ M0_INTERNAL void m0_poolmach_event_dump(struct m0_pool_event *e)
 
 M0_INTERNAL void m0_poolmach_event_list_dump(struct m0_poolmach *pm)
 {
-	struct m0_tl *head = &pm->pm_state.pst_events_list;
+	struct m0_tl *head = &pm->pm_state->pst_events_list;
 	struct m0_pool_event_link *scan;
 
 	M0_LOG(dump_level, ">>>>>");
@@ -811,9 +826,9 @@ M0_INTERNAL void m0_poolmach_device_state_dump(struct m0_poolmach *pm)
 {
 	int i;
 	M0_LOG(dump_level, ">>>>>");
-	for (i = 1; i < pm->pm_state.pst_nr_devices; i++) {
+	for (i = 1; i < pm->pm_state->pst_nr_devices; i++) {
 		M0_LOG(dump_level, "%04d:device[%d] state: %d",
-			lno, i, pm->pm_state.pst_devices_array[i].pd_state);
+			lno, i, pm->pm_state->pst_devices_array[i].pd_state);
 		lno++;
 	}
 	M0_LOG(dump_level, "=====");
diff --git a/pool/pool.h b/pool/pool.h
index dc3c285..446578d 100644
--- a/pool/pool.h
+++ b/pool/pool.h
@@ -291,18 +291,18 @@ struct m0_poolmach_state {
  */
 struct m0_poolmach {
 	/** struct m0_persistent_sm  pm_mach; */
-	struct m0_poolmach_state pm_state;
+	struct m0_poolmach_state *pm_state;
 
 	/** the be_seg. if this is NULL, the poolmach is on client. */
-	struct m0_be_seg        *pm_be_seg;
+	struct m0_be_seg         *pm_be_seg;
 
-	struct m0_sm_group      *pm_sm_grp;
+	struct m0_sm_group       *pm_sm_grp;
 
 	/** this pool machine initialized or not */
-	bool                     pm_is_initialised;
+	bool                      pm_is_initialised;
 
 	/** read write lock to protect the whole pool machine */
-	struct m0_rwlock         pm_lock;
+	struct m0_rwlock          pm_lock;
 };
 
 M0_INTERNAL bool
@@ -342,9 +342,9 @@ M0_INTERNAL void m0_poolmach_fini(struct m0_poolmach *pm);
  *        will be copied into pool machine state, and it can
  *        be used or released by caller after call.
  */
-M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach   *pm,
-					  struct m0_pool_event *event,
-					  struct m0_be_tx      *tx);
+M0_INTERNAL int m0_poolmach_state_transit(struct m0_poolmach         *pm,
+					  const struct m0_pool_event *event,
+					  struct m0_be_tx            *tx);
 
 /**
  * Query the state changes between the "from" and "to" version.
diff --git a/pool/pool_store.c b/pool/pool_store.c
index 7d4a37f..e2e0019 100644
--- a/pool/pool_store.c
+++ b/pool/pool_store.c
@@ -64,43 +64,23 @@ struct m0_pool_event_rec {
 
 #ifndef __KERNEL__
 
-static void m0_poolmach_events_load(struct m0_poolmach *pm,
-				    struct m0_poolmach_state *pm_state_on_disk)
-{
-	struct m0_tl *dst_head = &pm->pm_state.pst_events_list;
-	struct m0_tl *src_head = &pm_state_on_disk->pst_events_list;
-	struct m0_pool_event_link *scan;
-	struct m0_pool_event_link *new;
-
-	m0_tl_for(poolmach_events, src_head, scan) {
-		m0_poolmach_event_dump(&scan->pel_event);
-		m0_poolmach_version_dump(&scan->pel_new_version);
-		M0_ALLOC_PTR(new);
-		M0_ASSERT(new != NULL);
-
-		new->pel_event = scan->pel_event;
-		new->pel_new_version = scan->pel_new_version;
-		poolmach_events_tlink_init_at_tail(new, dst_head);
-	} m0_tl_endfor;
-}
-
-
 M0_INTERNAL void m0_poolmach_store_credit(struct m0_poolmach        *pm,
 					  struct m0_be_tx           *tx,
 					  struct m0_be_tx_credit *accum)
 {
 	struct m0_pool_event_link *event_link;
+	struct m0_poolmach_state  *state = pm->pm_state;
 
-	m0_be_tx_credit_add(accum, &M0_BE_TX_CREDIT_TYPE(pm->pm_state));
+	m0_be_tx_credit_add(accum, &M0_BE_TX_CREDIT_TYPE(state));
 	m0_be_tx_credit_add(accum,
-			    &M0_BE_TX_CREDIT(pm->pm_state.pst_nr_nodes,
-				sizeof (*pm->pm_state.pst_nodes_array)));
+			    &M0_BE_TX_CREDIT(state->pst_nr_nodes,
+				sizeof (*state->pst_nodes_array)));
 	m0_be_tx_credit_add(accum,
-			    &M0_BE_TX_CREDIT(pm->pm_state.pst_nr_devices,
-				sizeof (*pm->pm_state.pst_devices_array)));
+			    &M0_BE_TX_CREDIT(state->pst_nr_devices,
+				sizeof (*state->pst_devices_array)));
 	m0_be_tx_credit_add(accum,
-			&M0_BE_TX_CREDIT(pm->pm_state.pst_max_device_failures,
-				sizeof (*pm->pm_state.pst_spare_usage_array)));
+			&M0_BE_TX_CREDIT(state->pst_max_device_failures,
+				sizeof (*state->pst_spare_usage_array)));
 	M0_BE_ALLOC_CREDIT_PTR(event_link, pm->pm_be_seg, accum);
 	m0_be_tx_credit_add(accum, &M0_BE_TX_CREDIT_TYPE(*event_link));
 	m0_be_tx_credit_add(accum, &M0_BE_TX_CREDIT_TYPE(struct m0_tlink));
@@ -116,50 +96,15 @@ M0_INTERNAL int m0_poolmach_store(struct m0_poolmach        *pm,
 				  struct m0_be_tx           *tx,
 				  struct m0_pool_event_link *event_link)
 {
-	struct m0_poolmach_state  *src = &pm->pm_state;
-	struct m0_poolmach_state  *dest;
-	const char                *poolmach_name = "poolmach_state";
+	struct m0_poolmach_state  *dest = pm->pm_state;
 	struct m0_pool_event_link *new_link;
 	int                        rc = 0;
 	M0_ENTRY();
 
-	rc = m0_be_seg_dict_lookup(pm->pm_be_seg, poolmach_name, (void**)&dest);
-	if (rc != 0)
-		return rc;
-	
-	if (dest->pst_nr_nodes != src->pst_nr_nodes ||
-	    dest->pst_nr_devices != src->pst_nr_devices ||
-	    dest->pst_max_node_failures != src->pst_max_node_failures ||
-	    dest->pst_max_device_failures != src->pst_max_device_failures) {
-		M0_LOG(M0_FATAL, "Invalid pool configuration. Using stale pool "
-				 "info? On-disk pool param: %u:%u:%u:%u, "
-				 "Requested pool param: %u:%u:%u:%u",
-				 dest->pst_nr_nodes,
-				 dest->pst_nr_devices,
-				 dest->pst_max_node_failures,
-				 dest->pst_max_device_failures,
-				 src->pst_nr_nodes,
-				 src->pst_nr_devices,
-				 src->pst_max_node_failures,
-				 src->pst_max_device_failures);
-		return -EINVAL;
-	}
 	M0_BE_ALLOC_PTR_SYNC(new_link, pm->pm_be_seg, tx);
 	if (new_link == NULL)
 		return -ENOMEM;
 
-	dest->pst_version             = src->pst_version;
-	dest->pst_nr_nodes            = src->pst_nr_nodes;
-	dest->pst_nr_devices          = src->pst_nr_devices;
-	dest->pst_max_node_failures   = src->pst_max_node_failures;
-	dest->pst_max_device_failures = src->pst_max_device_failures;
-	memcpy(dest->pst_nodes_array, src->pst_nodes_array,
-	       sizeof(struct m0_poolnode) * src->pst_nr_nodes);
-	memcpy(dest->pst_devices_array, src->pst_devices_array,
-	       sizeof(struct m0_pooldev) * src->pst_nr_devices);
-	memcpy(dest->pst_spare_usage_array, src->pst_spare_usage_array,
-	       sizeof(struct m0_pool_spare_usage)*src->pst_max_device_failures);
-
 	*new_link = *event_link;
 	poolmach_events_tlink_init_at_tail(new_link, &dest->pst_events_list);
 
@@ -181,11 +126,10 @@ static int m0_poolmach_load(struct m0_poolmach       *pm,
 			    uint32_t                  max_node_failures,
 			    uint32_t                  max_device_failures)
 {
-	struct m0_poolmach_state *dest = &pm->pm_state;
 	int rc = 0;
 	
 	if (pm_state_on_disk->pst_nr_nodes != nr_nodes ||
-	    pm_state_on_disk->pst_nr_devices != nr_devices ||
+	    pm_state_on_disk->pst_nr_devices != nr_devices + 1 ||
 	    pm_state_on_disk->pst_max_node_failures != max_node_failures ||
 	    pm_state_on_disk->pst_max_device_failures != max_device_failures) {
 		M0_LOG(M0_FATAL, "Invalid pool configuration. Using stale pool "
@@ -202,18 +146,6 @@ static int m0_poolmach_load(struct m0_poolmach       *pm,
 		return -EINVAL;
 	}
 
-	dest->pst_version             = pm_state_on_disk->pst_version;
-	dest->pst_nr_nodes            = pm_state_on_disk->pst_nr_nodes;
-	dest->pst_nr_devices          = pm_state_on_disk->pst_nr_devices;
-	dest->pst_max_node_failures   = pm_state_on_disk->pst_max_node_failures;
-	dest->pst_max_device_failures = pm_state_on_disk->pst_max_device_failures;
-	memcpy(dest->pst_nodes_array, pm_state_on_disk->pst_nodes_array,
-	       sizeof(struct m0_poolnode) * nr_nodes);
-	memcpy(dest->pst_devices_array, pm_state_on_disk->pst_devices_array,
-	       sizeof(struct m0_pooldev) * nr_devices);
-	memcpy(dest->pst_spare_usage_array, pm_state_on_disk->pst_spare_usage_array,
-	       sizeof(struct m0_pool_spare_usage) * max_device_failures);
-	m0_poolmach_events_load(pm, pm_state_on_disk);
 	return rc;
 }
 
@@ -228,11 +160,12 @@ M0_INTERNAL int m0_poolmach_store_init(struct m0_poolmach *pm,
 {
 	struct m0_be_tx_credit      cred = {};
 	struct m0_be_tx            *tx;
-	struct m0_poolmach_state   *pm_state_on_disk;
+	struct m0_poolmach_state   *state;
 	struct m0_poolnode         *nodes_array;
 	struct m0_pooldev          *devices_array;
 	struct m0_pool_spare_usage *spare_usage_array;
 	const char                 *poolmach_name = "poolmach_state";
+	int                         i;
 	int                         rc;
 
 	M0_PRE(!pm->pm_is_initialised);
@@ -243,10 +176,12 @@ M0_INTERNAL int m0_poolmach_store_init(struct m0_poolmach *pm,
 	if (tx == NULL)
 		return -ENOMEM;
 
-	rc = m0_be_seg_dict_lookup(be_seg, poolmach_name, (void**)&pm_state_on_disk);
+	rc = m0_be_seg_dict_lookup(be_seg, poolmach_name, (void**)&state);
 	if (rc == 0) {
-		rc = m0_poolmach_load(pm, pm_state_on_disk, nr_nodes, nr_devices,
+		rc = m0_poolmach_load(pm, state, nr_nodes, nr_devices,
 				      max_node_failures, max_device_failures);
+		if (rc == 0)
+			pm->pm_state = state;
 		goto out;
 	} else if (rc != -ENOENT)
 		goto out;
@@ -254,39 +189,48 @@ M0_INTERNAL int m0_poolmach_store_init(struct m0_poolmach *pm,
 	/* Not found from disk. Let's allocate and insert it */
 	m0_sm_group_lock(sm_grp);
 	m0_be_tx_init(tx, 0, be_seg->bs_domain, sm_grp, NULL, NULL, NULL, NULL);
-	M0_BE_ALLOC_CREDIT_PTR(pm_state_on_disk, be_seg, &cred);
+	M0_BE_ALLOC_CREDIT_PTR(state, be_seg, &cred);
 	M0_BE_ALLOC_CREDIT_ARR(nodes_array, nr_nodes, be_seg, &cred);
-	M0_BE_ALLOC_CREDIT_ARR(devices_array, nr_devices, be_seg, &cred);
+	M0_BE_ALLOC_CREDIT_ARR(devices_array, nr_devices + 1, be_seg, &cred);
 	M0_BE_ALLOC_CREDIT_ARR(spare_usage_array, max_device_failures, be_seg, &cred);
 	m0_be_seg_dict_insert_credit(be_seg, poolmach_name, &cred);
 	m0_be_tx_prep(tx, &cred);
 	rc = m0_be_tx_open_sync(tx);
 	if (rc == 0) {
-		M0_BE_ALLOC_PTR_SYNC(pm_state_on_disk, be_seg, tx);
+		M0_BE_ALLOC_PTR_SYNC(state, be_seg, tx);
 		M0_BE_ALLOC_ARR_SYNC(nodes_array, nr_nodes, be_seg, tx);
-		M0_BE_ALLOC_ARR_SYNC(devices_array, nr_devices, be_seg, tx);
+		M0_BE_ALLOC_ARR_SYNC(devices_array, nr_devices + 1, be_seg, tx);
 		M0_BE_ALLOC_ARR_SYNC(spare_usage_array, max_device_failures, be_seg, tx);
-		M0_ASSERT(pm_state_on_disk != NULL);
+		M0_ASSERT(state != NULL);
 		M0_ASSERT(nodes_array != NULL);
 		M0_ASSERT(devices_array != NULL);
 		M0_ASSERT(spare_usage_array != NULL);
 
 		rc = m0_be_seg_dict_insert(be_seg, tx, poolmach_name,
-					   pm_state_on_disk);
+					   state);
 		M0_ASSERT(rc == 0);
-		*pm_state_on_disk = pm->pm_state;
-		pm_state_on_disk->pst_nodes_array = nodes_array;
-		pm_state_on_disk->pst_devices_array = devices_array;
-		pm_state_on_disk->pst_spare_usage_array = spare_usage_array;
-		poolmach_events_tlist_init(&pm_state_on_disk->pst_events_list);
-		memcpy(nodes_array, pm->pm_state.pst_nodes_array,
-		       sizeof(nodes_array) * nr_nodes);
-		memcpy(devices_array, pm->pm_state.pst_devices_array,
-		       sizeof(devices_array) * nr_devices);
-		memcpy(spare_usage_array, pm->pm_state.pst_spare_usage_array,
-		       sizeof(spare_usage_array) * max_device_failures);
-
-		M0_BE_TX_CAPTURE_PTR(be_seg, tx, pm_state_on_disk);
+		pm->pm_state = state;
+		state->pst_nodes_array       = nodes_array;
+		state->pst_devices_array     = devices_array + 1;
+		state->pst_spare_usage_array = spare_usage_array;
+		for (i = 0; i < state->pst_nr_nodes; i++) {
+			state->pst_nodes_array[i].pn_state = M0_PNDS_ONLINE;
+			state->pst_nodes_array[i].pn_id    = NULL;
+		}
+
+		for (i = 0; i < state->pst_nr_devices; i++) {
+			state->pst_devices_array[i].pd_state = M0_PNDS_ONLINE;
+			state->pst_devices_array[i].pd_id    = NULL;
+			state->pst_devices_array[i].pd_node  = NULL;
+		}
+
+		for (i = 0; i < state->pst_max_device_failures; i++) {
+			state->pst_spare_usage_array[i].psu_device_index =
+						POOL_PM_SPARE_SLOT_UNUSED;
+		}
+		poolmach_events_tlist_init(&state->pst_events_list);
+
+		M0_BE_TX_CAPTURE_PTR(be_seg, tx, state);
 		M0_BE_TX_CAPTURE_ARR(be_seg, tx, nodes_array, nr_nodes);
 		M0_BE_TX_CAPTURE_ARR(be_seg, tx, devices_array, nr_devices);
 		M0_BE_TX_CAPTURE_ARR(be_seg, tx, spare_usage_array, max_device_failures);
diff --git a/sns/cm/cm.c b/sns/cm/cm.c
index a2c1488..68bb1a2 100644
--- a/sns/cm/cm.c
+++ b/sns/cm/cm.c
@@ -523,11 +523,11 @@ M0_INTERNAL int m0_sns_cm_pm_event_post(struct m0_sns_cm *scm,
 	int                         i;
 	int                         rc = 0;
 
-	spare_array = pm->pm_state.pst_spare_usage_array;
+	spare_array = pm->pm_state->pst_spare_usage_array;
 	for (i = 0; spare_array[i].psu_device_index != POOL_PM_SPARE_SLOT_UNUSED; ++i) {
 		transit = false;
 		dev_id = spare_array[i].psu_device_index;
-		dev_array = pm->pm_state.pst_devices_array;
+		dev_array = pm->pm_state->pst_devices_array;
 		switch (state) {
 		case M0_PNDS_SNS_REPAIRING:
 			if (dev_array[dev_id].pd_state == M0_PNDS_FAILED)
diff --git a/sns/cm/repair/ut/net.c b/sns/cm/repair/ut/net.c
index f44ba5d..ce51d72 100644
--- a/sns/cm/repair/ut/net.c
+++ b/sns/cm/repair/ut/net.c
@@ -499,7 +499,7 @@ static void receiver_init()
 	 * Set the state of the failed device to "M0_PNDS_FAILED" in the pool
 	 * machine explicitly.
 	 */
-	ps = &cm->cm_pm->pm_state;
+	ps = cm->cm_pm->pm_state;
 	ps->pst_devices_array[DEV_ID].pd_state = M0_PNDS_FAILED;
 	ps->pst_spare_usage_array[DEV_ID].psu_device_state  =
 	M0_PNDS_SNS_REPAIRING;
diff --git a/sns/parity_repair.c b/sns/parity_repair.c
index 47b772a..2625670 100644
--- a/sns/parity_repair.c
+++ b/sns/parity_repair.c
@@ -176,7 +176,7 @@ M0_INTERNAL int m0_sns_repair_data_map(struct m0_poolmach *pm,
 		 * Fetch the correspinding data/parity unit device index for
 		 * the given spare unit.
 		 */
-		device_index = pm->pm_state.pst_spare_usage_array[spare_id].
+		device_index = pm->pm_state->pst_spare_usage_array[spare_id].
 			psu_device_index;
 
 		if (device_index == POOL_PM_SPARE_SLOT_UNUSED) {
-- 
1.8.3.2

