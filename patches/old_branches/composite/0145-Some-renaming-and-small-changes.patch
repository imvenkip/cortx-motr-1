From d0320861ffed92ec21ee867e83add1e5e6227e7d Mon Sep 17 00:00:00 2001
From: "trupti.patil" <trupti_patil@xyratex.com>
Date: Fri, 24 May 2013 15:55:14 +0530
Subject: [PATCH 145/172] Some renaming and small changes

---
 layout/composite.c       | 217 +++++++++++++++++++++++------------------------
 layout/layout_internal.h |   2 +-
 layout/ut/composite.c    |  53 ++++++------
 layout/ut/layout.c       |  44 +++++-----
 4 files changed, 152 insertions(+), 164 deletions(-)

diff --git a/layout/composite.c b/layout/composite.c
index 6fca606..c95c246 100644
--- a/layout/composite.c
+++ b/layout/composite.c
@@ -120,8 +120,7 @@ enum {
 };
 
 /**
- * Structure used to store extents preallocated during ext_inmem_paste()
- * operation.
+ * Structure used to store extents preallocated during ext_paste() operation.
  */
 struct preallocated_extents {
 		struct m0_composite_layer_extent *ext[PREALLOCATE_NR];
@@ -305,9 +304,9 @@ static void composite_delete(struct m0_layout *l)
 }
 
 /** Adds a layer to the in-memory layout. */
-static int layer_inmem_add(struct m0_composite_layout *cl,
-			   struct m0_layout *sublayout,
-			   struct m0_composite_layer **lr)
+static int layer_add(struct m0_composite_layout *cl,
+		     struct m0_layout *sublayout,
+		     struct m0_composite_layer **lr)
 {
 	struct m0_composite_layer        *layer;
 	struct m0_composite_layer_extent *lr_ext;
@@ -323,7 +322,7 @@ static int layer_inmem_add(struct m0_composite_layout *cl,
 
 	M0_ALLOC_PTR(layer);
 	if (layer == NULL) {
-		m0_layout__log("layer_inmem_add",
+		m0_layout__log("layer_add",
 			       "failed to allocate composite layer",
 			       M0_LAYOUT_ADDB_LOC_COMP_LAYER_ALLOC,
 			       &cl->cl_base.l_addb_ctx, cl->cl_base.l_id,
@@ -344,7 +343,7 @@ static int layer_inmem_add(struct m0_composite_layout *cl,
 	 */
 	M0_ALLOC_PTR(lr_ext);
 	if (lr_ext == NULL) {
-		m0_layout__log("layer_inmem_add",
+		m0_layout__log("layer_add",
 			       "failed to allocate layer extent",
 			       M0_LAYOUT_ADDB_LOC_COMP_LAYER_ALLOC,
 			       &cl->cl_base.l_addb_ctx, cl->cl_base.l_id,
@@ -382,8 +381,8 @@ static void extlist_free(struct m0_tl *extlist, bool is_fini)
 }
 
 /** Deletes the top-most layer from the in-memory layout. */
-static void layer_inmem_delete(struct m0_composite_layout *cl,
-			       struct m0_composite_layer *layer)
+static void layer_delete(struct m0_composite_layout *cl,
+			 struct m0_composite_layer *layer)
 {
 	M0_PRE(layer->clr_idx == cl->cl_layers_nr - 1);
 	M0_ENTRY("lid %llu, layer %lu", (unsigned long long)cl->cl_base.l_id,
@@ -409,7 +408,7 @@ static int composite_populate(struct m0_composite_layout *cl,
 	M0_PRE(m0_layout__invariant(sublayout));
 	M0_ENTRY("lid %llu", (unsigned long long)cl->cl_base.l_id);
 
-	rc = layer_inmem_add(cl, sublayout, &layer);
+	rc = layer_add(cl, sublayout, &layer);
 	if (rc == 0) {
 		M0_ASSERT(layer->clr_idx == 0);
 		m0_layout__populate(&cl->cl_base, user_count);
@@ -471,13 +470,13 @@ static void layers_inmem_delete(struct m0_composite_layout *cl)
 	struct m0_composite_layer *layer_prev;
 	/*
 	 * Start deleting layers from the top-most layer so that the check from
-	 * layer_inmem_delete() that 'it is the top-most layer being deleted'
+	 * layer_delete() that 'it is the top-most layer being deleted'
 	 * remains intact.
 	 */
 	layer = layers_tlist_tail(&cl->cl_layers);
 	while (layer != NULL) {
 		layer_prev = layers_tlist_prev(&cl->cl_layers, layer);
-		layer_inmem_delete(cl, layer);
+		layer_delete(cl, layer);
 		layer = layer_prev;
 	}
 }
@@ -517,7 +516,7 @@ M0_INTERNAL int m0_composite_layer_add(struct m0_composite_layout *cl,
 		 (unsigned long)cl->cl_layers_nr);
 	m0_mutex_lock(&cl->cl_base.l_lock);
 	M0_PRE(cl->cl_layers_nr < M0_COMPOSITE_LAYERS_MAX);
-	rc = layer_inmem_add(cl, sublayout, &layer);
+	rc = layer_add(cl, sublayout, &layer);
 	if (rc != 0) {
 		m0_layout__log("m0_composite_layer_add",
 			       "Failed to add layer",
@@ -564,7 +563,7 @@ M0_INTERNAL void m0_composite_layer_delete(struct m0_composite_layout *cl)
 	layer = layer_find(cl, cl->cl_layers_nr - 1);
 	M0_PRE(m0_tl_forall(ext, lr_ext, &layer->clr_extents,
 			    lr_ext->cle_state == M0_CLRES_HOLE));
-	layer_inmem_delete(cl, layer);
+	layer_delete(cl, layer);
 	m0_mutex_unlock(&cl->cl_base.l_lock);
 	M0_POST(composite_invariant(cl));
 }
@@ -663,14 +662,14 @@ static int sublayout_ids_inbuf_read(struct m0_composite_layout *cl,
 	return 0;
 }
 
-static void ext_inmem_del(struct m0_composite_layer *layer,
-			  struct m0_composite_layer_extent *lr_ext);
-static int ext_inmem_add(struct m0_tl *extlist,
-			 struct m0_layout *l,
-			 const struct m0_ext *ext,
-			 enum m0_composite_layer_ext_state ext_state,
-			 uint32_t add_position,
-			 struct m0_composite_layer_extent *adjacent_lr_ext);
+static void ext_del(struct m0_composite_layer *layer,
+		    struct m0_composite_layer_extent *lr_ext);
+static int ext_add(struct m0_tl *extlist,
+		   struct m0_layout *l,
+		   const struct m0_ext *ext,
+		   enum m0_composite_layer_ext_state ext_state,
+		   uint32_t add_position,
+		   struct m0_composite_layer_extent *adjacent_lr_ext);
 
 /*
  * Reads all the extents associated with each layer for a composite layout,
@@ -701,7 +700,7 @@ static int extents_inbuf_read(struct m0_composite_layout *cl,
 	lr_ext = ext_tlist_head(&layer->clr_extents);
 	M0_ASSERT(lr_ext->cle_ext.e_start == 0 &&
 		  lr_ext->cle_ext.e_end == M0_BINDEX_MAX + 1);
-	ext_inmem_del(layer, lr_ext);
+	ext_del(layer, lr_ext);
 
 	lr_header = m0_bufvec_cursor_addr(cur);
 	m0_bufvec_cursor_move(cur, sizeof *lr_header);
@@ -731,9 +730,9 @@ static int extents_inbuf_read(struct m0_composite_layout *cl,
 				       cl->cl_base.l_id, -ENOMEM);
 			return -EINVAL;
 		}
-		rc = ext_inmem_add(&layer->clr_extents, &cl->cl_base,
-				   &buf_ext->lbe_ext, buf_ext->lbe_state,
-				   ADD_AT_TAIL, NULL);
+		rc = ext_add(&layer->clr_extents, &cl->cl_base,
+			     &buf_ext->lbe_ext, buf_ext->lbe_state,
+			     ADD_AT_TAIL, NULL);
 		if (rc != 0) {
 			M0_LOG(M0_ERROR, "lid %llu, Extent could not be "
 			       "added to the list",
@@ -741,7 +740,7 @@ static int extents_inbuf_read(struct m0_composite_layout *cl,
 			return rc;
 		}
 	}
-	layer->clr_extents_nr =  ext_tlist_length(&layer->clr_extents);
+	layer->clr_extents_nr = ext_tlist_length(&layer->clr_extents);
 	M0_POST(composite_invariant(cl));
 	M0_RETURN(rc);
 }
@@ -804,10 +803,10 @@ static int layers_read(struct m0_composite_layout *cl,
 				populate_done = true;
 			}
 		} else
-			rc = layer_inmem_add(cl, sublayout, &layer);
+			rc = layer_add(cl, sublayout, &layer);
 		/*
 		 * Release the reference added by m0_layout_find(). In case of
-		 * success, layer_inmem_add() has added a reference on this
+		 * success, layer_add() has added a reference on this
 		 * sublayout.
 		 */
 		m0_layout_put(sublayout);
@@ -1008,10 +1007,10 @@ static int composite_encode(struct m0_layout *l,
  * Checks if the exact provided extent with the exact provided state is present
  * in the list of the extents associated with the specified layer.
  */
-static int ext_inmem_find(struct m0_composite_layer *layer,
-			  const struct m0_ext *ext,
-			  enum m0_composite_layer_ext_state expected_ext_state,
-			  struct m0_composite_layer_extent **lr_ext_out)
+static int ext_find(struct m0_composite_layer *layer,
+		    const struct m0_ext *ext,
+		    enum m0_composite_layer_ext_state expected_ext_state,
+		    struct m0_composite_layer_extent **lr_ext_out)
 {
 	struct m0_composite_layer_extent *lr_ext;
 	bool                              ext_encountered;
@@ -1051,13 +1050,13 @@ static int ext_inmem_find(struct m0_composite_layer *layer,
  * Adds an extent to the provided extent list, at the provided position and
  * using the pre-allocated extent.
  */
-static void ext_inmem_add_internal(struct m0_tl *extlist,
-				   struct m0_layout *l,
-				   const struct m0_ext *ext,
-				   enum m0_composite_layer_ext_state ext_state,
-				   uint32_t add_position,
-				   struct m0_composite_layer_extent *adj_lr_ext,
-				   struct m0_composite_layer_extent *lr_ext)
+static void ext_add_internal(struct m0_tl *extlist,
+			     struct m0_layout *l,
+			     const struct m0_ext *ext,
+			     enum m0_composite_layer_ext_state ext_state,
+			     uint32_t add_position,
+			     struct m0_composite_layer_extent *adj_lr_ext,
+			     struct m0_composite_layer_extent *lr_ext)
 {
 	M0_PRE(extlist != NULL);
 	M0_PRE(m0_layout__invariant(l));
@@ -1073,9 +1072,8 @@ static void ext_inmem_add_internal(struct m0_tl *extlist,
 	M0_PRE(lr_ext != NULL);
 
 	M0_ENTRY("lid %llu, e_start %llu, e_end %llu, e_state %llu, "
-		 "add_position %lu, adjacent_ext_start %llu, "
-		 "adjacent_ext_end %llu", (unsigned long long)l->l_id,
-		 (unsigned long long)ext->e_start,
+		 "add_position %lu, adj_ext_start %llu, adj_ext_end %llu",
+		 (unsigned long long)l->l_id, (unsigned long long)ext->e_start,
 		 (unsigned long long)ext->e_end, (unsigned long long)ext_state,
 		 (unsigned long)add_position,
 		 (adj_lr_ext == NULL) ? 0 :
@@ -1098,24 +1096,24 @@ static void ext_inmem_add_internal(struct m0_tl *extlist,
 }
 
 /** Adds an extent to the provided extent list, at the provided position. */
-static int ext_inmem_add(struct m0_tl *extlist,
-			 struct m0_layout *l,
-			 const struct m0_ext *ext,
-			 enum m0_composite_layer_ext_state ext_state,
-			 uint32_t add_position,
-			 struct m0_composite_layer_extent *adjacent_lr_ext)
+static int ext_add(struct m0_tl *extlist,
+		   struct m0_layout *l,
+		   const struct m0_ext *ext,
+		   enum m0_composite_layer_ext_state ext_state,
+		   uint32_t add_position,
+		   struct m0_composite_layer_extent *adjacent_lr_ext) //todo adj
 {
 	struct m0_composite_layer_extent *lr_ext;
 
 	M0_ALLOC_PTR(lr_ext);
 	if (lr_ext == NULL) {
-		m0_layout__log("ext_inmem_add",
+		m0_layout__log("ext_add",
 			       "failed to allocate composite extent",
 			       M0_LAYOUT_ADDB_LOC_COMP_EXT_ADD_INTERNAL,
 			       &l->l_addb_ctx, l->l_id, -ENOMEM);
 		M0_RETURN(-ENOMEM);
 	}
-	ext_inmem_add_internal(extlist, l, ext, ext_state, add_position,
+	ext_add_internal(extlist, l, ext, ext_state, add_position,
 			       adjacent_lr_ext, lr_ext);
 	M0_RETURN(0);
 }
@@ -1181,8 +1179,8 @@ M0_INTERNAL int m0_composite_layer_ext_lookup(
 }
 
 /** Deletes an extent from the extent list associated with the given layer. */
-static void ext_inmem_del(struct m0_composite_layer *layer,
-			  struct m0_composite_layer_extent *lr_ext)
+static void ext_del(struct m0_composite_layer *layer,
+		    struct m0_composite_layer_extent *lr_ext)
 {
 	M0_LOG(M0_DEBUG, "lid %llu, layer %lu, e_start %llu, e_end %llu, "
 	       "e_state %llu", (unsigned long long)layer->clr_cl->l_id,
@@ -1225,16 +1223,16 @@ static void ext_split(struct m0_composite_layer *layer,
 		if (len != 0) {
 			ext.e_start = scan;
 			ext.e_end = scan = scan + len;
-			ext_inmem_add_internal(&layer->clr_extents,
-					       layer->clr_cl, &ext,
-					       vec->iv_index[i],
-					       ADD_BEFORE, lr_ext,
-					       preallocated->ext[preallocated->max_used]); //todo indent
+			ext_add_internal(&layer->clr_extents,
+					 layer->clr_cl, &ext,
+					 vec->iv_index[i],
+					 ADD_BEFORE, lr_ext,
+					 preallocated->ext[preallocated->max_used]); //todo indent
 			preallocated->is_used[preallocated->max_used++] = true;
 			M0_CNT_INC(layer->clr_extents_nr);
 		}
 	}
-	ext_inmem_del(layer, lr_ext);
+	ext_del(layer, lr_ext);
 	M0_LEAVE();
 }
 
@@ -1252,12 +1250,12 @@ static void ext_split(struct m0_composite_layer *layer,
  * - all with the mixture of some with the state M0_CLRES_HOLE and some with
  *   one single state other than M0_CLRES_HOLE.
  */
-static int ext_inmem_validate(struct m0_composite_layout *cl,
-			      struct m0_composite_layer *layer,
-			      const struct m0_ext *ext,
-			      uint64_t new_ext_state,
-			      uint32_t ext_validation_kind,
-			      struct m0_composite_layer_extent **lr_ext_nearest)
+static int ext_validate(struct m0_composite_layout *cl,
+			struct m0_composite_layer *layer,
+			const struct m0_ext *ext,
+			uint64_t new_ext_state,
+			uint32_t ext_validation_kind,
+			struct m0_composite_layer_extent **lr_ext_nearest)
 {
 	struct m0_composite_layer_extent *lr_ext;
 	uint64_t                          first_nonhole_state;
@@ -1353,12 +1351,11 @@ static int ext_inmem_validate(struct m0_composite_layout *cl,
  * efficient! For 'an example illustrating the functioning of m0_emap_paste()',
  * see the note added in ext_indb_write().
  */
-static int ext_inmem_paste(struct m0_composite_layout *cl,
-			   struct m0_composite_layer *layer,
-			   const struct m0_ext *ext,
-			   enum m0_composite_layer_ext_state new_ext_state,
-			   struct m0_composite_layer_extent
-					*lr_ext_to_insert_into)
+static int ext_paste(struct m0_composite_layout *cl,
+		     struct m0_composite_layer *layer,
+		     const struct m0_ext *ext,
+		     enum m0_composite_layer_ext_state new_ext_state,
+		     struct m0_composite_layer_extent *lr_ext_to_insert_into)
 {
 	struct preallocated_extents       preallocated;
 	struct m0_composite_layer_extent *lr_ext;
@@ -1390,7 +1387,7 @@ static int ext_inmem_paste(struct m0_composite_layout *cl,
 		preallocated.is_used[i] = false;
 	}
 	if (rc != 0) {
-		m0_layout__log("ext_inmem_paste",
+		m0_layout__log("ext_paste",
 			       "M0_ALLOC_PTR() failed",
 			       M0_LAYOUT_ADDB_LOC_LIN_ALLOC, /*todo*/
 			       &cl->cl_base.l_addb_ctx,
@@ -1458,7 +1455,7 @@ static int ext_inmem_paste(struct m0_composite_layout *cl,
 				  chunk->e_start : ext->e_start, &preallocated);
 		}
 		if (delete_required)
-			ext_inmem_del(layer, lr_ext_to_del);
+			ext_del(layer, lr_ext_to_del);
 
 		ext0.e_start += consumed;
 		M0_ASSERT(ext0.e_start <= ext0.e_end);
@@ -1480,20 +1477,17 @@ static int ext_inmem_paste(struct m0_composite_layout *cl,
 	 * has been handled above, let's add the ultimate whole extent.
 	 */
 	if (is_ultimate_ext_add) {
-		M0_ASSERT(ext_inmem_find(layer, ext, new_ext_state, &lr_ext) ==
+		M0_ASSERT(ext_find(layer, ext, new_ext_state, &lr_ext) ==
 			  -ENOENT);
 		if (ext->e_start == 0) {
 			M0_ASSERT(prev == NULL);
-			ext_inmem_add_internal(&layer->clr_extents,
-					       &cl->cl_base, ext,
-					       new_ext_state,
-					       ADD_AT_START, NULL,
-					       preallocated.ext[preallocated.max_used]); //todo indent
+			ext_add_internal(&layer->clr_extents, &cl->cl_base,
+					 ext, new_ext_state, ADD_AT_START, NULL,
+					 preallocated.ext[preallocated.max_used]); //todo indent
 		} else {
 			M0_ASSERT(prev != NULL);
-			M0_ASSERT(ext_inmem_find(layer, &prev->cle_ext,
-						 prev->cle_state,
-						 &lr_ext) == 0);
+			M0_ASSERT(ext_find(layer, &prev->cle_ext,
+					   prev->cle_state, &lr_ext) == 0);
 			if (prev->cle_ext.e_end < ext->e_start)
 				/*
 				 * It is possible that as a result of some
@@ -1502,11 +1496,9 @@ static int ext_inmem_paste(struct m0_composite_layout *cl,
 				 */
 				prev = ext_tlist_next(&layer->clr_extents,
 						      prev);
-			ext_inmem_add_internal(&layer->clr_extents,
-					       &cl->cl_base, ext,
-					       new_ext_state,
-					       ADD_AFTER, prev,
-					       preallocated.ext[preallocated.max_used]); //todo indent
+			ext_add_internal(&layer->clr_extents, &cl->cl_base,
+					 ext, new_ext_state, ADD_AFTER, prev,
+				       preallocated.ext[preallocated.max_used]); //todo indent
 		}
 		preallocated.is_used[preallocated.max_used++] = true;
 		M0_CNT_INC(layer->clr_extents_nr);
@@ -1523,11 +1515,11 @@ static int ext_inmem_paste(struct m0_composite_layout *cl,
  * associated with the specified layer'. It internally deletes or truncates
  * the overlappping extents as necessary.
  */
-static int ext_inmem_write(struct m0_composite_layout *cl,
-			   struct m0_composite_layer *layer,
-			   const struct m0_ext *ext,
-			   enum m0_composite_layer_ext_state new_ext_state,
-			   uint32_t ext_validation_kind)
+static int ext_write(struct m0_composite_layout *cl,
+		     struct m0_composite_layer *layer,
+		     const struct m0_ext *ext,
+		     enum m0_composite_layer_ext_state new_ext_state,
+		     uint32_t ext_validation_kind)
 {
 	uint64_t                          lid;
 	struct m0_composite_layer_extent *lr_ext;
@@ -1539,8 +1531,8 @@ static int ext_inmem_write(struct m0_composite_layout *cl,
 
 	lid = cl->cl_base.l_id;
 	/* Validate the 'ext' and find the nearest extent from the list. */
-	rc = ext_inmem_validate(cl, layer, ext, new_ext_state,
-			        ext_validation_kind, &lr_ext_to_insert_into);
+	rc = ext_validate(cl, layer, ext, new_ext_state, ext_validation_kind,
+			  &lr_ext_to_insert_into);
 	if (rc != 0)
 		return rc;
 	M0_ASSERT(lr_ext_to_insert_into != NULL);
@@ -1577,11 +1569,10 @@ static int ext_inmem_write(struct m0_composite_layout *cl,
 		return rc;
 	}
 
-	rc = ext_inmem_paste(cl, layer, ext, new_ext_state,
-			     lr_ext_to_insert_into);
+	rc = ext_paste(cl, layer, ext, new_ext_state, lr_ext_to_insert_into);
 	/* In case of success, the extent has to be present in the list. */
 	M0_POST(ergo(rc == 0,
-		     ext_inmem_find(layer, ext, new_ext_state, &lr_ext) == 0));
+		     ext_find(layer, ext, new_ext_state, &lr_ext) == 0));
 	M0_POST(composite_invariant(cl));
 	M0_LEAVE("lid %llu, layer %lu, rc %d", (unsigned long long)lid,
 		 (unsigned long)layer->clr_idx, rc);
@@ -1610,7 +1601,7 @@ M0_INTERNAL int m0_composite_layer_ext_add(
 		 (unsigned long long)ext_state);
 	m0_mutex_lock(&cl->cl_base.l_lock);
 	layer = layer_find(cl, layer_idx);
-	rc = ext_inmem_write(cl, layer, ext, ext_state, EXT_MERGE_VALIDATION);
+	rc = ext_write(cl, layer, ext, ext_state, EXT_MERGE_VALIDATION);
 	if (rc != 0)
 		m0_layout__log("m0_composite_layer_ext_add",
 			       "failed to add extent",
@@ -1646,7 +1637,7 @@ M0_INTERNAL int m0_composite_layer_ext_state_update(
 		 (unsigned long long)ext->e_end, (unsigned long long)new_state);
 	m0_mutex_lock(&cl->cl_base.l_lock);
 	layer = layer_find(cl, layer_idx);
-	rc = ext_inmem_write(cl, layer, ext, new_state, EXT_MERGE_VALIDATION);
+	rc = ext_write(cl, layer, ext, new_state, EXT_MERGE_VALIDATION);
 	if (rc != 0)
 		m0_layout__log("m0_composite_layer_ext_state_update",
 			       "failed to update extent state",
@@ -1681,7 +1672,7 @@ M0_INTERNAL int m0_composite_layer_ext_delete(struct m0_composite_layout *cl,
 	m0_mutex_lock(&cl->cl_base.l_lock);
 	layer = layer_find(cl, layer_idx);
 
-	rc = ext_inmem_write(cl, layer, ext, M0_CLRES_HOLE, EXT_DEL_VALIDATION);
+	rc = ext_write(cl, layer, ext, M0_CLRES_HOLE, EXT_DEL_VALIDATION);
 	if (rc != 0)
 		m0_layout__log("m0_composite_layer_ext_delete",
 			       "failed to write extent",
@@ -1726,7 +1717,7 @@ static m0_bcount_t composite_bufsize(const struct m0_layout *l)
 	return sizeof(struct m0_layout_rec) +
 		sizeof(struct m0_layout_composite_rec) +
 		(cl->cl_layers_nr * (sizeof l->l_id +
-				    sizeof(struct layer_header))) + bufsize;
+				     sizeof(struct layer_header))) + bufsize;
 }
 
 /** Implementation of lto_max_recsize() for COMPOSITE layout type. */
@@ -1738,6 +1729,7 @@ static m0_bcount_t composite_max_recsize(struct m0_layout_domain *dom)
 }
 
 /* DB related routines start here. */
+/** Sets prefix with the given lid and layer id. */
 static void prefix_set(struct layout_prefix *prefix,
 		       uint64_t composite_lid,
 		       uint32_t layer_idx)
@@ -1939,7 +1931,7 @@ static int extents_indb_read(struct m0_composite_layout *cl,
 	lr_ext = ext_tlist_head(&layer->clr_extents);
 	M0_ASSERT(lr_ext->cle_ext.e_start == 0 &&
 		 lr_ext->cle_ext.e_end == M0_BINDEX_MAX + 1);
-	ext_inmem_del(layer, lr_ext);
+	ext_del(layer, lr_ext);
 
 	l = &cl->cl_base;
 	emap = emap_from_cl(cl);
@@ -1966,14 +1958,14 @@ static int extents_indb_read(struct m0_composite_layout *cl,
 			break;
 		}
 
-		rc = ext_inmem_add(&layer->clr_extents, l, &seg->ee_ext,
-				   seg->ee_val, ADD_AT_TAIL, NULL);
+		rc = ext_add(&layer->clr_extents, l, &seg->ee_ext, seg->ee_val,
+			     ADD_AT_TAIL, NULL);
 		if (rc != 0 || m0_emap_ext_is_last(&seg->ee_ext))
 			break;
 		m0_emap_next(&it);
 		seg = m0_emap_seg_get(&it);
 	}
-	layer->clr_extents_nr =  ext_tlist_length(&layer->clr_extents);
+	layer->clr_extents_nr = ext_tlist_length(&layer->clr_extents);
 	m0_emap_close(&it);
 	M0_RETURN(rc);
 }
@@ -2023,7 +2015,7 @@ static int single_ext_indb_write(struct m0_composite_layout *cl,
 	int                    rc;
 	struct m0_ext          ext = {
 		.e_start = 0,
-		.e_end = M0_BINDEX_MAX + 1
+		.e_end   = M0_BINDEX_MAX + 1
 	};
 
 	M0_ENTRY("lid %llu, layer_idx %lu",
@@ -2059,7 +2051,7 @@ err2_injected:
 }
 
 /**
- * This is a check for an error that a layer that is asked to be deleted has
+ * This is a check for an error if a layer that is asked to be deleted has
  * some valid extents associated with it in its DB version.
  */
 static int layer_indb_delete_verify(struct m0_composite_layout *cl,
@@ -2175,11 +2167,12 @@ err1_injected:
 		rc = sublayout_user_count_dec(cl, sublayout_id, sublayout,
 					      in_update_path);
 		if (rc != 0)
-			m0_layout__log(
-			      "layer_indb_delete",
-			      "failed to decrement user count for a sublayout",
-			      M0_LAYOUT_ADDB_LOC_COMP_LAYER_INDB_DEL,
-			      &cl->cl_base.l_addb_ctx, cl->cl_base.l_id, rc);
+			m0_layout__log("layer_indb_delete",
+				       "failed to decrement user count for a "
+				       "sublayout",
+				       M0_LAYOUT_ADDB_LOC_COMP_LAYER_INDB_DEL,
+				       &cl->cl_base.l_addb_ctx,
+				       cl->cl_base.l_id, rc);
 	} else
 		m0_layout__log("layer_indb_delete",
 			       "failed to delete from layer_emap",
diff --git a/layout/layout_internal.h b/layout/layout_internal.h
index 336cf08..23d1690 100644
--- a/layout/layout_internal.h
+++ b/layout/layout_internal.h
@@ -53,7 +53,7 @@ enum {
 
 	/**
 	 * Number of extents required to be preallocated during an
-	 * ext_inmem_paste() operation. It is 2 * 3 + 1 that is
+	 * ext_paste() operation. It is 2 * 3 + 1 that is
 	 * "max_nr_of_split_operations_those_can_take_place *
 	 *  max_nr_of_extents_required_for_one_split_op +
 	 *  required_for_adding_the_ultimate_extent".
diff --git a/layout/ut/composite.c b/layout/ut/composite.c
index 4054af8..587f0aa 100644
--- a/layout/ut/composite.c
+++ b/layout/ut/composite.c
@@ -1577,10 +1577,10 @@ static int ext_op_pre(enum extent_operation eop,
 	} else {
 		M0_UT_ASSERT(rc_tmp == 0);
 		if (extent_kind == EXACT_EXISTING) {
+			//todo use m0_ext_equal()
 			M0_UT_ASSERT(ext_to_operate->e_start ==
 				     ext_lookup.e_start &&
-				     ext_to_operate->e_end ==
-				     ext_lookup.e_end);
+				     ext_to_operate->e_end == ext_lookup.e_end);
 		} else {
 			M0_UT_ASSERT(ext_lookup.e_start <= *offset_to_operate);
 			M0_UT_ASSERT(ext_lookup.e_end > *offset_to_operate);
@@ -2118,76 +2118,71 @@ void test_layer_ext_ops_composite_failure(uint64_t base_lid,
 
 #if 0 //todo Need to choose ext_to_op such that paste is used
 	/*
-	 * Simulate memory allocation error in the path of ext_inmem_add().
+	 * Simulate memory allocation error in the path of ext_add().
 	 * This test exercises restoring the original extent list due to
 	 * encountering error while adding one of the overlapping extents.
 	 */
 	lid = base_lid + 22;
 #if 0 //todo
-	m0_fi_enable_off_n_on_m("ext_inmem_add", "alloc_ptr_fail/lr_ext",
-				82, 1);
+	m0_fi_enable_off_n_on_m("ext_add", "alloc_ptr_fail/lr_ext", 82, 1);
 #endif
-	m0_fi_enable_off_n_on_m("ext_inmem_paste",
+	m0_fi_enable_off_n_on_m("ext_paste",
 			        "alloc_ptr_fail/preallocated.ext[i]", 112, 1);
 	rc = test_ext_add(lid, domain, 3, 6,
 			  !CONTIGUOUS_EXTENTS, OVERLAPPING_LEFT,
 			  M0_CLRES_VALID, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("ext_inmem_paste", "alloc_ptr_fail/lr_ext");
+	m0_fi_disable("ext_paste", "alloc_ptr_fail/lr_ext");
 #endif
 
 #if 0 //todo
 	/*
-	 * Simulate memory allocation in ext_inmem_add() that is in the path of
-	 * ext_inmem_write().
-	 * This test exercises error in the code part from ext_inmem_write()
-	 * that makes a copy of the original extent list so that it can be
+	 * Simulate memory allocation in ext_add() that is in the path of
+	 * ext_write().
+	 * This test exercises error in the code part from ext_write() that
+	 * makes a copy of the original extent list so that it can be
 	 * restored at a later point, if required.
 	 */
 	lid = base_lid + 23;
-	m0_fi_enable_off_n_on_m("ext_inmem_add", "alloc_ptr_fail/lr_ext",
-				80, 1);
+	m0_fi_enable_off_n_on_m("ext_add", "alloc_ptr_fail/lr_ext", 80, 1);
 	rc = test_ext_add(lid, domain, 3, 6,
 			  !CONTIGUOUS_EXTENTS, OVERLAPPING_LEFT,
 			  M0_CLRES_VALID, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("ext_inmem_add", "alloc_ptr_fail/lr_ext");
+	m0_fi_disable("ext_add", "alloc_ptr_fail/lr_ext");
 #endif
 
 #if 0 //todo
 	/*
-	 * Simulate memory allocation in ext_inmem_add() that is in the path of
-	 * ext_inmem_add().
-	 * This test exercises error in ext_inmem_add() such that its
-	 * internally called ext_inmem_add() faces error.
+	 * Simulate memory allocation in ext_add() that is in the path of
+	 * ext_add().
+	 * This test exercises error in ext_add() such that its
+	 * internally called ext_add() faces error.
 	 */
 	lid = base_lid + 24;
-	m0_fi_enable_off_n_on_m("ext_inmem_add", "alloc_ptr_fail/lr_ext",
-				140, 1);
+	m0_fi_enable_off_n_on_m("ext_add", "alloc_ptr_fail/lr_ext", 140, 1);
 	rc = test_ext_add(lid, domain, 4, 7,
 			  !CONTIGUOUS_EXTENTS, OVERLAPPING_RIGHT,
 			  M0_CLRES_VALID, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("ext_inmem_add", "alloc_ptr_fail/lr_ext");
+	m0_fi_disable("ext_add", "alloc_ptr_fail/lr_ext");
 #endif
 
 #if 0
 	/*
-	 * Simulate an exception in ext_inmem_add() such that
+	 * Simulate an exception in ext_add() such that
 	 * lr_ext_to_insert_after is NULL, lr_ext_to_insert_before is non-NULL
-	 * and then memory allocation in ext_inmem_add() that is in the path of
-	 * ext_inmem_add() faces error.
+	 * and then memory allocation in ext_add() that is in the path of
+	 * ext_add() faces error.
 	 */
 	lid = base_lid + 25;
-	m0_fi_enable_once("ext_inmem_add",
-			  "insert_after_null_insert_before_nonnull");
-	m0_fi_enable_off_n_on_m("ext_inmem_add", "alloc_ptr_fail/lr_ext",
-				140, 1);
+	m0_fi_enable_once("ext_add", "insert_after_null_insert_before_nonnull");
+	m0_fi_enable_off_n_on_m("ext_add", "alloc_ptr_fail/lr_ext", 140, 1);
 	rc = test_ext_add(lid, domain, 4, 7,
 			  !CONTIGUOUS_EXTENTS, OVERLAPPING_RIGHT,
 			  M0_CLRES_VALID, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("ext_inmem_add", "alloc_ptr_fail/lr_ext");
+	m0_fi_disable("ext_add", "alloc_ptr_fail/lr_ext");
 #endif
 
 	/*
diff --git a/layout/ut/layout.c b/layout/ut/layout.c
index b926b6c..7e316d1 100644
--- a/layout/ut/layout.c
+++ b/layout/ut/layout.c
@@ -595,20 +595,20 @@ static void test_build_failure(void)
 
 	/*
 	 * Simulate layer memory allocation failure in the first invokation of
-	 * layer_inmem_add() that is in the path of m0_composite_build().
+	 * layer_add() that is in the path of m0_composite_build().
 	 */
 	lid = 2022;
-	m0_fi_enable_once("layer_inmem_add", "alloc_ptr_fail/layer");
+	m0_fi_enable_once("layer_add", "alloc_ptr_fail/layer");
 	rc = test_build_composite(lid, &domain, 5, !CONTIGUOUS_EXTENTS,
 				  FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
 
 	/*
 	 * Simulate lr_ext memory allocation failure in the first invokation of
-	 * layer_inmem_add() that is in the path of m0_composite_build().
+	 * layer_add() that is in the path of m0_composite_build().
 	 */
 	lid = 2023;
-	m0_fi_enable_once("layer_inmem_add", "alloc_ptr_fail/lr_ext");
+	m0_fi_enable_once("layer_add", "alloc_ptr_fail/lr_ext");
 	rc = test_build_composite(lid, &domain, 5, !CONTIGUOUS_EXTENTS,
 				  FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
@@ -792,7 +792,7 @@ static void test_decode_failure(void)
 	 * extents_inbuf_read().
 	 */
 	lid = 4024;
-	m0_fi_enable_once("ext_inmem_add", "alloc_ptr_fail/lr_ext");
+	m0_fi_enable_once("ext_add", "alloc_ptr_fail/lr_ext");
 	rc = test_decode_composite(lid, &domain, 5, 6,
 				   !CONTIGUOUS_EXTENTS, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
@@ -802,21 +802,21 @@ static void test_decode_failure(void)
 	 * in the path of composite_populate()
 	 */
 	lid = 4025;
-	m0_fi_enable_off_n_on_m("layer_inmem_add", "alloc_ptr_fail/layer",
+	m0_fi_enable_off_n_on_m("layer_add", "alloc_ptr_fail/layer",
 				2 /* composite_sublayouts nr */, 1);
 	rc = test_decode_composite(lid, &domain, 5, 6,
 				   !CONTIGUOUS_EXTENTS, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("layer_inmem_add", "alloc_ptr_fail/layer");
+	m0_fi_disable("layer_add", "alloc_ptr_fail/layer");
 
 	/* Simulate memory allocation failure for the first layer addition. */
 	lid = 4026;
-	m0_fi_enable_off_n_on_m("layer_inmem_add", "alloc_ptr_fail/layer",
+	m0_fi_enable_off_n_on_m("layer_add", "alloc_ptr_fail/layer",
 				3 /* 1 + composite_sublayouts nr */, 1);
 	rc = test_decode_composite(lid, &domain, 5, 6,
 				   !CONTIGUOUS_EXTENTS, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("layer_inmem_add", "alloc_ptr_fail/layer");
+	m0_fi_disable("layer_add", "alloc_ptr_fail/layer");
 
 	/* Simulate sublayout find error while reading the zeroth layer. */
 	lid = 4027;
@@ -1431,13 +1431,13 @@ static void test_layer_ops_failure(void)
 
 	/* Simulate memory allocation error while adding a layer. */
 	lid = 15001;
-	m0_fi_enable_off_n_on_m("layer_inmem_add", "alloc_ptr_fail/layer",
+	m0_fi_enable_off_n_on_m("layer_add", "alloc_ptr_fail/layer",
 				3 /* 1 + composite_sublayouts nr */, 1);
 	rc = test_layer_ops_composite(lid, &domain, 5, 8,
 				      LAYER_ADD_FAILURE_TEST,
 				      !LAYER_DEL_FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("layer_inmem_add", "alloc_ptr_fail/layer");
+	m0_fi_disable("layer_add", "alloc_ptr_fail/layer");
 }
 
 /**
@@ -1665,41 +1665,41 @@ static void test_lookup_failure(void)
 	M0_UT_ASSERT(rc == -EPROTO);
 
 	/*
-	 * Simulate layer_inmem_add() failure for its first invokation that is
+	 * Simulate layer_add() failure for its first invokation that is
 	 * in the path of composite_decode().
 	 */
 	lid = 19021;
-	m0_fi_enable_off_n_on_m("layer_inmem_add", "alloc_ptr_fail/layer",
+	m0_fi_enable_off_n_on_m("layer_add", "alloc_ptr_fail/layer",
 				6 /* layers_nr + composite_sublayouts nr */, 1);
 	rc = test_lookup_composite(lid, &domain, 4, 5, CONTIGUOUS_EXTENTS,
 				   EXISTING_TEST, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("layer_inmem_add", "alloc_ptr_fail/layer");
+	m0_fi_disable("layer_add", "alloc_ptr_fail/layer");
 
 	/*
-	 * Simulate layer_inmem_add() failure for its second invokation that is
+	 * Simulate layer_add() failure for its second invokation that is
 	 * in the path of composite_decode().
 	 */
 	lid = 19022;
-	m0_fi_enable_off_n_on_m("layer_inmem_add", "alloc_ptr_fail/layer",
+	m0_fi_enable_off_n_on_m("layer_add", "alloc_ptr_fail/layer",
 				7 /* layers_nr + 1 + composite_sublayouts nr */,
 				1);
 	rc = test_lookup_composite(lid, &domain, 4, 5, CONTIGUOUS_EXTENTS,
 				   EXISTING_TEST, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("layer_inmem_add", "alloc_ptr_fail/layer");
+	m0_fi_disable("layer_add", "alloc_ptr_fail/layer");
 
 	/*
-	 * Simulate layer_inmem_add() failure for the last layer addition
+	 * Simulate layer_add() failure for the last layer addition
 	 * that is in the path of composite_decode().
 	 */
 	lid = 19023;
-	m0_fi_enable_off_n_on_m("layer_inmem_add", "alloc_ptr_fail/layer",
+	m0_fi_enable_off_n_on_m("layer_add", "alloc_ptr_fail/layer",
 				7 /* 2 * layers_nr - 1) */, 1);
 	rc = test_lookup_composite(lid, &domain, 4, 5, CONTIGUOUS_EXTENTS,
 				   EXISTING_TEST, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("layer_inmem_add", "alloc_ptr_fail/layer");
+	m0_fi_disable("layer_add", "alloc_ptr_fail/layer");
 
 #if 0 //todo
 	/*
@@ -1707,12 +1707,12 @@ static void test_lookup_failure(void)
 	 * extents_indb_read().
 	 */
 	lid = 19024;
-	m0_fi_enable_off_n_on_m("ext_inmem_add", "alloc_ptr_fail/lr_ext",
+	m0_fi_enable_off_n_on_m("ext_add", "alloc_ptr_fail/lr_ext",
 				80 /* layers_nr * extents_nr * 4 */, 1);
 	rc = test_lookup_composite(lid, &domain, 4, 5, CONTIGUOUS_EXTENTS,
 				   EXISTING_TEST, FAILURE_TEST);
 	M0_UT_ASSERT(rc == -ENOMEM);
-	m0_fi_disable("ext_inmem_add", "alloc_ptr_fail/lr_ext");
+	m0_fi_disable("ext_add", "alloc_ptr_fail/lr_ext");
 #endif
 
 	/*
-- 
1.8.3.2

