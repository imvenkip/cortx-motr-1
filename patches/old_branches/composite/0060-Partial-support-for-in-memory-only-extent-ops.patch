From d483ad5c8895661519808716253cb33ce5752cfa Mon Sep 17 00:00:00 2001
From: "trupti.patil" <trupti_patil@xyratex.com>
Date: Wed, 30 Jan 2013 18:49:17 +0530
Subject: [PATCH 060/172] Partial support for in memory only extent ops

---
 layout/composite.c    | 705 ++++++++++++++++++++++++++++++++++++++++++++++----
 layout/composite.h    |   3 +
 layout/ut/composite.c | 348 ++++++++++++++++++-------
 layout/ut/composite.h |  12 +-
 layout/ut/layout.c    |  86 ++++++
 5 files changed, 1015 insertions(+), 139 deletions(-)

diff --git a/layout/composite.c b/layout/composite.c
index 3508f49..2ceed6e 100644
--- a/layout/composite.c
+++ b/layout/composite.c
@@ -190,6 +190,14 @@ static bool layer_invariant(const struct m0_composite_layer *layer)
 {
 	struct m0_composite_layer_extent *extent;
 	m0_bindex_t                       addr = 0;
+	//todo uint32_t                          i = 0;
+
+	//todo Shall do some more checks like clr_extents_nr etc
+
+	if (layer->clr_extents == NULL ||
+	    layer->clr_extents_nr !=
+	    m0_composite_layer_ext_tlist_length(layer->clr_extents))
+		return false;
 
 	/*
 	 * Since assignment can not be performed in a m0_tl_forall() loop,
@@ -198,6 +206,12 @@ static bool layer_invariant(const struct m0_composite_layer *layer)
 	m0_tl_for(m0_composite_layer_ext, layer->clr_extents, extent) {
 		M0_ASSERT(extent->cle_ext.e_start >= addr);
 		addr = extent->cle_ext.e_start;
+#if 0
+		M0_ASSERT(ergo(i == 0, extent->cle_ext.e_start == 0));
+		M0_ASSERT(ergo(i == layer->clr_extents_nr - 1,
+			  extent->cle_ext.e_end == M0_BINDEX_MAX));
+		++i;
+#endif
 	} m0_tl_endfor;
 	return true;
 }
@@ -585,6 +599,8 @@ enum extent_op {
 };
 
 #ifndef __KERNEL__
+//todo check placement of this and a few of the following functions
+/* todo The extent is confirmed to be non-overlapping. */
 static int ext_in_memory_add(struct m0_composite_layer *layer,
 			     const struct m0_ext *ext,
 			     uint64_t ext_state)
@@ -602,6 +618,16 @@ static int ext_in_memory_add(struct m0_composite_layer *layer,
 		 (unsigned long long)ext->e_end,
 		 (unsigned long long)ext_state);
 
+#ifndef __KERNEL__
+	printf("ext_in_memory_add(): lid %llu, layer %lu, e_start %llu, "
+		"e_end %llu, e_state %llu\n",
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx,
+		 (unsigned long long)ext->e_start,
+		 (unsigned long long)ext->e_end,
+		 (unsigned long long)ext_state);
+#endif
+
 	ext_to_insert_before = NULL;
 	ext_to_insert_after = NULL;
 
@@ -638,6 +664,7 @@ static int ext_in_memory_add(struct m0_composite_layer *layer,
 	M0_CNT_INC(layer->clr_extents_nr);
 	M0_RETURN(0);
 }
+#endif
 
 static int ext_in_memory_delete(struct m0_composite_layer *layer,
 				const struct m0_ext *ext,
@@ -648,6 +675,16 @@ static int ext_in_memory_delete(struct m0_composite_layer *layer,
 	bool                              lr_ext_to_delete_found;
 	int                               rc;
 
+#ifndef __KERNEL__
+	printf("ext_in_memory_delete(): lid %llu, layer %lu, "
+		"e_start %llu, e_end %llu, old_e_state %llu\n",
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx,
+		 (unsigned long long)ext->e_start,
+		 (unsigned long long)ext->e_end,
+		 (unsigned long long)old_ext_state);
+#endif
+
 	M0_ENTRY("lid %llu, layer %lu, e_start %llu, e_end %llu, "
 		 "old_e_state %llu",
 		 (unsigned long long)layer->clr_l->l_id,
@@ -661,9 +698,19 @@ static int ext_in_memory_delete(struct m0_composite_layer *layer,
 		if (ext->e_start > lr_ext->cle_ext.e_end)
 			continue;
 		if (ext->e_start == lr_ext->cle_ext.e_start) {
-			lr_ext_to_delete = lr_ext;
-			lr_ext_to_delete_found = true;
-			break;
+			if (ext->e_end == lr_ext->cle_ext.e_end) {
+				lr_ext_to_delete = lr_ext;
+				lr_ext_to_delete_found = true;
+				break;
+			} else
+				/*
+				 * It is only during the process of an extent
+				 * getting added by splitting some existing
+				 * extent, when there could be two extents
+				 * starting with the same offset. So, this
+				 * continue to find that other exact extent.
+				 */
+				continue;
 		}
 	} m0_tl_endfor;
 
@@ -674,6 +721,12 @@ static int ext_in_memory_delete(struct m0_composite_layer *layer,
 		m0_free(lr_ext_to_delete);
 		M0_CNT_DEC(layer->clr_extents_nr);
 		rc = 0;
+		/*
+		 * todo Once I start storing the invalid extents in the
+		 * in-memory version of the extents list, delete (for in-memory
+		 * only) will need to add an equivalent extent with invalid
+		 * state.
+		 */
 	} else
 		rc = -ENOENT;
 	M0_RETURN(rc);
@@ -718,37 +771,92 @@ static int ext_in_memory_find(struct m0_composite_layer *layer,
 	M0_RETURN(rc);
 }
 
+#ifndef __KERNEL__
+/**
+ * Trims the existing extent as requested.
+ * - If it is an operation on only the in-memory version of the extent list,
+ *   then the remaining part of the extent is added back so that the subsequent
+ *   processing can take place on that part. (todo Possibly not req'd, not
+ *   even the is_in_memory_only_op flag.)
+ * - In case of the DB version of the extent list that is emap, addition
+ *   of applicable part of the extent is handled by accumulatively adding the
+ *   required extents (maximum upto 3 of them) towards the end of
+ *   m0_emap_paste().
+ */
 static int ext_in_memory_trim(struct m0_composite_layer *layer,
 			      enum extent_op extent_op,
-			      const struct m0_emap_seg *seg,
-			      const struct m0_ext *ext)
+			      const struct m0_ext *ext_to_trim,
+			      uint64_t ext_state,
+			      const struct m0_ext *trim_reference_ext,
+			      bool is_in_memory_only_op)
 {
 	struct m0_composite_layer_extent *lr_ext;
+	struct m0_ext                     ext_to_add;
+	m0_bindex_t                       tmp;
 	int                               rc;
 
 	M0_PRE(M0_IN(extent_op, (CUT_LEFT, CUT_RIGHT)));
 	M0_ENTRY("lid %llu, layer %lu, extent_op %d, "
-		 "seg_e_start %llu, seg_e_end %llu, seg_val %llu, "
-		 "e_start %llu, e_end %llu",
+		 "ext_to_trim_start %llu, ext_to_trim_end %llu, "
+		 "ext_state %llu, "
+		 "trim_ref_ext_start %llu, trim_ref_ext_end %llu",
 		 (unsigned long long)layer->clr_l->l_id,
 		 (unsigned long)layer->clr_idx, extent_op,
-		 (unsigned long long)seg->ee_ext.e_start,
-		 (unsigned long long)seg->ee_ext.e_end,
-		 (unsigned long long)seg->ee_val,
-		 (unsigned long long)ext->e_start,
-		 (unsigned long long)ext->e_end);
+		 (unsigned long long)ext_to_trim->e_start,
+		 (unsigned long long)ext_to_trim->e_end,
+		 (unsigned long long)ext_state,
+		 (unsigned long long)trim_reference_ext->e_start,
+		 (unsigned long long)trim_reference_ext->e_end);
 
-	rc = ext_in_memory_find(layer, &seg->ee_ext, seg->ee_val, &lr_ext);
+#ifndef __KERNEL__
+	printf("ext_in_memory_trim(): lid %llu, layer %lu, extent_op %d, "
+		 "ext_to_trim_start %llu, ext_to_trim_end %llu, "
+		 "ext_state %llu, "
+		 "trim_ref_ext_start %llu, trim_ref_ext_end %llu, "
+		 "in_memory_only_op %d\n",
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx, extent_op,
+		 (unsigned long long)ext_to_trim->e_start,
+		 (unsigned long long)ext_to_trim->e_end,
+		 (unsigned long long)ext_state,
+		 (unsigned long long)trim_reference_ext->e_start,
+		 (unsigned long long)trim_reference_ext->e_end,
+		 is_in_memory_only_op ? 1 : 0);
+#endif
+
+	rc = ext_in_memory_find(layer, ext_to_trim, ext_state, &lr_ext);
+	M0_ASSERT(rc == 0); //todo rm
 	if (rc == 0) {
-		M0_ASSERT(lr_ext->cle_ext.e_start <= ext->e_start);
-		M0_ASSERT(lr_ext->cle_ext.e_end >= ext->e_end);
-
-		if (extent_op == CUT_LEFT)
-			/* Retain left part of the existing segment. */
-			lr_ext->cle_ext.e_end = ext->e_start;
-		else
-			/* Retain right part of the existing segment. */
-			lr_ext->cle_ext.e_start = ext->e_end;
+		M0_ASSERT(lr_ext->cle_ext.e_start <=
+			  trim_reference_ext->e_start);
+		M0_ASSERT(lr_ext->cle_ext.e_end >= trim_reference_ext->e_end);
+
+		if (extent_op == CUT_LEFT) {
+			tmp = lr_ext->cle_ext.e_end;
+			/* Retain left part of the existing extent. */
+			lr_ext->cle_ext.e_end = trim_reference_ext->e_start;
+			if (is_in_memory_only_op) {
+				/* Add back the remaining right part. */
+				ext_to_add.e_start =
+					trim_reference_ext->e_start;
+				ext_to_add.e_end = tmp;
+				rc = ext_in_memory_add(layer, &ext_to_add,
+						       ext_state);
+				M0_ASSERT(rc == 0); //todo Handle
+			}
+		} else {
+			tmp = lr_ext->cle_ext.e_start;
+			/* Retain right part of the existing extent. */
+			lr_ext->cle_ext.e_start = trim_reference_ext->e_end;
+			if (is_in_memory_only_op) {
+				/* Add back the remaining left part. */
+				ext_to_add.e_start = tmp;
+				ext_to_add.e_end = trim_reference_ext->e_end;
+				rc = ext_in_memory_add(layer, &ext_to_add,
+						       ext_state);
+				M0_ASSERT(rc == 0); //todo Handle
+			}
+		}
 	}
 	M0_RETURN(rc);
 }
@@ -787,7 +895,8 @@ static int ext_in_memory_adjust(struct m0_composite_layer *layer,
 		 */
 		rc = ext_in_memory_delete(layer, &seg->ee_ext, seg->ee_val);
 	else
-		rc = ext_in_memory_trim(layer, extent_op, seg, ext);
+		rc = ext_in_memory_trim(layer, extent_op,
+					&seg->ee_ext, seg->ee_val, ext, false);
 	M0_RETURN(rc);
 }
 #endif /* __KERNEL__ */
@@ -1717,6 +1826,7 @@ static void comp_layout_in_buf_write(const struct m0_composite_layout *cl,
 	/* Write composite layout header into the buffer. */
 	M0_ASSERT(m0_bufvec_cursor_step(out) >= sizeof cl_header);
 	cl_header.ch_layers_nr = cl->cl_layers_nr;
+	cl_header.ch_pad = 0;
 	nbytes = m0_bufvec_cursor_copyto(out, &cl_header, sizeof cl_header);
 	M0_ASSERT(nbytes == sizeof cl_header);
 
@@ -1730,6 +1840,7 @@ static void comp_layout_in_buf_write(const struct m0_composite_layout *cl,
 		lr_header.clh_lid = layer->clr_l->l_id;
 		lr_header.clh_idx = layer->clr_idx;
 		lr_header.clh_extents_nr = layer->clr_extents_nr;
+		lr_header.clh_pad = 0;
 		nbytes = m0_bufvec_cursor_copyto(out, &lr_header,
 						 sizeof lr_header);
 		m0_tl_for(m0_composite_layer_ext, layer->clr_extents, lr_ext) {
@@ -1898,33 +2009,511 @@ M0_INTERNAL int m0_composite_layer_ext_lookup(struct m0_composite_layout *cl,
 	return rc;
 }
 
-M0_INTERNAL int m0_composite_layer_ext_add(struct m0_composite_layout *cl,
-					   uint32_t layer_idx,
-					   const struct m0_ext *ext,
-					   struct m0_db_tx *tx)
+//to Use this fn where applicable to avoid code duplication e.g. in
+//extlist_in_buf_read() but this adds before and not at tail. So, a flag will
+//be required
+static int ext_add(struct m0_composite_layer *layer,
+		   struct m0_composite_layer_extent *lr_ext,
+		   struct m0_ext *ext,
+		   uint64_t ext_state)
 {
-	struct m0_emap            *emap;
-	struct m0_emap_cursor      it;
-	struct m0_composite_layer *layer;
-	struct layout_prefix       prefix;
-	int                        rc;
+	struct m0_composite_layer_extent *lr_ext1;
+	struct m0_composite_layer_extent *lr_ext2; //todo rm
+	int                               rc; //todo rm
+
+#if 1 //todo rm
+	M0_ASSERT(m0_composite_layer_ext_tlink_is_in(lr_ext));
+	rc = ext_in_memory_find(layer, &lr_ext->cle_ext, lr_ext->cle_state,
+				&lr_ext2);
+	M0_ASSERT(rc == 0);
+#endif
+
+#ifndef __KERNEL__
+	printf("ext_add(): lr_ext_start %llu, lr_ext_end %llu, "
+		"e_start %llu, e_end %llu\n",
+		(unsigned long long)lr_ext->cle_ext.e_start,
+		(unsigned long long)lr_ext->cle_ext.e_end,
+		(unsigned long long)ext->e_start,
+		(unsigned long long)ext->e_end);
+#endif
+
+	M0_ALLOC_PTR(lr_ext1);
+	if (lr_ext1 == NULL) {
+		m0_layout__log("extlist_in_buf_read",
+			       "failed to allocate composite extent",
+			       M0_LAYOUT_ADDB_LOC_COMP_ELIST_READ_2,
+			       &layer->clr_l->l_addb_ctx,
+			       layer->clr_l->l_id, -ENOMEM);
+		return -ENOMEM;
+	}
+	lr_ext1->cle_ext = *ext;
+	lr_ext1->cle_state = ext_state;
+	//m0_composite_layer_ext_tlink_init_at(lr_ext1, layer->clr_extents);
+	m0_composite_layer_ext_tlink_init(lr_ext1);
+	M0_ASSERT(m0_composite_layer_ext_tlink_is_in(lr_ext)); //rm
+	M0_ASSERT(!m0_composite_layer_ext_tlink_is_in(lr_ext1)); //rm
+	m0_composite_layer_ext_tlist_add_before(lr_ext, lr_ext1);
+	M0_CNT_INC(layer->clr_extents_nr);
+	return 0;
+}
+
+static int extent_split_internal(struct m0_composite_layer *layer,
+				 struct m0_composite_layer_extent *lr_ext,
+				 struct m0_indexvec *vec,
+				 m0_bindex_t scan)
+{
+	struct m0_ext                     ext;
+	struct m0_composite_layer_extent *lr_ext1;
+	m0_bcount_t                       len;
+	uint32_t                          i;
+	int                               rc;
+
+#ifndef __KERNEL__
+	printf("extent_split_internal(): len0 %llu, len1 %llu, "
+		"len2 %llu\n",
+		(unsigned long long)vec->iv_vec.v_count[0],
+		(unsigned long long)vec->iv_vec.v_count[1],
+		(unsigned long long)vec->iv_vec.v_count[2]);
+#endif
+
+
+#if 1 //todo rm
+	rc = ext_in_memory_find(layer, &lr_ext->cle_ext, lr_ext->cle_state,
+				&lr_ext1);
+	M0_ASSERT(rc == 0);
+	M0_ASSERT(lr_ext == lr_ext1);
+#endif
+
+	if (rc == 0) {
+		for (i = 0; i < vec->iv_vec.v_nr; ++i) {
+			len = vec->iv_vec.v_count[i];
+			if (len != 0) {
+				ext.e_start = scan;
+				ext.e_end = scan = scan + len;
+				rc = ext_add(layer, lr_ext, &ext,
+					     vec->iv_index[i]);
+				M0_ASSERT(rc == 0); //todo Handle
+				//todo If i==0, check if the ext shall be merged with th prior one
+				if (rc != 0)
+					break;
+			}
+		}
+	}
+
+#if 1 //todo rm
+	rc = ext_in_memory_find(layer, &lr_ext->cle_ext, lr_ext->cle_state,
+				&lr_ext1);
+	M0_ASSERT(rc == 0);
+	M0_ASSERT(lr_ext == lr_ext1);
+#endif
+
+	rc = ext_in_memory_delete(layer, &lr_ext->cle_ext, lr_ext->cle_state);
+	M0_ASSERT(rc == 0);
+	M0_POST(layer_invariant(layer));
+	return rc;
+}
+
+static int ext_add_in_mem(struct m0_composite_layout *cl,
+			  struct m0_composite_layer *layer,
+			  struct m0_ext *ext,
+			  uint64_t ext_state)
+{
+	struct m0_composite_layer_extent *lr_ext;
+	struct m0_composite_layer_extent *ext_to_insert_into;
+	uint64_t                          ext_state_orig;
+	struct m0_ext                    *chunk;
+	const struct m0_ext               ext0 = *ext;
+	uint32_t                          i; //todo rm
+	int                               rc;
 
 	M0_PRE(composite_invariant(cl));
-	M0_PRE(ext != NULL);
-	M0_PRE(tx != NULL);
 	M0_ENTRY("lid %llu, layer %lu, e_start %llu, e_end %llu",
-		 (unsigned long long)cl->cl_base.l_id,
-		 (unsigned long)layer_idx, (unsigned long long)ext->e_start,
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx,
+		 (unsigned long long)ext->e_start,
 		 (unsigned long long)ext->e_end);
 
-	m0_mutex_lock(&cl->cl_base.l_lock);
-	layer = layer_find(cl, layer_idx);
+	//todo Find the nearest in-memory extent
+	ext_to_insert_into = NULL;
+	m0_tl_for(m0_composite_layer_ext, layer->clr_extents, lr_ext) {
+		if (ext->e_start >= lr_ext->cle_ext.e_start)
+			ext_to_insert_into = lr_ext;
+	} m0_tl_endfor;
+	M0_ASSERT(ext_to_insert_into != NULL);
+#ifndef __KERNEL__
+	printf("ext_add_in_mem(): lid %llu, layer %lu, e_start %llu, "
+		"e_end %llu, ext_to_insert_into_start %llu, "
+		"ext_to_insert_into_end %llu\n",
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx,
+		 (unsigned long long)ext->e_start,
+		 (unsigned long long)ext->e_end,
+		 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+		 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+
+	chunk = &ext_to_insert_into->cle_ext;
+	M0_ASSERT(m0_ext_is_in(chunk, ext->e_start));
+	M0_ASSERT(layer_invariant(layer));
+
+	/*
+	 * Iterate over existing extent overlapping with the new one,
+	 * calculating for each, what parts have to be deleted and what remains.
+	 *
+	 * In the worst case, an existing extent can split into three
+	 * parts. Generally, some of these parts can be empty.
+	 *
+	 * Note that the _whole_ new segment is inserted on the last iteration
+	 * of the loop below (see length[1] assignment), thus violating the map
+	 * invariant until the loop exits (the map is "porous" during that
+	 * time).
+	 */
+
+	i = 0;
+	while (!m0_ext_is_empty(ext)) {
+		m0_bcount_t    length[3];
+		m0_bindex_t    bstart[3] = { 0 };
+		m0_bcount_t    consumed;
+		struct m0_ext  clip;
+#if 1
+		struct m0_indexvec vec = {
+			.iv_vec = {
+				.v_nr    = 3,
+				.v_count = length
+			},
+			.iv_index = bstart
+		};
+#endif
+
+		m0_ext_intersection(ext, chunk, &clip);
+		M0_ASSERT(clip.e_start == ext->e_start);
+		consumed = m0_ext_length(&clip);
+		M0_ASSERT(consumed > 0);
+
+		length[0] = clip.e_start - chunk->e_start;
+		length[1] = clip.e_end == ext->e_end ? m0_ext_length(&ext0) : 0;
+		length[2] = chunk->e_end - clip.e_end;
+		M0_ASSERT(length[0] != 0 || length[1] != 0 || length[2] != 0);
+
+		bstart[0] = ext_state;
+		ext_state_orig = ext_to_insert_into->cle_state;
+
+		if (length[0] > 0)
+			bstart[0] = ext_state_orig;
+		if (length[2] > 0)
+			bstart[2] = ext_state_orig;
+
+		if (!(length[0] == 0 && length[2] == 0)) {
+			rc = extent_split_internal(layer, ext_to_insert_into,
+						   &vec,
+						   length[0] > 0 ?
+						   chunk->e_start :
+						   ext0.e_start);
+			if (rc != 0)
+				break;
+		} else {
+			/* There is no need to split the existing extent. */
+			M0_ASSERT(length[1] ==
+				  m0_ext_length(&ext_to_insert_into->cle_ext));
+			rc = 0;
+		}
+
+		ext->e_start += consumed;
+		M0_ASSERT(ext->e_start <= ext->e_end);
+
+		if (!m0_ext_is_empty(ext)) {
+#if 0
+			/*
+			 * If ext is not yet empty, ext_to_insert_into should
+			 * not be the last element of the list.
+			 */
+			M0_ASSERT(m0_tlist_tail(m0_composite_layer_ext_tlist,
+						layer->clr_extents) != NULL);
+#endif
+			ext_to_insert_into = m0_composite_layer_ext_tlist_next(
+                                                        layer->clr_extents,
+                                                        ext_to_insert_into);
+#ifndef __KERNEL__
+	printf("ext_add_in_mem(): i %lu, lid %llu, layer %lu, e_start %llu, "
+		"e_end %llu, ext_to_insert_into_start %llu, "
+		"ext_to_insert_into_end %llu\n",
+		 (unsigned long)i,
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx,
+		 (unsigned long long)ext->e_start,
+		 (unsigned long long)ext->e_end,
+		 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+		 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+
+			if (ext_to_insert_into == NULL)
+				break;
+		}
+		++i;
+	}
+
+	M0_ASSERT_EX(ergo(rc == 0, layer_invariant(layer)));
+	M0_ASSERT_EX(ergo(rc == 0, composite_invariant(cl)));
+	return rc;
+}
+
+#if 0
+static int ext_add_in_mem(struct m0_composite_layout *cl,
+			  struct m0_composite_layer *layer,
+			  const struct m0_ext *ext_to_operate,
+			  uint64_t ext_state)
+{
+	struct m0_composite_layer_extent *lr_ext;
+	struct m0_composite_layer_extent *lr_ext2; //todo rm
+	struct m0_composite_layer_extent *ext_to_insert_into;
+	uint64_t                          ext_state_orig;
+	//struct m0_emap_seg                seg; //todo rm?
+	struct m0_ext                    *chunk;
+	struct m0_ext                     ext;
+	const struct m0_ext               ext0 = *ext_to_operate;
+	uint32_t                          i; //todo rm
+	int                               rc;
+
+	ext = *ext_to_operate;
+	M0_ENTRY("lid %llu, layer %lu, e_start %llu, e_end %llu",
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx,
+		 (unsigned long long)ext.e_start,
+		 (unsigned long long)ext.e_end);
+
+	//todo Find the nearest in-memory extent
+	ext_to_insert_into = NULL;
+	m0_tl_for(m0_composite_layer_ext, layer->clr_extents, lr_ext) {
+		if (ext.e_start >= lr_ext->cle_ext.e_start)
+			ext_to_insert_into = lr_ext;
+	} m0_tl_endfor;
+	M0_ASSERT(ext_to_insert_into != NULL);
+#ifndef __KERNEL__
+	printf("ext_add_in_mem(): lid %llu, layer %lu, e_start %llu, "
+		"e_end %llu, ext_to_insert_into_start %llu, "
+		"ext_to_insert_into_end %llu\n",
+		 (unsigned long long)layer->clr_l->l_id,
+		 (unsigned long)layer->clr_idx,
+		 (unsigned long long)ext.e_start,
+		 (unsigned long long)ext.e_end,
+		 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+		 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+
+/*
+	seg.ee_ext = ext_to_insert_into->cle_ext;
+	seg.ee_val = ext_to_insert_into->cle_state;
+*/
+
+	chunk = &ext_to_insert_into->cle_ext;
+	M0_ASSERT(m0_ext_is_in(chunk, ext.e_start));
+
+	/*
+	 * Iterate over existing extent overlapping with the new one,
+	 * calculating for each, what parts have to be deleted and what remains.
+	 *
+	 * In the worst case, an existing extent can split into three
+	 * parts. Generally, some of these parts can be empty.
+	 *
+	 * Note that the _whole_ new segment is inserted on the last iteration
+	 * of the loop below (see length[1] assignment), thus violating the map
+	 * invariant until the loop exits (the map is "porous" during that
+	 * time).
+	 */
+
+	i = 0;
+	while (!m0_ext_is_empty(&ext)) {
+		m0_bcount_t    length[3];
+		m0_bindex_t    bstart[3] = { 0 };
+		m0_bcount_t    consumed;
+		struct m0_ext  clip;
+#if 0
+		struct m0_indexvec vec = {
+			.iv_vec = {
+				.v_nr    = 3,
+				.v_count = length
+			},
+			.iv_index = bstart
+		};
+#endif
+
+		m0_ext_intersection(&ext, chunk, &clip);
+		M0_ASSERT(clip.e_start == ext.e_start);
+		consumed = m0_ext_length(&clip);
+		M0_ASSERT(consumed > 0);
+
+		length[0] = clip.e_start - chunk->e_start;
+		length[1] = clip.e_end == ext.e_end ? m0_ext_length(&ext0) : 0;
+		length[2] = chunk->e_end - clip.e_end;
+		bstart[1] = ext_state;
+		ext_state_orig = ext_to_insert_into->cle_state;
+
+#ifndef __KERNEL__
+		printf("Hello\n");
+		printf("ext_add_in_mem(): len0 %llu, len1 %llu, len2 %llu\n",
+			(unsigned long long)length[0],
+			(unsigned long long)length[1],
+			(unsigned long long)length[2]);
+
+		printf("ext_add_in_mem(): Before _trim: i %lu, "
+			"ext_to_insert_into_start %llu, "
+			"ext_to_insert_into_end %llu\n",
+			 (unsigned long)i,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+
+
+		if (length[0] > 0) {
+#if 1 //todo rm
+	rc = ext_in_memory_find(layer, &ext_to_insert_into->cle_ext,
+				ext_to_insert_into->cle_state, &lr_ext2);
+	M0_ASSERT(rc == 0);
+#endif
+			/* Cut left */
+			rc = ext_in_memory_trim(layer, CUT_LEFT,
+						&ext_to_insert_into->cle_ext,
+						ext_to_insert_into->cle_state,
+						&clip, true);
+			M0_ASSERT(rc == 0);
+			//seg.ee_ext.e_start = clip.e_start;
+			//ext_to_insert_into->cle_ext.e_start = clip.e_start;
+			bstart[0] = ext_to_insert_into->cle_state;
+
+#ifndef __KERNEL__
+		printf("ext_add_in_mem(): After _trim_left: i %lu, "
+			"ext_to_insert_into_start %llu, "
+			"ext_to_insert_into_end %llu\n",
+			 (unsigned long)i,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+
+
+		}
+		if (length[2] > 0) {
+#if 1 //todo rm
+	rc = ext_in_memory_find(layer, &ext_to_insert_into->cle_ext,
+				ext_to_insert_into->cle_state, &lr_ext2);
+	M0_ASSERT(rc == 0);
+#endif
+			/* Cut right */
+			//todo Once _trim accepts ext, pass clip to it
+			rc = ext_in_memory_trim(layer, CUT_RIGHT,
+						&ext_to_insert_into->cle_ext,
+						ext_to_insert_into->cle_state,
+						&clip, true);
+			M0_ASSERT(rc == 0);
+			//seg.ee_ext.e_end = clip.e_end;
+			//ext_to_insert_into->cle_ext.e_end = clip.e_end;
+			bstart[2] = ext_to_insert_into->cle_state;
+
+#ifndef __KERNEL__
+		printf("ext_add_in_mem(): After _trim_right: i %lu, "
+			"ext_to_insert_into_start %llu, "
+			"ext_to_insert_into_end %llu\n",
+			 (unsigned long)i,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+		}
+		if (length[0] == 0 && length[2] == 0) {
+#if 1 //todo rm
+	rc = ext_in_memory_find(layer, &ext_to_insert_into->cle_ext,
+				ext_to_insert_into->cle_state, &lr_ext2);
+	M0_ASSERT(rc == 0);
+#endif
+			/* Delete */
+#if 0
+			rc = ext_in_memory_delete(layer,
+						&ext_to_insert_into->cle_ext,
+						ext_to_insert_into->cle_state);
+			M0_ASSERT(rc == 0);
+#endif
+		}
+
+#if 0
+		result = emap_split_internal(it, &vec, length[0] > 0 ?
+					     chunk->e_start : ext0.e_start);
+		if (result != 0)
+			break;
+#endif
+		ext.e_start += consumed;
+		M0_ASSERT(ext.e_start <= ext.e_end);
+
+#if 1
+		if (!m0_ext_is_empty(&ext)) {
+#if 0
+			M0_ASSERT(!m0_emap_ext_is_last(&seg->ee_ext));
+			result = emap_next(it);
+			if (result != 0)
+				break;
+#endif
+
+#if 0 //todo rm
+			M0_ASSERT(m0_tlist_tail(m0_composite_layer_ext_tlist,
+						layer->clr_extents) != NULL);
+#endif
+#ifndef __KERNEL__
+		printf("ext_add_in_mem(): Before _next: i %lu, "
+			"ext_to_insert_into_start %llu, "
+			"ext_to_insert_into_end %llu\n",
+			 (unsigned long)i,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+
+			ext_to_insert_into = m0_composite_layer_ext_tlist_next(
+                                                        layer->clr_extents,
+                                                        ext_to_insert_into);
+			/*
+			 * If ext is not yet empty, ext_to_insert_into should
+			 * not be the last element of the list.
+			 */
+			M0_ASSERT(ext_to_insert_into != NULL);
+#ifndef __KERNEL__
+		printf("ext_add_in_mem(): After _next: i %lu, "
+			"ext_to_insert_into_start %llu, "
+			"ext_to_insert_into_end %llu\n",
+			 (unsigned long)i,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_start,
+			 (unsigned long long)ext_to_insert_into->cle_ext.e_end);
+#endif
+
+
+		}
+#endif
+		++i;
+	}
+
+#if 0
+	//todo ext_to_operate need not be separate from ext now
+	rc = ext_in_memory_add(layer, ext_to_operate, ext_state);
+	M0_ASSERT(rc == 0);
+#endif
+
+	//M0_ASSERT_EX(ergo(rc == 0, emap_invariant(it)));
+	return rc;
+}
+#endif
+
+static int ext_add_in_mem_and_DB(struct m0_composite_layout *cl,
+				 struct m0_composite_layer *layer,
+				 const struct m0_ext *ext,
+				 struct m0_db_tx *tx)
+{
+	struct m0_emap        *emap;
+	struct m0_emap_cursor  it;
+	struct layout_prefix   prefix;
+	int                    rc;
+
+	//todo Change m0_layout__log to M0_LOG now
 	emap = emap_from_cl(cl);
 	prefix_set(&prefix, cl->cl_base.l_id, layer->clr_idx);
 	rc = m0_emap_lookup(emap, tx, (struct m0_uint128 *)&prefix,
 			    ext->e_start, &it);
 	if (rc != 0) {
-		m0_layout__log("m0_composite_layer_ext_add",
+		m0_layout__log("ext_add_in_mem_and_DB",
 			       "failed to lookup into layer_emap",
 			       M0_LAYOUT_ADDB_LOC_COMP_EXT_ADD_1,
 			       &cl->cl_base.l_addb_ctx, cl->cl_base.l_id, rc);
@@ -1951,18 +2540,44 @@ M0_INTERNAL int m0_composite_layer_ext_add(struct m0_composite_layout *cl,
 
 	rc = ext_in_db_write(&it, layer, ext, M0_CLRES_VALID, true);
 	if (rc != 0)
-		m0_layout__log("m0_composite_layer_ext_add",
+		m0_layout__log("ext_add_in_mem_and_DB",
 			       "failed to write extent in DB",
 			       M0_LAYOUT_ADDB_LOC_COMP_EXT_ADD_2,
 			       &cl->cl_base.l_addb_ctx, cl->cl_base.l_id, rc);
 	m0_emap_close(&it);
-	m0_mutex_unlock(&cl->cl_base.l_lock);
-	M0_POST(layer_invariant(layer));
-	M0_LEAVE("lid %llu, layer %lu, e_start %llu, e_end %llu, rc %d",
+	M0_RETURN(rc);
+}
+
+M0_INTERNAL int m0_composite_layer_ext_add(struct m0_composite_layout *cl,
+					   uint32_t layer_idx,
+					   const struct m0_ext *ext,
+					   struct m0_db_tx *tx)
+{
+	struct m0_composite_layer *layer;
+	struct m0_ext              ext1 = *ext; //todo May considering making such copy in ext_add_in_mem() and ext_add_in_mem_and_DB()
+	int                        rc;
+
+	M0_PRE(composite_invariant(cl));
+	M0_PRE(ext != NULL);
+	/* todo change this to s'thing like
+	M0_PRE(ergo(cl->cl_base.l_dom->ld_do_i_have_DB, tx != NULL)); */
+	M0_ENTRY("lid %llu, layer %lu, e_start %llu, e_end %llu",
 		 (unsigned long long)cl->cl_base.l_id,
 		 (unsigned long)layer_idx, (unsigned long long)ext->e_start,
-		 (unsigned long long)ext->e_end, rc);
-	return rc;
+		 (unsigned long long)ext->e_end);
+
+	m0_mutex_lock(&cl->cl_base.l_lock);
+	layer = layer_find(cl, layer_idx);
+
+	//todo This condition has to be based on do_i_have_DB
+	if (tx == NULL)
+		rc = ext_add_in_mem(cl, layer, &ext1, M0_CLRES_VALID);
+	else
+		rc = ext_add_in_mem_and_DB(cl, layer, ext, tx);
+
+	m0_mutex_unlock(&cl->cl_base.l_lock);
+	M0_POST(layer_invariant(layer));
+	M0_RETURN(rc);
 }
 
 M0_INTERNAL int m0_composite_layer_ext_state_update(
diff --git a/layout/composite.h b/layout/composite.h
index 5d1e2e6..e627df4 100644
--- a/layout/composite.h
+++ b/layout/composite.h
@@ -139,6 +139,9 @@ enum m0_composite_layer_ext_state {
 	 *
 	 * Extents with this state are not stored in the in-memory list of the
 	 * extents.
+	 * todo INVALID extents too are stored in memory now
+	 * todo Make changes in UT such that even INVALID extents are
+	 * provided as a part of the input extent list
 	 */
 	M0_CLRES_INVALID,
 
diff --git a/layout/ut/composite.c b/layout/ut/composite.c
index 2396782..225dae5 100644
--- a/layout/ut/composite.c
+++ b/layout/ut/composite.c
@@ -21,6 +21,7 @@
 #include "lib/ut.h"                 /* M0_UT_ASSERT() */
 #include "lib/memory.h"             /* M0_ALLOC_PTR() */
 #include "lib/misc.h"               /* M0_IN() */
+#include "lib/finject.h" //todo Check if req'd
 
 #include "layout/layout.h"
 #include "layout/layout_internal.h" /* *_ERR */
@@ -136,6 +137,7 @@ static void sublayouts_delete(struct m0_layout_domain *domain,
 	00001 [7fffffffffffffff .. fffffffffffffffe) (7fffffffffffffff):                1
 	00002 [fffffffffffffffe .. ffffffffffffffff) (               1):                0    <----
  */
+//todo rename extentmask_build()
 static void extentlist_build(struct m0_tl **extlist,
 			     uint32_t extents_nr,
 			     m0_bindex_t min_start_offset,
@@ -148,6 +150,9 @@ static void extentlist_build(struct m0_tl **extlist,
 	m0_bindex_t                       multiplier;
 	uint32_t                          i;
 
+	min_start_offset = 0;
+	approximate_end_offset = M0_BINDEX_MAX;
+
 	/* Initialise a m0_tl for storing the extents. */
 	M0_ALLOC_PTR(extents);
 	M0_UT_ASSERT(extents != NULL);
@@ -157,7 +162,63 @@ static void extentlist_build(struct m0_tl **extlist,
 	multiplier = if_contiguous_extents ? 1 : 2;
 	delta = (approximate_end_offset - min_start_offset) /
 		(extents_nr * multiplier);
+#if 1
+#ifndef __KERNEL__
+	printf("extents_nr %lu, min_start_offset %llu, "
+	       "approximate_end_offset %llu\n",
+		(unsigned long)extents_nr,
+		(unsigned long long)min_start_offset,
+		(unsigned long long)approximate_end_offset);
+#endif
+#endif
+	for (i = 0; i < extents_nr; ++i) {
+		M0_ALLOC_PTR(extent);
+		M0_UT_ASSERT(extent != NULL);
+		extent->cle_ext.e_start = min_start_offset +
+					  (multiplier * i * delta);
+		if (i == extents_nr - 1)
+			extent->cle_ext.e_end = M0_BINDEX_MAX;
+		else
+			extent->cle_ext.e_end = extent->cle_ext.e_start + delta;
+		extent->cle_state = M0_CLRES_VALID;
+
+#if 1
+#ifndef __KERNEL__
+	printf("ext[%u]: start %llu, end %llu \n", i,
+		(unsigned long long)extent->cle_ext.e_start,
+		(unsigned long long)extent->cle_ext.e_end);
+#endif
+#endif
+		m0_composite_layer_ext_tlink_init_at_tail(extent, extents);
+	}
+	*extlist = extents;
+	M0_UT_ASSERT(!m0_composite_layer_ext_tlist_is_empty(*extlist));
+}
+
 #if 0
+//Old version to build the extent list and not the extent mask
+static void extentlist_build(struct m0_tl **extlist,
+			     uint32_t extents_nr,
+			     m0_bindex_t min_start_offset,
+			     m0_bindex_t approximate_end_offset,
+			     bool if_contiguous_extents)
+{
+	struct m0_tl                     *extents;
+	struct m0_composite_layer_extent *extent;
+	m0_bindex_t                       delta;
+	m0_bindex_t                       multiplier;
+	uint32_t                          i;
+
+	/* Initialise a m0_tl for storing the extents. */
+	M0_ALLOC_PTR(extents);
+	M0_UT_ASSERT(extents != NULL);
+	m0_composite_layer_ext_tlist_init(extents);
+	M0_UT_ASSERT(m0_composite_layer_ext_tlist_is_empty(extents));
+
+	multiplier = if_contiguous_extents ? 1 : 2;
+	delta = (approximate_end_offset - min_start_offset) /
+		(extents_nr * multiplier);
+#if 1
 #ifndef __KERNEL__
 		printf("extents_nr %lu, min_start_offset %llu, "
 		       "approximate_end_offset %llu\n",
@@ -173,7 +234,7 @@ static void extentlist_build(struct m0_tl **extlist,
 					  (multiplier * i * delta);
 		extent->cle_ext.e_end = extent->cle_ext.e_start + delta;
 		extent->cle_state = M0_CLRES_VALID;
-#if 0
+#if 1
 #ifndef __KERNEL__
 		printf("ext[%u]: start %llu, end %llu \n", i,
 			(unsigned long long)extent->cle_ext.e_start,
@@ -185,6 +246,7 @@ static void extentlist_build(struct m0_tl **extlist,
 	*extlist = extents;
 	M0_UT_ASSERT(!m0_composite_layer_ext_tlist_is_empty(*extlist));
 }
+#endif
 
 static void composite_layout_verify(struct m0_layout *l,
 				    uint64_t composite_lid,
@@ -210,6 +272,9 @@ static void composite_layout_verify(struct m0_layout *l,
 	uint32_t                          i;
 	uint32_t                          j;
 
+	min_start_offset = 0;
+	approximate_end_offset = M0_BINDEX_MAX;
+
 	M0_UT_ASSERT(l != NULL);
 	M0_UT_ASSERT(l->l_type == &m0_composite_layout_type);
 
@@ -249,7 +314,8 @@ static void composite_layout_verify(struct m0_layout *l,
 				     min_start_offset +
 				     (multiplier * j * delta));
 			M0_UT_ASSERT(extent->cle_ext.e_end ==
-				     extent->cle_ext.e_start + delta);
+				     extent->cle_ext.e_start + delta ||
+				     extent->cle_ext.e_end == M0_BINDEX_MAX);
 			++j;
 		} m0_tl_endfor;
 		M0_UT_ASSERT(j == extents_nr);
@@ -446,6 +512,163 @@ int test_build_composite(uint64_t lid,
 	return rc;
 }
 
+enum extent_operation {
+	EXTENT_LOOKUP,
+	EXTENT_ADD,
+	EXTENT_UPDATE,
+	EXTENT_DELETE
+}; //todo placement
+
+//todo placement
+static void extent_to_be_operated(const struct m0_composite_layout *cl,
+				  bool if_contiguous_extents,
+				  uint32_t layer_idx,
+				  uint64_t extent_idx,
+				  uint32_t kind_of_extent_to_add,
+				  struct m0_ext *ext)
+{
+	struct m0_composite_layer        *layer;
+	struct m0_composite_layer_extent *extent;
+	struct m0_ext                     ext_idxth;
+	struct m0_ext                     ext_idx_plus_oneth;
+	int                               i;
+
+	M0_UT_ASSERT(layer_idx > 0);
+	M0_UT_ASSERT(M0_IN(kind_of_extent_to_add, (EXACT_EXISTING,
+						   NON_EXISTING,
+						   OVERLAPPING_LEFT,
+						   OVERLAPPING_RIGHT,
+						   OVERLAPPING_COMPLETE,
+						   CONTAINED_WITHIN)));
+
+	/* Find the layer with the specified layer id. */
+	layer = NULL;
+	m0_tl_for(comp_layer, &cl->cl_layers, layer) {
+		if (layer->clr_idx == layer_idx)
+			break;
+	} m0_tl_endfor;
+	M0_UT_ASSERT(layer != NULL);
+
+	M0_UT_ASSERT(ergo(kind_of_extent_to_add == EXACT_EXISTING,
+			  extent_idx < layer->clr_extents_nr));
+	M0_UT_ASSERT(ergo(kind_of_extent_to_add == NON_EXISTING,
+			  if_contiguous_extents == false));
+	M0_UT_ASSERT(ergo(kind_of_extent_to_add != EXACT_EXISTING,
+			  layer->clr_extents_nr >= 3 &&
+			  layer->clr_extents_nr >= extent_idx + 1));
+#if 0 //todo rm
+	M0_UT_ASSERT(ergo(kind_of_extent_to_add == CONTAINED_WITHIN,
+			  if_contiguous_extents == true));
+#endif
+
+	i = 0;
+	ext_idxth.e_start = 0; /* To keep the compiler happy. */
+	ext_idxth.e_end = 0;
+	ext_idx_plus_oneth.e_start = 0;
+	ext_idx_plus_oneth.e_end = 0;
+	m0_tl_for(m0_composite_layer_ext, layer->clr_extents, extent) {
+		if (i == extent_idx) {
+			ext_idxth = extent->cle_ext;
+			if (kind_of_extent_to_add == EXACT_EXISTING)
+				break;
+		} else if (i == extent_idx + 1) {
+			ext_idx_plus_oneth = extent->cle_ext;
+			break;
+		}
+		++i;
+	} m0_tl_endfor;
+
+	M0_UT_ASSERT(ergo(!if_contiguous_extents,
+			  ext_idxth.e_end != ext_idx_plus_oneth.e_start));
+
+	if (kind_of_extent_to_add == EXACT_EXISTING)
+		*ext = ext_idxth;
+	else if (kind_of_extent_to_add == NON_EXISTING) {
+		ext->e_start = ext_idxth.e_end;
+		ext->e_end = ext_idx_plus_oneth.e_start;
+	} else if (kind_of_extent_to_add == OVERLAPPING_LEFT) {
+		ext->e_start = ext_idxth.e_start;
+		ext->e_end = ext_idx_plus_oneth.e_start + 1;
+	} else if (kind_of_extent_to_add == OVERLAPPING_RIGHT) {
+		ext->e_start = ext_idxth.e_end - 1;
+		ext->e_end = ext_idx_plus_oneth.e_end;
+	} else if (kind_of_extent_to_add == OVERLAPPING_COMPLETE) {
+		ext->e_start = ext_idxth.e_start - 1;
+		ext->e_end = ext_idx_plus_oneth.e_end + 1;
+	} else if (kind_of_extent_to_add == CONTAINED_WITHIN) {
+		ext->e_start = ext_idxth.e_start + 2;
+		ext->e_end = ext_idxth.e_end - 2;
+	}
+
+#if 1
+#ifndef __KERNEL__
+	printf("extent_to_be_operated: start %llu, end %llu \n",
+		(unsigned long long)ext->e_start,
+		(unsigned long long)ext->e_end);
+#endif
+#endif
+}
+
+static void extent_to_be_operated(const struct m0_composite_layout *cl,
+				  bool if_contiguous_extents,
+				  uint32_t layer_idx,
+				  uint64_t extent_idx,
+				  uint32_t kind_of_extent_to_add,
+				  struct m0_ext *ext); //todo placement
+int test_layer_op_inmem_composite(uint64_t lid,
+				  struct m0_layout_domain *domain,
+				  uint32_t layers_nr,
+				  uint32_t min_extents_nr,
+				  m0_bindex_t min_start_offset,
+				  m0_bindex_t approximate_end_offset,
+				  bool if_contiguous_extents,
+				  uint32_t kind_of_extent_to_add,
+				  bool failure_test)
+{
+	struct m0_composite_layout *cl;
+	struct m0_ext               ext_to_operate;
+
+	m0_fi_enable("m0_composite_layer_add", "skip_DB_sync");
+	rc = composite_build_and_layers_add(lid, domain, NULL, &cl, layers_nr,
+					    min_extents_nr, min_start_offset,
+					    approximate_end_offset,
+					    if_contiguous_extents,
+					    !FAILURE_TEST,
+					    !FAILURE_TEST /* todo replace by
+					    some other enum value */);
+	M0_UT_ASSERT(rc == 0);
+	m0_fi_disable("m0_composite_layer_add", "skip_DB_sync");
+
+	extent_to_be_operated(cl, if_contiguous_extents, 1, 1,
+			      kind_of_extent_to_add, &ext_to_operate);
+
+	//todo Lookup in mem to see that the ext_to_operate does not exist
+	rc = m0_composite_layer_ext_add(cl, cl->cl_layers_nr - 1,
+					&ext_to_operate, NULL);
+	M0_UT_ASSERT(rc == 0);
+	//todo Lookup in mem to see that the ext_to_operate does exist
+
+#if 1
+	if (kind_of_extent_to_add == OVERLAPPING_LEFT)
+		M0_UT_ASSERT(0);
+#endif
+#if 0
+	if (kind_of_extent_to_add == CONTAINED_WITHIN)
+		M0_UT_ASSERT(0);
+#endif
+
+	//M0_UT_ASSERT(0); //todo rm tempo to check contents of the extlist
+	//todo Verify the updated extent list.
+
+	/* Delete the composite layout object. */
+	m0_layout_put(&cl->cl_base);
+	M0_UT_ASSERT(m0_layout_find(domain, lid) == NULL);
+
+	/* Delete all the precreated sublayouts. */
+	sublayouts_delete(domain, lid, layers_nr);
+	return rc;
+}
+
 /* Builds a buffer containing serialised representation of a layout object. */
 static void composite_layout_buf_build(uint64_t composite_lid,
 				       struct m0_layout_domain *domain,
@@ -472,6 +695,9 @@ static void composite_layout_buf_build(uint64_t composite_lid,
 	M0_UT_ASSERT(dcur != NULL);
 	M0_UT_ASSERT(layers_nr > 0);
 
+	min_start_offset = 0;
+	approximate_end_offset = M0_BINDEX_MAX;
+
 	/* Build part of the buffer representing generic part of the layout. */
 	generic_buf_build(m0_composite_layout_type.lt_id, dcur);
 
@@ -481,6 +707,7 @@ static void composite_layout_buf_build(uint64_t composite_lid,
 	 */
 	M0_ASSERT(m0_bufvec_cursor_step(dcur) >= sizeof cl_header);
 	cl_header.ch_layers_nr = layers_nr;
+	cl_header.ch_pad = 0;
 	nbytes = m0_bufvec_cursor_copyto(dcur, &cl_header, sizeof cl_header);
 	M0_ASSERT(nbytes == sizeof cl_header);
 
@@ -516,6 +743,7 @@ static void composite_layout_buf_build(uint64_t composite_lid,
 		layer_header.clh_lid = sublayout_id;
 		layer_header.clh_idx = i;
 		layer_header.clh_extents_nr = extents_nr;
+		layer_header.clh_pad = 0;
 		nbytes = m0_bufvec_cursor_copyto(dcur, &layer_header,
 						 sizeof layer_header);
 		M0_ASSERT(nbytes == sizeof layer_header);
@@ -534,7 +762,10 @@ static void composite_layout_buf_build(uint64_t composite_lid,
 		for (j = 0; j < layer_header.clh_extents_nr; ++j) {
 			ext.e_start = min_start_offset +
 				      multiplier * j * delta;
-			ext.e_end = ext.e_start + delta;
+			if (j == layer_header.clh_extents_nr - 1)
+				ext.e_end = M0_BINDEX_MAX;
+			else
+				ext.e_end = ext.e_start + delta;
 			nbytes = m0_bufvec_cursor_copyto(dcur, &ext,
 							 sizeof ext);
 			M0_ASSERT(nbytes == sizeof ext);
@@ -648,6 +879,9 @@ static void composite_layout_buf_verify(uint64_t lid,
 
 	M0_UT_ASSERT(cur != NULL);
 
+	min_start_offset = 0;
+	approximate_end_offset = M0_BINDEX_MAX;
+
 	/* Verify generic part of the layout buffer. */
 	lbuf_verify(cur, &lt_id);
 	M0_UT_ASSERT(lt_id == m0_composite_layout_type.lt_id);
@@ -679,7 +913,11 @@ static void composite_layout_buf_verify(uint64_t lid,
 			m0_bufvec_cursor_move(cur, sizeof *ext);
 			M0_UT_ASSERT(ext->e_start == min_start_offset +
 						     multiplier * j * delta);
-			M0_UT_ASSERT(ext->e_end == ext->e_start + delta);
+			if (j == layer_header->clh_extents_nr - 1)
+				M0_UT_ASSERT(ext->e_end == M0_BINDEX_MAX);
+			else
+				M0_UT_ASSERT(ext->e_end ==
+					     ext->e_start + delta);
 
 			ext_state = m0_bufvec_cursor_addr(cur);
 			m0_bufvec_cursor_move(cur, sizeof *ext_state);
@@ -758,6 +996,8 @@ static void composite_layout_buf_compare(struct m0_bufvec_cursor *cur1,
 	struct composite_layer_header *layer_header2;
 	struct m0_ext                 *ext1;
 	struct m0_ext                 *ext2;
+	uint64_t                      *ext_state1;
+	uint64_t                      *ext_state2;
 	uint32_t                       i;
 	uint32_t                       j;
 
@@ -790,6 +1030,9 @@ static void composite_layout_buf_compare(struct m0_bufvec_cursor *cur1,
 		layer_header2 = m0_bufvec_cursor_addr(cur2);
 		m0_bufvec_cursor_move(cur1, sizeof *layer_header1);
 		m0_bufvec_cursor_move(cur2, sizeof *layer_header2);
+		M0_UT_ASSERT(layer_header1->clh_lid ==
+			     layer_header2->clh_lid);
+		M0_UT_ASSERT(layer_header1->clh_idx == layer_header2->clh_idx);
 		M0_UT_ASSERT(layer_header1->clh_extents_nr ==
 			     layer_header2->clh_extents_nr);
 
@@ -801,6 +1044,13 @@ static void composite_layout_buf_compare(struct m0_bufvec_cursor *cur1,
 
 			M0_UT_ASSERT(ext1->e_start == ext2->e_start);
 			M0_UT_ASSERT(ext1->e_end == ext2->e_end);
+
+			ext_state1 = m0_bufvec_cursor_addr(cur1);
+			ext_state2 = m0_bufvec_cursor_addr(cur2);
+			m0_bufvec_cursor_move(cur1, sizeof *ext_state1);
+			m0_bufvec_cursor_move(cur2, sizeof *ext_state2);
+
+			M0_UT_ASSERT(*ext_state1 == *ext_state2);
 		}
 	}
 }
@@ -902,7 +1152,7 @@ static void composite_layout_compare(const struct m0_layout *l1,
 	struct m0_composite_layout       *cl2;
 	struct m0_composite_layer        *layer1;
 	struct m0_composite_layer        *layer2;
-	struct m0_composite_layer_extent *extent1;
+	struct m0_composite_layer_extent *extent1; //todo lr_ext1 and at other places applicable
 	struct m0_composite_layer_extent *extent2;
 
 	M0_UT_ASSERT(l1 != NULL && l2 != NULL);
@@ -1447,94 +1697,6 @@ int test_delete_composite(uint64_t lid,
 	return rc;
 }
 
-static void extent_to_be_operated(const struct m0_composite_layout *cl,
-				  bool if_contiguous_extents,
-				  uint32_t layer_idx,
-				  uint64_t extent_idx,
-				  uint32_t kind_of_extent_to_add,
-				  struct m0_ext *ext)
-{
-	struct m0_composite_layer        *layer;
-	struct m0_composite_layer_extent *extent;
-	struct m0_ext                     ext_idxth;
-	struct m0_ext                     ext_idx_plus_oneth;
-	int                               i;
-
-	M0_UT_ASSERT(layer_idx > 0);
-	M0_UT_ASSERT(M0_IN(kind_of_extent_to_add, (EXACT_EXISTING,
-						   NON_EXISTING,
-						   OVERLAPPING_LEFT,
-						   OVERLAPPING_RIGHT,
-						   OVERLAPPING_COMPLETE)));
-
-	/* Find the layer with the specified layer id. */
-	layer = NULL;
-	m0_tl_for(comp_layer, &cl->cl_layers, layer) {
-		if (layer->clr_idx == layer_idx)
-			break;
-	} m0_tl_endfor;
-	M0_UT_ASSERT(layer != NULL);
-
-	M0_UT_ASSERT(ergo(kind_of_extent_to_add == EXACT_EXISTING,
-			  extent_idx < layer->clr_extents_nr));
-	M0_UT_ASSERT(ergo(kind_of_extent_to_add == NON_EXISTING,
-			  if_contiguous_extents == false));
-	M0_UT_ASSERT(ergo(kind_of_extent_to_add != EXACT_EXISTING,
-			  layer->clr_extents_nr >= 3 &&
-			  layer->clr_extents_nr >= extent_idx + 1));
-
-	i = 0;
-	ext_idxth.e_start = 0; /* To keep the compiler happy. */
-	ext_idxth.e_end = 0;
-	ext_idx_plus_oneth.e_start = 0;
-	ext_idx_plus_oneth.e_end = 0;
-	m0_tl_for(m0_composite_layer_ext, layer->clr_extents, extent) {
-		if (i == extent_idx) {
-			ext_idxth = extent->cle_ext;
-			if (kind_of_extent_to_add == EXACT_EXISTING)
-				break;
-		} else if (i == extent_idx + 1) {
-			ext_idx_plus_oneth = extent->cle_ext;
-			break;
-		}
-		++i;
-	} m0_tl_endfor;
-
-	M0_UT_ASSERT(ergo(!if_contiguous_extents,
-			  ext_idxth.e_end != ext_idx_plus_oneth.e_start));
-
-	if (kind_of_extent_to_add == EXACT_EXISTING)
-		*ext = ext_idxth;
-	else if (kind_of_extent_to_add == NON_EXISTING) {
-		ext->e_start = ext_idxth.e_end;
-		ext->e_end = ext_idx_plus_oneth.e_start;
-	} else if (kind_of_extent_to_add == OVERLAPPING_LEFT) {
-		ext->e_start = ext_idxth.e_start;
-		ext->e_end = ext_idx_plus_oneth.e_start + 1;
-	} else if (kind_of_extent_to_add == OVERLAPPING_RIGHT) {
-		ext->e_start = ext_idxth.e_end - 1;
-		ext->e_end = ext_idx_plus_oneth.e_end;
-	} else if (kind_of_extent_to_add == OVERLAPPING_COMPLETE) {
-		ext->e_start = ext_idxth.e_start - 1;
-		ext->e_end = ext_idx_plus_oneth.e_end + 1;
-	}
-
-#if 0
-#ifndef __KERNEL__
-	printf("extent_to_be_operated: start %llu, end %llu \n",
-		(unsigned long long)ext->e_start,
-		(unsigned long long)ext->e_end);
-#endif
-#endif
-}
-
-enum extent_operation {
-	EXTENT_LOOKUP,
-	EXTENT_ADD,
-	EXTENT_UPDATE,
-	EXTENT_DELETE
-};
-
 int ext_operate(enum extent_operation eop,
 		uint64_t lid,
 		struct m0_layout_domain *domain,
diff --git a/layout/ut/composite.h b/layout/ut/composite.h
index 728c6a6..e5e7628 100644
--- a/layout/ut/composite.h
+++ b/layout/ut/composite.h
@@ -33,7 +33,8 @@ enum {
 	EXACT_EXISTING,
 	OVERLAPPING_LEFT,
 	OVERLAPPING_RIGHT,
-	OVERLAPPING_COMPLETE
+	OVERLAPPING_COMPLETE,
+	CONTAINED_WITHIN
 };
 
 int test_build_composite(uint64_t lid,
@@ -44,6 +45,15 @@ int test_build_composite(uint64_t lid,
 			 m0_bindex_t approximate_end_address,
 			 bool if_contiguous_extents,
 			 bool failure_test);
+int test_layer_op_inmem_composite(uint64_t lid,
+				  struct m0_layout_domain *domain,
+				  uint32_t sublayouts_nr,
+				  uint32_t min_extents_nr,
+				  m0_bindex_t min_start_offset,
+				  m0_bindex_t approximate_end_address,
+				  bool if_contiguous_extents,
+				  uint32_t kind_of_extent_to_add,
+				  bool failure_test);
 int test_decode_composite(uint64_t lid,
 			  struct m0_layout_domain *domain,
 			  uint32_t sublayouts_nr,
diff --git a/layout/ut/layout.c b/layout/ut/layout.c
index 2eac1b7..d6289dd 100644
--- a/layout/ut/layout.c
+++ b/layout/ut/layout.c
@@ -490,6 +490,85 @@ static void test_build(void)
 	M0_UT_ASSERT(rc == 0);
 
 	m0_fi_disable("m0_composite_layer_add", "skip_DB_sync");
+
+	/* todo tempo */
+#if 0
+	lid = 1024;
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   !CONTIGUOUS_EXTENTS,
+					   NON_EXISTING,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
+#endif
+
+	lid = 1025;
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   CONTIGUOUS_EXTENTS,
+					   EXACT_EXISTING,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
+
+	lid = 1026;
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   !CONTIGUOUS_EXTENTS,
+					   EXACT_EXISTING,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
+
+#if 0
+	//This won't work until invalid extents are store in-memory
+	lid = 1027;
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   !CONTIGUOUS_EXTENTS,
+					   OVERLAPPING_LEFT,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
+#endif
+
+#if 0
+	//todo Jan 30
+	lid = 1028;
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   CONTIGUOUS_EXTENTS,
+					   OVERLAPPING_LEFT,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
+#endif
+
+#if 0
+	//This won't work until invalid extents are store in-memory
+	lid = 1029;
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   !CONTIGUOUS_EXTENTS,
+					   OVERLAPPING_RIGHT,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
+#endif
+
+#if 0
+	//todo Jan 30
+	lid = 1030;
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   CONTIGUOUS_EXTENTS,
+					   OVERLAPPING_RIGHT,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
+#endif
+
+	lid = 1031; //todo
+	rc = test_layer_op_inmem_composite(lid, &domain, 6, 6, //todo 100,
+					   lid * 100, lid * 100 * 100,
+					   CONTIGUOUS_EXTENTS,
+					   CONTAINED_WITHIN,
+					   !FAILURE_TEST);
+	M0_UT_ASSERT(rc == 0);
 }
 
 static void test_build_failure(void)
@@ -878,6 +957,7 @@ static void test_decode_encode(void)
 					LINEAR_ENUM_ID, INLINE_NOT_APPLICABLE);
 	M0_UT_ASSERT(rc == 0);
 
+#if 1
 	m0_fi_enable("m0_composite_layer_add", "skip_DB_sync");
 	/*
 	 * Build a layout buffer representing a layout with COMPOSITE layout
@@ -888,12 +968,18 @@ static void test_decode_encode(void)
 	 * buffer.
 	 */
 	lid = 7005;
+#if 0
 	rc = test_decode_encode_composite(lid, &domain, 11, 21,
 					  lid * 100, lid * 10 * 100,
 					  CONTIGUOUS_EXTENTS);
+#endif
+	rc = test_decode_encode_composite(lid, &domain, 5, 4,
+					  lid * 100, lid * 10 * 100,
+					  CONTIGUOUS_EXTENTS);
 	M0_UT_ASSERT(rc == 0);
 
 	m0_fi_disable("m0_composite_layer_add", "skip_DB_sync");
+#endif
 }
 
 /* Tests the API sequence m0_layout_encode() followed by m0_layout_decode(). */
-- 
1.8.3.2

