From 05d7edcd1453934b031741fc0ec8390c63903d6d Mon Sep 17 00:00:00 2001
From: "Valery V. Vorotyntsev" <valery_vorotyntsev@xyratex.com>
Date: Sat, 13 Jul 2013 02:13:14 +0300
Subject: [PATCH 10/14] lnet: refactor nlx_tm_ev_worker()

---
 net/lnet/lnet_tm.c | 239 ++++++++++++++++++++++++++++++-----------------------
 1 file changed, 135 insertions(+), 104 deletions(-)

diff --git a/net/lnet/lnet_tm.c b/net/lnet/lnet_tm.c
index 10da4b8..f8592ad 100644
--- a/net/lnet/lnet_tm.c
+++ b/net/lnet/lnet_tm.c
@@ -113,6 +113,137 @@ tm_start(struct m0_net_transfer_mc *tm, struct m0_net_end_point **epp)
 	return rc;
 }
 
+static uint64_t tm_delay(const struct m0_net_transfer_mc *tm)
+{
+	return (tm->ntm_bev_auto_deliver ||
+		tm->ntm_state == M0_NET_TM_STOPPING) ?
+		M0_NET_LNET_EVT_SHORT_WAIT_SECS :
+		M0_NET_LNET_EVT_LONG_WAIT_SECS;
+}
+
+static void tm_lock(struct m0_net_transfer_mc *tm)
+{
+	m0_mutex_lock(&tm->ntm_mutex);
+}
+
+static void tm_unlock(struct m0_net_transfer_mc *tm)
+{
+	m0_mutex_unlock(&tm->ntm_mutex);
+}
+
+static void
+buffer_events_process(struct m0_net_transfer_mc *tm, m0_time_t timeout)
+{
+	struct nlx_xo_transfer_mc   *tp  = tm->ntm_xprt_private;
+	struct nlx_core_transfer_mc *ctp = &tp->xtm_core;
+	struct nlx_core_domain      *cd  = core_domain(tm);
+	int                          rc;
+
+	if (tm->ntm_bev_auto_deliver) {
+		rc = NLX_core_buf_event_wait(cd, ctp, timeout);
+		if (rc == 0) { /* not timed out --- events pending */
+			tm_lock(tm);
+			nlx_xo_bev_deliver_all(tm);
+			tm_unlock(tm);
+		}
+		return;
+	}
+
+	/* Application initiated delivery. */
+	tm_lock(tm);
+	if (tp->xtm_ev_chan == NULL)
+		m0_cond_timedwait(&tp->xtm_ev_cond, timeout);
+	if (tp->xtm_ev_chan != NULL) {
+		tm_unlock(tm);
+		rc = nlx_core_buf_event_wait(cd, ctp, timeout);
+
+		tm_lock(tm);
+		if (rc == 0 && tp->xtm_ev_chan != NULL) {
+			if (tp->xtm_ev_chan == &tm->ntm_chan)
+				m0_chan_signal(tp->xtm_ev_chan);
+			else
+				m0_chan_signal_lock(tp->xtm_ev_chan);
+			tp->xtm_ev_chan = NULL;
+		}
+	}
+	tm_unlock(tm);
+}
+
+static bool
+tm_must_stop(struct m0_net_transfer_mc *tm, struct m0_net_tm_event *tmev)
+{
+	struct nlx_core_domain      *cd  = core_domain(tm);
+	struct nlx_xo_transfer_mc   *tp  = tm->ntm_xprt_private;
+	struct nlx_core_transfer_mc *ctp = &tp->xtm_core;
+	bool stop = false;
+
+	if (tm->ntm_state != M0_NET_TM_STOPPING)
+		return false;
+
+	tm_lock(tm);
+	if (all_tm_queues_are_empty(tm) && tm->ntm_callback_counter == 0) {
+		nlx_core_tm_stop(cd, ctp);
+		stop = true;
+	}
+	tm_unlock(tm);
+
+	if (stop) {
+		tmev->nte_next_state = M0_NET_TM_STOPPED;
+		tmev->nte_time       = m0_time_now();
+		m0_net_tm_event_post(tmev);
+	}
+	return stop;
+}
+
+static void
+worker_loop(struct m0_net_transfer_mc *tm, struct m0_net_tm_event *tmev)
+{
+	const struct nlx_xo_transfer_mc *tp = tm->ntm_xprt_private;
+	m0_time_t now;
+	m0_time_t last_stat_time;
+	m0_time_t next_stat_time;
+	m0_time_t buffer_timeout_tick;
+	m0_time_t next_buffer_timeout;
+
+	tm_lock(tm);
+	now = m0_time_now();
+	last_stat_time = now;
+	next_stat_time = m0_time_add(last_stat_time, tp->xtm_stat_interval);
+	tm_unlock(tm);
+
+	buffer_timeout_tick = NLX_tm_get_buffer_timeout_tick(tm);
+	next_buffer_timeout = m0_time_add(now, buffer_timeout_tick);
+
+	NLXDBGP(tp, 1, "%p: tm_worker_thread started\n", tp);
+	while (1) {
+		buffer_events_process(tm,
+				      min3(m0_time_from_now(tm_delay(tm), 0),
+					   next_stat_time,
+					   next_buffer_timeout));
+
+		/* Periodically record statistics and time out buffers. */
+		now = m0_time_now();
+		tm_lock(tm);
+		next_stat_time = m0_time_add(last_stat_time,
+					     tp->xtm_stat_interval);
+		if (now >= next_stat_time) {
+			last_stat_time = now;
+			next_stat_time = m0_time_add(last_stat_time,
+						     tp->xtm_stat_interval);
+		}
+		if (now >= next_buffer_timeout) {
+			NLX_tm_timeout_buffers(tm, now);
+			next_buffer_timeout = m0_time_add(now,
+							  buffer_timeout_tick);
+		}
+		tm_unlock(tm);
+
+		if (tm_must_stop(tm, tmev))
+			break;
+	}
+	NLXDBGP(tp, 1, "%p: tm_worker_thread stopped\n", tp);
+}
+
 /**
    The entry point of the LNet transport event processing thread.
    It is spawned when the transfer machine starts.  It completes
@@ -125,18 +256,11 @@ static void nlx_tm_ev_worker(struct m0_net_transfer_mc *tm)
 {
 	struct nlx_xo_transfer_mc   *tp  = tm->ntm_xprt_private;
 	struct nlx_core_transfer_mc *ctp = &tp->xtm_core;
-	struct nlx_core_domain      *cd  = core_domain(tm);
 	struct m0_net_tm_event       tmev;
 	struct m0_net_end_point     *ep  = NULL;
-	m0_time_t                    timeout;
-	m0_time_t                    last_stat_time;
-	m0_time_t                    next_stat_time;
-	m0_time_t                    next_buffer_timeout;
-	m0_time_t                    buffer_timeout_tick;
-	m0_time_t                    now;
 	int                          rc;
 
-	m0_mutex_lock(&tm->ntm_mutex);
+	tm_lock(tm);
 	M0_PRE(nlx_tm_invariant(tm));
 
 	nlx_core_tm_set_debug(ctp, tp->_debug_);
@@ -146,7 +270,7 @@ static void nlx_tm_ev_worker(struct m0_net_transfer_mc *tm)
 		LNET_ADDB_FUNCFAIL(rc, C_EV_WORKER, &tm->ntm_addb_ctx);
 
 	tm->ntm_ep = NULL;
-	m0_mutex_unlock(&tm->ntm_mutex);
+	tm_unlock(tm);
 	/*
 	 * Deliver a M0_NET_TEV_STATE_CHANGE event to transition the TM
 	 * to M0_NET_TM_STARTED or M0_NET_TM_FAILED state.
@@ -163,101 +287,8 @@ static void nlx_tm_ev_worker(struct m0_net_transfer_mc *tm)
 	};
 	m0_net_tm_event_post(&tmev);
 
-	if (rc != 0)
-		return;
-
-	m0_mutex_lock(&tm->ntm_mutex);
-	now = m0_time_now();
-	last_stat_time = now;
-	next_stat_time = m0_time_add(last_stat_time, tp->xtm_stat_interval);
-	m0_mutex_unlock(&tm->ntm_mutex);
-
-	buffer_timeout_tick = NLX_tm_get_buffer_timeout_tick(tm);
-	next_buffer_timeout = m0_time_add(now, buffer_timeout_tick);
-
-	NLXDBGP(tp, 1, "%p: tm_worker_thread started\n", tp);
-
-	while (1) {
-		/* Compute next timeout (short if automatic or stopping).
-		   Upper bound constrained by the next stat schedule time.
-		 */
-		if (tm->ntm_bev_auto_deliver ||
-		    tm->ntm_state == M0_NET_TM_STOPPING)
-			timeout = m0_time_from_now(
-					   M0_NET_LNET_EVT_SHORT_WAIT_SECS, 0);
-		else
-			timeout = m0_time_from_now(
-					    M0_NET_LNET_EVT_LONG_WAIT_SECS, 0);
-		if (timeout > next_stat_time)
-			timeout = next_stat_time;
-		if (timeout > next_buffer_timeout)
-			timeout = next_buffer_timeout;
-
-		if (tm->ntm_bev_auto_deliver) {
-			rc = NLX_core_buf_event_wait(cd, ctp, timeout);
-			/* buffer event processing */
-			if (rc == 0) { /* did not time out - events pending */
-				m0_mutex_lock(&tm->ntm_mutex);
-				nlx_xo_bev_deliver_all(tm);
-				m0_mutex_unlock(&tm->ntm_mutex);
-			}
-		} else {		/* application initiated delivery */
-			m0_mutex_lock(&tm->ntm_mutex);
-			if (tp->xtm_ev_chan == NULL)
-				m0_cond_timedwait(&tp->xtm_ev_cond, timeout);
-			if (tp->xtm_ev_chan != NULL) {
-				m0_mutex_unlock(&tm->ntm_mutex);
-				rc = nlx_core_buf_event_wait(cd, ctp, timeout);
-				m0_mutex_lock(&tm->ntm_mutex);
-				if (rc == 0 && tp->xtm_ev_chan != NULL) {
-					if (tp->xtm_ev_chan == &tm->ntm_chan) {
-						m0_chan_signal(tp->xtm_ev_chan);
-					} else {
-						m0_chan_signal_lock(
-							tp->xtm_ev_chan);
-					}
-					tp->xtm_ev_chan = NULL;
-				}
-			}
-			m0_mutex_unlock(&tm->ntm_mutex);
-		}
-
-		/* periodically record statistics and time out buffers */
-		now = m0_time_now();
-		m0_mutex_lock(&tm->ntm_mutex);
-		next_stat_time = m0_time_add(last_stat_time,
-					     tp->xtm_stat_interval);
-		if (now >= next_stat_time) {
-			last_stat_time = now;
-			next_stat_time = m0_time_add(last_stat_time,
-						     tp->xtm_stat_interval);
-		}
-		if (now >= next_buffer_timeout) {
-			NLX_tm_timeout_buffers(tm, now);
-			next_buffer_timeout = m0_time_add(now,
-							  buffer_timeout_tick);
-		}
-		m0_mutex_unlock(&tm->ntm_mutex);
-
-		/* termination processing */
-		if (tm->ntm_state == M0_NET_TM_STOPPING) {
-			bool must_stop = false;
-
-			m0_mutex_lock(&tm->ntm_mutex);
-			if (all_tm_queues_are_empty(tm) &&
-			    tm->ntm_callback_counter == 0) {
-				nlx_core_tm_stop(cd, ctp);
-				must_stop = true;
-			}
-			m0_mutex_unlock(&tm->ntm_mutex);
-			if (must_stop) {
-				tmev.nte_next_state = M0_NET_TM_STOPPED;
-				tmev.nte_time = m0_time_now();
-				m0_net_tm_event_post(&tmev);
-				break;
-			}
-		}
-	}
+	if (rc == 0)
+		worker_loop(tm, &tmev);
 }
 
 /**
-- 
1.8.3.2

