From f2c87dcea7cdb7ddea26a9e9bf93d622d1b6ef6e Mon Sep 17 00:00:00 2001
From: Nachiket Sahasrabuddhe <nachiket_sahasrabuddhe@xyratex.com>
Date: Mon, 9 Sep 2013 18:58:45 +0530
Subject: [PATCH 26/61] bigmemalloc.mf

-Code compiles and is ready for inspection.
-UT for the code does not compile.
---
 lib/linux_kernel/varr.c | 16 +++++-----
 lib/user_space/varr.c   |  9 +++---
 lib/varr.c              | 80 ++++++++++++++++++++++++++-----------------------
 lib/varr.h              | 29 +++++++++---------
 4 files changed, 71 insertions(+), 63 deletions(-)

diff --git a/lib/linux_kernel/varr.c b/lib/linux_kernel/varr.c
index d576d28..f1a94d1 100644
--- a/lib/linux_kernel/varr.c
+++ b/lib/linux_kernel/varr.c
@@ -18,15 +18,17 @@
  * Original creation date: 12/17/2012
  */
 
-#include "lib/varr.h"	/* m0_varr */
-#include "lib/bob.h"	/* m0_bob_type */
-#include "lib/types.h"	/* Includes appropriate types header. */
+#include "lib/varr.h"		/* m0_varr */
+#include "lib/varr_private.h"
+#include "lib/bob.h"		/* m0_bob_type */
+#include "lib/types.h"		/* Includes appropriate types header. */
+#include "lib/memory.h"		/* m0_alloc(), m0_free() */
 #include <linux/pagemap.h>
 
 M0_EXTERN void *m0_varr_buf_alloc(size_t bufsize)
 {
-	if (bufsize == PAGE_CACHE_SIZE);
-	return (void *)get_zeroed_page(GFP_KERNEL);
+	if (bufsize == PAGE_CACHE_SIZE)
+		return (void *)get_zeroed_page(GFP_KERNEL);
 	else
 		return m0_alloc(bufsize);
 }
@@ -34,7 +36,7 @@ M0_EXTERN void *m0_varr_buf_alloc(size_t bufsize)
 M0_EXTERN void m0_varr_buf_free(void *buf, size_t bufsize)
 {
 	M0_PRE(buf != NULL);
-	if (bufsize == PAGECACHE_SIZE)
+	if (bufsize == PAGE_CACHE_SIZE)
 		free_page((unsigned long)buf);
 	else
 		m0_free(buf);
@@ -45,7 +47,7 @@ M0_EXTERN bool m0_varr_size_is_valid(const struct m0_varr *arr)
 	M0_PRE(arr != NULL);
 
 	return  arr->va_buf_shift <= PAGE_CACHE_SHIFT    &&
-		arr->va_obj_shift  <=  arr->va_buf_shift
+		arr->va_obj_shift  <=  arr->va_buf_shift;
 }
 
 /*
diff --git a/lib/user_space/varr.c b/lib/user_space/varr.c
index ff207ef..3647900 100644
--- a/lib/user_space/varr.c
+++ b/lib/user_space/varr.c
@@ -18,10 +18,11 @@
  * Original creation date: 12/17/2012
  */
 
-#include "lib/varr.h"	/* m0_varr */
-#include "lib/bob.h"	/* m0_bob_type */
-#include "lib/memory.h" /* m0_alloc, m0_free */
-#include "lib/types.h"	/* Includes appropriate types header. */
+#include "lib/varr.h"		/* m0_varr */
+#include "lib/varr_private.h"
+#include "lib/bob.h"		/* m0_bob_type */
+#include "lib/memory.h"		/* m0_alloc, m0_free */
+#include "lib/types.h"		/* Includes appropriate types header. */
 
 M0_EXTERN void *m0_varr_buf_alloc(size_t bufsize)
 {
diff --git a/lib/varr.c b/lib/varr.c
index 958b35b..6c86204 100644
--- a/lib/varr.c
+++ b/lib/varr.c
@@ -18,14 +18,20 @@
  * Original creation date: 12/17/2012
  */
 
-#include "lib/varr_private.h"	/* m0_varr_buf_alloc(), m0_varr_buf_free */
 #include "lib/varr.h"		/* m0_varr */
+#include "lib/varr_private.h"	/* m0_varr_buf_alloc(), m0_varr_buf_free */
 #include "lib/bob.h"		/* m0_bob_type */
 #include "lib/memory.h"		/* M0_ALLOC_ARR */
 #include "lib/misc.h"		/* m0_forall */
 #include "lib/errno.h"		/* Includes appropriate errno header. */
 #include "lib/types.h"		/* Includes appropriate types header. */
 #include "lib/trace.h"		/* M0_ENTRY() */
+#include "lib/string.h"		/* strcmp() */
+#ifndef __KERNEL__
+#include <limits.h>		/* CHAR_BIT */
+#else
+#include <linux/limits.h>
+#endif
 
 M0_INTERNAL const struct m0_bob_type varr_bobtype;
 
@@ -49,9 +55,9 @@ M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr,
 	({								     \
 	 uint8_t __shift = (shift);					     \
 	 type    __num   = (num);					     \
-	 M0_BASSERT(operator == "<<" || operator == ">>");		     \
-	 M0_ASSERT(__shift < 8 * sizeof __num);				     \
-	 operator == "<<" ? __num << __shift : __num >> __shift;	     \
+	 M0_ASSERT(!strcmp(operator, "<<") || !strcmp(operator, ">>"));	     \
+	 M0_ASSERT(__shift < CHAR_BIT * sizeof __num);			     \
+	 !strcmp(operator, "<<") ? __num << __shift : __num >> __shift;	     \
 	 })
 
 /* A record in a stack holding address, and index associated with that address
@@ -78,13 +84,13 @@ struct varr_cache {
 	unsigned long *vc_buff;
 	uint64_t       vc_first_index;
 	uint64_t       vc_last_index;
-}
+};
 
 /* Enumeration for action to be taken on a set of buffers. */
 enum buffer_action {
 	BA_ALLOC,
 	BA_DEALLOC,
-	BA_NR
+	BA_NR,
 };
 
 /* Returns logarithm to the base two, for the nearest power of two
@@ -95,7 +101,7 @@ M0_INTERNAL uint8_t nearest_power_of_two(size_t size)
 	uint8_t aligned_shift = 0;
 
 	while (size > aligned_size) {
-		safe_bitshift(aligned_size, size_t, 1, "<<");
+		safe_bitshift(aligned_size, size_t, (size_t)1, "<<");
 		++aligned_shift;
 	}
 	return aligned_shift;
@@ -114,10 +120,11 @@ M0_INTERNAL int stack_init(struct m0_varr *arr)
 	M0_ALLOC_PTR(arr->va_stack);
 	if (arr->va_stack == NULL)
 		return -ENOMEM;
-	M0_ALLOC_ARR(arr->va_stack->vs_srec, arr->va_depth - 1);
-	if (arr->va_stack->vs_srec == NULL)
+	M0_ALLOC_ARR(arr->va_stack->vs_rec, arr->va_depth - 1);
+	if (arr->va_stack->vs_rec == NULL)
 		return -ENOMEM;
 	arr->va_stack->vs_sp = -1;
+	return 0;
 }
 
 M0_INTERNAL int push(struct m0_varr *arr, void *addr, uint64_t index)
@@ -125,8 +132,8 @@ M0_INTERNAL int push(struct m0_varr *arr, void *addr, uint64_t index)
 	++arr->va_stack->vs_sp;
 	if (arr->va_stack->vs_sp == arr->va_depth - 1)
 		return -EPERM;
-	arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_addr  = addr;
-	arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_index = index;
+	arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_addr  = addr;
+	arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_index = index;
 	return 0;
 }
 
@@ -134,8 +141,8 @@ M0_INTERNAL int pop(struct m0_varr *arr, void **addr, uint64_t *index)
 {
 	if (arr->va_stack->vs_sp == -1)
 		return -EPERM;
-	*addr  = arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_addr;
-	*index = arr->va_stack->vs_srec[arr->va_stack->vs_sp].vsr_index;
+	*addr  = arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_addr;
+	*index = arr->va_stack->vs_rec[arr->va_stack->vs_sp].vsr_index;
 	--arr->va_stack->vs_sp;
 	return 0;
 }
@@ -151,7 +158,7 @@ M0_INTERNAL bool cache_fetch(const struct m0_varr *arr, uint64_t index,
 		 arr->va_cache->vc_first_index);
 }
 
-M0_INTERNAL void cache_update(struct m0_varr *arr, unsigned long holder,
+M0_INTERNAL void cache_update(struct m0_varr *arr, unsigned long *holder,
 			      uint64_t start_index)
 {
 	M0_PRE(arr != NULL);
@@ -182,7 +189,7 @@ M0_INTERNAL uint64_t cont_nr_for_objs(unsigned long nr,
 	M0_PRE(obj_nr_in_1_cont > 0);
 
 	return safe_bitshift(nr, unsigned long, obj_nr_shift, ">>") +
-		(nr & (obj_nr_in_1_cont - 1) == 0 ? 0 : 1);
+		(nr & (obj_nr_in_1_cont - 1)) == 0 ? 0 : 1;
 }
 
 /*
@@ -213,8 +220,7 @@ M0_INTERNAL uint64_t max_buff_nr_till_lev_n_pn(const struct m0_varr *arr,
  * VA_TNODE_NR then for *all* arrays with total objects less than or equal to
  * k * VA_TNODE_NR, depth of trees holding object(s) will be one.
  * When total objects in an array exceed k * VA_TNODE_NR, we increase
- * depth by one and calculate the total number of trees with depth 2 that can
- * hold the given number of objects. If buf_size represents size of a buffer,
+ * depth by one. If buf_size represents size of a buffer,
  * ptr_size represents size of a pointer and obj_size represents size of an
  * object, then following table summarizes mapping between total number of
  * objects and depth of trees holding objects.
@@ -242,7 +248,7 @@ M0_INTERNAL uint32_t depth_find(const struct m0_varr *arr,
 	for (level = 0; !found; ++level)
 		if (pg <= safe_bitshift((uint32_t)1, uint32_t,
 					arr->va_bufptr_nr_shift*level +
-					VA_NODE_SHIFT, "<<"))
+					VA_TNODE_NR_SHIFT, "<<"))
 			found = true;
 	return level + 1;
 }
@@ -262,7 +268,6 @@ M0_INTERNAL bool varr_invariant(const struct m0_varr *arr)
 {
 	return  m0_varr_bob_check(arr) &&
 		arr->va_nr > 0         &&
-		arr->va_alloc > 0      &&
 		arr->va_obj_shift > 0  &&
 		arr->va_buf_shift >= arr->va_obj_shift;
 }
@@ -286,7 +291,7 @@ M0_INTERNAL int m0_varr_init(struct m0_varr *arr, uint64_t nr, size_t size,
 	arr->va_bufsize		= safe_bitshift((size_t)1, size_t,
 						arr->va_buf_shift, "<<");
 	arr->va_bufptr_nr_shift = arr->va_buf_shift -
-		neares_power_of_two(VA_TNODEPTR_SIZE);
+		nearest_power_of_two(VA_TNODEPTR_SIZE);
 	arr->va_bufptr_nr       = safe_bitshift((uint64_t)1, uint64_t,
 						arr->va_bufptr_nr_shift, "<<");
 
@@ -328,18 +333,18 @@ M0_INTERNAL void m0_varr_fini(struct m0_varr *arr)
 	M0_PRE_EX(varr_invariant(arr));
 
 	varr_buffers_dealloc(arr, cont_nr_for_objs(arr->va_nr,
-			     varr_obj_nr_in_buff(arr)));
-	m0_free(arr->va_stack->vs_srec);
+						   varr_obj_nr_in_buff(arr),
+						   arr->va_buf_shift -
+						   arr->va_obj_shift));
+	m0_free(arr->va_stack->vs_rec);
 	m0_free(arr->va_stack);
 	m0_free(arr->va_cache);
-	M0_POST(arr->va_alloc == arr->va_dealloc);
 	m0_varr_bob_fini(arr);
 	arr->va_nr     = arr->va_bufsize = 0;
 	arr->va_depth  = 0;
-	arr->va_sizeof = 0;
 }
 
-M0_INTERNAL unsigned long *m0_varr_ele_get(const struct m0_varr *arr,
+M0_INTERNAL unsigned long *m0_varr_ele_get(struct m0_varr *arr,
 					   uint64_t index)
 {
 	uint32_t       level;
@@ -354,14 +359,14 @@ M0_INTERNAL unsigned long *m0_varr_ele_get(const struct m0_varr *arr,
 	if (cache_fetch(arr, index, &holder))
 		goto end;
 	obj_mask    = last_nbits_set(arr->va_obj_shift);
-	buff_mask   = last_nbits_set(arr->va_buff_shift);
+	buff_mask   = last_nbits_set(arr->va_buf_shift);
 	index_local = safe_bitshift(index, uint64_t,
 				    arr->va_obj_shift + (arr->va_depth - 1) *
 				    arr->va_buf_shift, ">>");
 	holder = arr->va_tree[index_local];
 	for (level = 1; level <= arr->va_depth - 1; ++level) {
 		index_local = safe_bitshift(index, uint64_t,
-					    arr->va_obj_shif +
+					    arr->va_obj_shift +
 					    (arr->va_depth - 1 - level) *
 					    arr->va_buf_shift, ">>");
 		index_local &= buff_mask;
@@ -375,7 +380,7 @@ M0_INTERNAL unsigned long *m0_varr_ele_get(const struct m0_varr *arr,
 end:
 	/* Adds to holder the value of last arr->va_obj_shift bits
 	 * from index. */
-	return holder + index & (varr_obj_nr_in_buff(arr) - 1);
+	return holder + (index & (varr_obj_nr_in_buff(arr) - 1));
 }
 
 /* A helper function to factor out one or multiple buffer (de)allocation(s). */
@@ -415,8 +420,8 @@ M0_INTERNAL int buffers_helper(struct m0_varr *arr, void *holder, uint64_t nr,
  * which will store parent of a given level while traversing from top down.
  * The whole approach is taken in order to implement tree traversal in an
  * iterative manner rather than using recursive functions.
- * This approach is a bit similar to inorder traversal of a tree but
- * not exactly the same.
+ * This approach is a similar to preorder traversal (left-right-root) of a
+ * tree but not exactly the same.
  */
 M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr, uint64_t buff_nr)
 {
@@ -433,10 +438,9 @@ M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr, uint64_t buff_nr)
 	M0_PRE(arr != NULL);
 	M0_PRE(buff_nr > 0);
 
-	arr->va_stack->vs_sp = -1;
 	for (done = 0, done_pt = 0, node = 0, child_id = 0, level = 1;
 	     node < VA_TNODE_NR && done < buff_nr;
-	     ++node, done_pt = 0, level = 1, child_id = 0) {
+	     ++node, done += done_pt, done_pt = 0, level = 1, child_id = 0) {
 		holder = arr->va_tree[node];
 		buff_nr_pn = min64u(max_buff_nr_till_lev_n_pn(arr, 1),
 				    buff_nr - done);
@@ -451,8 +455,8 @@ M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr, uint64_t buff_nr)
 			M0_ASSERT(rc == 0);
 		}
 		while (within_tree_height(arr, level)) {
-			/*Keep going down the tree unless end (tree-depth or
-			 * NULL address) is reached. */
+			/*Keep going down the tree unless end (penultimate
+			 * level or NULL address) is reached. */
 			while (done_pt < buff_nr_pn &&
 			       within_tree_width(arr, child_id) &&
 			       (unsigned long *)*holder != NULL) {
@@ -482,7 +486,6 @@ M0_INTERNAL void varr_buffers_dealloc(struct m0_varr *arr, uint64_t buff_nr)
 			++child_id;
 			M0_ASSERT(arr->va_stack->vs_sp == level - 1);
 		}
-		done += done_pt;
 		M0_ASSERT(arr->va_stack->vs_sp == -1);
 	}
 }
@@ -506,7 +509,7 @@ M0_INTERNAL int varr_buffers_alloc(struct m0_varr *arr, uint64_t buff_nr)
 	arr->va_stack->vs_sp = -1;
 	for (done = 0, done_pt = 0, node = 0, child_id = 0, level = 1;
 	     node < VA_TNODE_NR && done < buff_nr;
-	     ++node, done_pt = 0, level = 1, child_id = 0) {
+	     ++node, done += done_pt, done_pt = 0, level = 1, child_id = 0) {
 		buff_nr_pn = min64u(max_buff_nr_till_lev_n_pn(arr, 1),
 				    buff_nr - done);
 		rc = buffers_helper(arr, arr->va_tree[node], 1, BA_ALLOC);
@@ -525,6 +528,8 @@ M0_INTERNAL int varr_buffers_alloc(struct m0_varr *arr, uint64_t buff_nr)
 		}
 		while (done_pt < buff_nr_pn &&
 		       within_tree_height(arr, level)) {
+			/* Keep going down in the tree unless tree-depth is
+			 * reached. */
 			while (within_tree_width(arr, child_id)) {
 				nr = min64u(level != arr->va_depth - 1? 1 :
 					    arr->va_bufptr_nr,
@@ -553,12 +558,13 @@ M0_INTERNAL int varr_buffers_alloc(struct m0_varr *arr, uint64_t buff_nr)
 			++child_id;
 			M0_ASSERT(arr->va_stack->vs_sp == level - 1);
 		}
-		done += done_pt;
 		/* Reset the stack pointer before parsing the next tree. */
 		arr->va_stack->vs_sp = -1;
 	}
 end:
 	M0_POST(ergo(rc == 0, done == buff_nr));
+	if (arr->va_depth > 1)
+		arr->va_stack->vs_sp = -1;
 	return rc;
 }
 
diff --git a/lib/varr.h b/lib/varr.h
index dba6fba..cd44664 100644
--- a/lib/varr.h
+++ b/lib/varr.h
@@ -41,7 +41,7 @@
  * The structure of virtual array is kept something similar to a block map
  * from an on-disk inode which multiple indirections.
  *
- * Using pointer arithmatic on virtual array is strongly discouraged since
+ * Using pointer arithmetic on virtual array is strongly discouraged since
  * it does not guarantee contiguity of buffers.
  *
  * The virtual array uses a radix-tree like structure whose height is
@@ -150,10 +150,8 @@ struct m0_varr {
  * @pre   arr != NULL && nr > 0.
  * @post  varr_invariant(arr) == true.
  */
-M0_INTERNAL int m0_varr_init(struct m0_varr *arr,
-		uint64_t        nr,
-		size_t          size,
-		int             bufsize);
+M0_INTERNAL int m0_varr_init(struct m0_varr *arr, uint64_t nr, size_t size,
+			     size_t bufsize);
 
 /**
  * Finalises a virtual array.
@@ -162,27 +160,28 @@ M0_INTERNAL int m0_varr_init(struct m0_varr *arr,
 M0_INTERNAL void m0_varr_fini(struct m0_varr *arr);
 
 /**
- * Returns address of an object having index as 'index'.
+ * Returns address of an object having index as 'index'. Updates the internal
+ * cache if required.
  * @pre  arr != NULL && index < arr->va_nr.
  * @post varr_invariant(arr).
  */
-M0_INTERNAL unsigned long *m0_varr_ele_get(const struct m0_varr *arr,
+M0_INTERNAL unsigned long *m0_varr_ele_get(struct m0_varr *arr,
 					   uint64_t index);
 
 /* Iterates over an arbitrary arithmetic progression of indices */
 #define m0_varr_for_arith_prog(arr, type, obj, start, end, inc) \
-	({								 \
-	 uint64_t oi;						 \
-	 type    *obj;						 \
-	 M0_PRE(start < arr->va_nr && end < arr->va_nr)		 \
-	 \
-	 for (oi = start; oi <= end; oi += inc) {			 \
-	 obj = (type*)m0_ele_get(arr, oi);		 \
+	({							\
+	 uint64_t oi;						\
+	 type    *obj;						\
+	 M0_PRE(start < arr->va_nr && end < arr->va_nr)		\
+								\
+	 for (oi = start; oi <= end; oi += inc) {		\
+	 obj = (type*)m0_ele_get(arr, oi);			\
 
 #define m0_varr_end for_arith_prog } } )
 
 /** Iterates over whole virtual array. */
-#define m0_varr_for(arr, type, obj)			 \
+#define m0_varr_for(arr, type, obj)				\
 	m0_varr_for_arith_prog(arr, type, obj, 0, arr->va_nr, 1)
 
 #define m0_varr_end_for m0_varr_end_for_arith_prog
-- 
1.8.3.2

